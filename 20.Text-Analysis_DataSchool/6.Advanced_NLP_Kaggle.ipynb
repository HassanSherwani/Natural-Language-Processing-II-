{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Machine Learning Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "1. Reading in the Kaggle data and adding features\n",
    "2. Using a **`Pipeline`** for proper cross-validation\n",
    "3. Combining **`GridSearchCV`** with **`Pipeline`**\n",
    "4. Efficiently searching for tuning parameters using **`RandomizedSearchCV`**\n",
    "5. Adding features to a document-term matrix (using SciPy)\n",
    "6. Adding features to a document-term matrix (using **`FeatureUnion`**)\n",
    "7. Ensembling models\n",
    "8. Locating groups of similar cuisines\n",
    "9. Model stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Python 2: use print only as a function\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Reading in the Kaggle data and adding features\n",
    "\n",
    "- Our goal is to predict the **cuisine** of a recipe, given its **ingredients**.\n",
    "- **Feature engineering** is the process through which you create features that don't natively exist in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import learning_curve,GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts a DataFrame and adds new features\n",
    "def make_features(df):\n",
    "    \n",
    "    # number of ingredients\n",
    "    df['num_ingredients'] = df.ingredients.apply(len)\n",
    "    \n",
    "    # mean length of ingredient names\n",
    "    df['ingredient_length'] = df.ingredients.apply(lambda x: np.mean([len(item) for item in x]))\n",
    "    \n",
    "    # string representation of the ingredient list\n",
    "    df['ingredients_str'] = df.ingredients.astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the same features in the training data and the new data\n",
    "train = make_features(pd.read_json('../data/train.json'))\n",
    "new = make_features(pd.read_json('../data/test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "      <th>ingredients_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>['romaine lettuce', 'black olives', 'grape tom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "      <td>['plain flour', 'ground pepper', 'salt', 'toma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>['water', 'vegetable oil', 'wheat', 'salt']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>['black pepper', 'shallots', 'cornflour', 'cay...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients  \\\n",
       "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3  22213       indian                [water, vegetable oil, wheat, salt]   \n",
       "4  13162       indian  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "   num_ingredients  ingredient_length  \\\n",
       "0                9          12.000000   \n",
       "1               11          10.090909   \n",
       "2               12          10.333333   \n",
       "3                4           6.750000   \n",
       "4               20          10.100000   \n",
       "\n",
       "                                     ingredients_str  \n",
       "0  ['romaine lettuce', 'black olives', 'grape tom...  \n",
       "1  ['plain flour', 'ground pepper', 'salt', 'toma...  \n",
       "2  ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...  \n",
       "3        ['water', 'vegetable oil', 'wheat', 'salt']  \n",
       "4  ['black pepper', 'shallots', 'cornflour', 'cay...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['greek', 'southern_us', 'filipino', 'indian', 'jamaican',\n",
       "       'spanish', 'italian', 'mexican', 'chinese', 'british', 'thai',\n",
       "       'vietnamese', 'cajun_creole', 'brazilian', 'french', 'japanese',\n",
       "       'irish', 'korean', 'moroccan', 'russian'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.cuisine.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We need to have same features in test-set as in train-set except target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "      <th>ingredients_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>[baking powder, eggs, all-purpose flour, raisi...</td>\n",
       "      <td>6</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>['baking powder', 'eggs', 'all-purpose flour',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>[sugar, egg yolks, corn starch, cream of tarta...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.272727</td>\n",
       "      <td>['sugar', 'egg yolks', 'corn starch', 'cream o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>[sausage links, fennel bulb, fronds, olive oil...</td>\n",
       "      <td>6</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>['sausage links', 'fennel bulb', 'fronds', 'ol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>[meat cuts, file powder, smoked sausage, okra,...</td>\n",
       "      <td>21</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>['meat cuts', 'file powder', 'smoked sausage',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>[ground black pepper, salt, sausage casings, l...</td>\n",
       "      <td>8</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>['ground black pepper', 'salt', 'sausage casin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        ingredients  num_ingredients  \\\n",
       "0  18009  [baking powder, eggs, all-purpose flour, raisi...                6   \n",
       "1  28583  [sugar, egg yolks, corn starch, cream of tarta...               11   \n",
       "2  41580  [sausage links, fennel bulb, fronds, olive oil...                6   \n",
       "3  29752  [meat cuts, file powder, smoked sausage, okra,...               21   \n",
       "4  35687  [ground black pepper, salt, sausage casings, l...                8   \n",
       "\n",
       "   ingredient_length                                    ingredients_str  \n",
       "0           9.333333  ['baking powder', 'eggs', 'all-purpose flour',...  \n",
       "1          10.272727  ['sugar', 'egg yolks', 'corn starch', 'cream o...  \n",
       "2           9.666667  ['sausage links', 'fennel bulb', 'fronds', 'ol...  \n",
       "3          12.000000  ['meat cuts', 'file powder', 'smoked sausage',...  \n",
       "4          13.000000  ['ground black pepper', 'salt', 'sausage casin...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Using a `Pipeline` for proper cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = train.ingredients_str\n",
    "y = train.cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['romaine lettuce', 'black olives', 'grape tom...\n",
       "1    ['plain flour', 'ground pepper', 'salt', 'toma...\n",
       "2    ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...\n",
       "3          ['water', 'vegetable oil', 'wheat', 'salt']\n",
       "4    ['black pepper', 'shallots', 'cornflour', 'cay...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X is just a Series of strings\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the regex pattern that is used for tokenization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(token_pattern=r\"'([a-z ]+)'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate Multinomial Naive Bayes (with the default parameters)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[make_pipeline documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline of vectorization and Naive Bayes\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(vect, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countvectorizer',\n",
       "  CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                  dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                  lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                  ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                  strip_accents=None, token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "                  vocabulary=None)),\n",
       " ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the pipeline steps\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proper cross-validation:**\n",
    "\n",
    "- By passing our pipeline to **`cross_val_score`**, features will be created from **`X`** (via **`CountVectorizer`**) within each fold of cross-validation.\n",
    "- This process simulates the real world, in which your out-of-sample data will contain **features that were not seen** during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7322884933790151"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validate the entire pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(pipe, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Combining `GridSearchCV` with `Pipeline`\n",
    "\n",
    "- We use **`GridSearchCV`** to locate optimal tuning parameters by performing an \"exhaustive grid search\" of different parameter combinations, searching for the combination that has the best cross-validated accuracy.\n",
    "- By passing a **`Pipeline`** to **`GridSearchCV`** (instead of just a model), we can search tuning parameters for both the vectorizer and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['countvectorizer', 'multinomialnb'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline steps are automatically assigned names by make_pipeline\n",
    "pipe.named_steps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"],\n",
       " 'multinomialnb__alpha': [0.5, 1]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a grid of parameters to search (and specify the pipeline step along with the parameter)\n",
    "param_grid = {}\n",
    "param_grid['countvectorizer__token_pattern'] = [r\"\\b\\w\\w+\\b\", r\"'([a-z ]+)'\"]\n",
    "param_grid['multinomialnb__alpha'] = [0.5, 1]\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GridSearchCV documentation](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pipeline (instead of the model) to GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.4 s, sys: 494 ms, total: 34.8 s\n",
      "Wall time: 16.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('countvectorizer',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accen...\n",
       "                                                                      \"]+)'\",\n",
       "                                                        tokenizer=None,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('multinomialnb',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                            \"'([a-z ]+)'\"],\n",
       "                         'multinomialnb__alpha': [0.5, 1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time the grid search\n",
    "%time grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.68571405, 0.73354559, 0.53802452, 0.53402543]),\n",
       " 'std_fit_time': array([0.04993944, 0.0264956 , 0.02710726, 0.04987582]),\n",
       " 'mean_score_time': array([0.15376539, 0.15582905, 0.10774155, 0.10062079]),\n",
       " 'std_score_time': array([0.01728257, 0.00947986, 0.01431289, 0.00574068]),\n",
       " 'param_countvectorizer__token_pattern': masked_array(data=['\\\\b\\\\w\\\\w+\\\\b', '\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\",\n",
       "                    \"'([a-z ]+)'\"],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_multinomialnb__alpha': masked_array(data=[0.5, 1, 0.5, 1],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b',\n",
       "   'multinomialnb__alpha': 0.5},\n",
       "  {'countvectorizer__token_pattern': '\\\\b\\\\w\\\\w+\\\\b',\n",
       "   'multinomialnb__alpha': 1},\n",
       "  {'countvectorizer__token_pattern': \"'([a-z ]+)'\",\n",
       "   'multinomialnb__alpha': 0.5},\n",
       "  {'countvectorizer__token_pattern': \"'([a-z ]+)'\",\n",
       "   'multinomialnb__alpha': 1}],\n",
       " 'split0_test_score': array([0.72029641, 0.7206732 , 0.74328058, 0.72619945]),\n",
       " 'split1_test_score': array([0.73133953, 0.73133953, 0.75596884, 0.74114099]),\n",
       " 'split2_test_score': array([0.72121669, 0.71895425, 0.74509804, 0.72674711]),\n",
       " 'split3_test_score': array([0.72028676, 0.72016099, 0.74481197, 0.73261225]),\n",
       " 'split4_test_score': array([0.72794765, 0.72643765, 0.74933937, 0.73474267]),\n",
       " 'mean_test_score': array([0.72421683, 0.72351285, 0.7476995 , 0.73228742]),\n",
       " 'std_test_score': array([0.00457127, 0.00468854, 0.00459876, 0.00551981]),\n",
       " 'rank_test_score': array([3, 4, 1, 2], dtype=int32)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7476995021873586\n",
      "{'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.5}\n"
     ]
    }
   ],
   "source": [
    "# print the single best score and parameters that produced that score\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Efficiently searching for tuning parameters using `RandomizedSearchCV`\n",
    "\n",
    "- When there are many parameters to tune, searching all possible combinations of parameter values may be **computationally infeasible**.\n",
    "- **`RandomizedSearchCV`** searches a sample of the parameter values, and you control the computational \"budget\".\n",
    "\n",
    "[RandomizedSearchCV documentation](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.RandomizedSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scipy.stats documentation](http://docs.scipy.org/doc/scipy/reference/stats.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b', \"'([a-z ]+)'\"],\n",
       " 'countvectorizer__min_df': [1, 2, 3],\n",
       " 'multinomialnb__alpha': <scipy.stats._distn_infrastructure.rv_frozen at 0x110da3250>}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for any continuous parameters, specify a distribution instead of a list of options\n",
    "import scipy as sp\n",
    "param_grid = {}\n",
    "param_grid['countvectorizer__token_pattern'] = [r\"\\b\\w\\w+\\b\", r\"'([a-z ]+)'\"]\n",
    "param_grid['countvectorizer__min_df'] = [1, 2, 3]\n",
    "param_grid['multinomialnb__alpha'] = sp.stats.uniform(scale=1)\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a random seed for sp.stats.uniform\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional parameters are n_iter (number of searches) and random_state\n",
    "rand = RandomizedSearchCV(pipe, param_grid, cv=5, scoring='accuracy', n_iter=5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.2 s, sys: 519 ms, total: 40.7 s\n",
      "Wall time: 18.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=Pipeline(memory=None,\n",
       "                                      steps=[('countvectorizer',\n",
       "                                              CountVectorizer(analyzer='word',\n",
       "                                                              binary=False,\n",
       "                                                              decode_error='strict',\n",
       "                                                              dtype=<class 'numpy.int64'>,\n",
       "                                                              encoding='utf-8',\n",
       "                                                              input='content',\n",
       "                                                              lowercase=True,\n",
       "                                                              max_df=1.0,\n",
       "                                                              max_features=None,\n",
       "                                                              min_df=1,\n",
       "                                                              ngram_range=(1,\n",
       "                                                                           1),\n",
       "                                                              preprocessor=None,\n",
       "                                                              stop_words=None,\n",
       "                                                              strip...\n",
       "                                      verbose=False),\n",
       "                   iid='warn', n_iter=5, n_jobs=None,\n",
       "                   param_distributions={'countvectorizer__min_df': [1, 2, 3],\n",
       "                                        'countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                                           \"'([a-z \"\n",
       "                                                                           \"]+)'\"],\n",
       "                                        'multinomialnb__alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x110da3250>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
       "                   return_train_score=False, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time the randomized search\n",
    "%time rand.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.745436717453613\n",
      "{'countvectorizer__min_df': 2, 'countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.7203244934421581}\n"
     ]
    }
   ],
   "source": [
    "print(rand.best_score_)\n",
    "print(rand.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X_new as the ingredient text\n",
    "X_new = new.ingredients_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('countvectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=2,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "                                 vocabulary=None)),\n",
       "                ('multinomialnb',\n",
       "                 MultinomialNB(alpha=0.7203244934421581, class_prior=None,\n",
       "                               fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the best model found by RandomizedSearchCV\n",
    "rand.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['southern_us', 'southern_us', 'italian', ..., 'italian',\n",
       "       'southern_us', 'mexican'], dtype='<U12')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomizedSearchCV/GridSearchCV automatically refit the best model with the entire dataset, and can be used to make predictions\n",
    "new_pred_class_rand = rand.predict(X_new)\n",
    "new_pred_class_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a submission file (score: 0.75342)\n",
    "pd.DataFrame({'id':new.id, 'cuisine':new_pred_class_rand}).set_index('id').to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Adding features to a document-term matrix (using SciPy)\n",
    "\n",
    "- So far, we've trained models on either the **document-term matrix** or the **manually created features**, but not both.\n",
    "- To train a model on both types of features, we need to **combine them into a single feature matrix**.\n",
    "- Because one of the matrices is **sparse** and the other is **dense**, the easiest way to combine them is by using SciPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6250)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a document-term matrix from all of the training data\n",
    "X_dtm = vect.fit_transform(X)\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scipy.sparse documentation](http://docs.scipy.org/doc/scipy/reference/sparse.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of the manually created features\n",
    "X_manual = train.loc[:, ['num_ingredients', 'ingredient_length']]\n",
    "X_manual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a sparse matrix from the DataFrame\n",
    "X_manual_sparse = sp.sparse.csr_matrix(X_manual)\n",
    "type(X_manual_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6252)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine the two sparse matrices\n",
    "X_dtm_manual = sp.sparse.hstack([X_dtm, X_manual_sparse])\n",
    "X_dtm_manual.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This was a relatively easy process.\n",
    "- However, it does not allow us to do **proper cross-validation**, and it doesn't integrate well with the rest of the **scikit-learn workflow**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Adding features to a document-term matrix (using `FeatureUnion`)\n",
    "\n",
    "- Below is an alternative process that does allow for proper cross-validation, and does integrate well with the scikit-learn workflow.\n",
    "- To use this process, we have to learn about transformers, **`FunctionTransformer`**, and **`FeatureUnion`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are \"transformers\"?\n",
    "\n",
    "Transformer objects provide a `transform` method in order to perform **data transformations**. Here are a few examples:\n",
    "\n",
    "- **`CountVectorizer`**\n",
    "    - `fit` learns the vocabulary\n",
    "    - `transform` creates a document-term matrix using the vocabulary\n",
    "- **`Imputer`**\n",
    "    - `fit` learns the value to impute\n",
    "    - `transform` fills in missing entries using the imputation value\n",
    "- **`StandardScaler`**\n",
    "    - `fit` learns the mean and scale of each feature\n",
    "    - `transform` standardizes the features using the mean and scale\n",
    "- **`HashingVectorizer`**\n",
    "    - `fit` is not used, and thus it is known as a \"stateless\" transformer\n",
    "    - `transform` creates the document-term matrix using a hash of the token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting a function into a transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts a DataFrame returns the manually created features\n",
    "def get_manual(df):\n",
    "    return df.loc[:, ['num_ingredients', 'ingredient_length']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_ingredients  ingredient_length\n",
       "0                9          12.000000\n",
       "1               11          10.090909\n",
       "2               12          10.333333\n",
       "3                4           6.750000\n",
       "4               20          10.100000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_manual(train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[FunctionTransformer documentation](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html) (new in 0.17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.preprocessing._function_transformer.FunctionTransformer"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a stateless transformer from the get_manual function\n",
    "get_manual_ft = FunctionTransformer(get_manual, validate=False)\n",
    "type(get_manual_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_ingredients  ingredient_length\n",
       "0                9          12.000000\n",
       "1               11          10.090909\n",
       "2               12          10.333333\n",
       "3                4           6.750000\n",
       "4               20          10.100000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute the function using the transform method\n",
    "get_manual_ft.transform(train).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts a DataFrame returns the ingredients string\n",
    "def get_text(df):\n",
    "    return df.ingredients_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['romaine lettuce', 'black olives', 'grape tom...\n",
       "1    ['plain flour', 'ground pepper', 'salt', 'toma...\n",
       "2    ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...\n",
       "3          ['water', 'vegetable oil', 'wheat', 'salt']\n",
       "4    ['black pepper', 'shallots', 'cornflour', 'cay...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and test another transformer\n",
    "get_text_ft = FunctionTransformer(get_text, validate=False)\n",
    "get_text_ft.transform(train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining feature extraction steps\n",
    "\n",
    "- **`FeatureUnion`** applies a list of transformers in parallel to the input data (not sequentially), then **concatenates the results**.\n",
    "- This is useful for combining several feature extraction mechanisms into a single transformer.\n",
    "\n",
    "![Pipeline versus FeatureUnion](06_pipeline_versus_featureunion.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[make_union documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_union.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6250)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a document-term matrix from all of the training data\n",
    "X_dtm = vect.fit_transform(X)\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6250)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is identical to a FeatureUnion with just one transformer\n",
    "union = make_union(vect)\n",
    "X_dtm = union.fit_transform(X)\n",
    "X_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to add a second transformer to the Feature Union (what's wrong with this?)\n",
    "# union = make_union(vect, get_manual_ft)\n",
    "# X_dtm_manual = union.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39774, 6252)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# properly combine the transformers into a FeatureUnion\n",
    "union = make_union(make_pipeline(get_text_ft, vect), get_manual_ft)\n",
    "X_dtm_manual = union.fit_transform(train)\n",
    "X_dtm_manual.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pipeline in a FeatureUnion](06_pipeline_in_a_featureunion.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7102895106852953"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slightly improper cross-validation\n",
    "cross_val_score(nb, X_dtm_manual, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline of the FeatureUnion and Naive Bayes\n",
    "pipe = make_pipeline(union, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7134318388611878"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# properly cross-validate the entire pipeline (and pass it the entire DataFrame)\n",
    "cross_val_score(pipe, train, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative way to specify `Pipeline` and `FeatureUnion`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminder of how we created the pipeline\n",
    "union = make_union(make_pipeline(get_text_ft, vect), get_manual_ft)\n",
    "pipe = make_pipeline(union, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pipeline documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) and [FeatureUnion documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.FeatureUnion.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# duplicate the pipeline structure without using make_pipeline or make_union\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "pipe = Pipeline([\n",
    "    ('featureunion', FeatureUnion([\n",
    "            ('pipeline', Pipeline([\n",
    "                    ('functiontransformer', get_text_ft),\n",
    "                    ('countvectorizer', vect)\n",
    "                    ])),\n",
    "            ('functiontransformer', get_manual_ft)\n",
    "        ])),\n",
    "    ('multinomialnb', nb)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search of a nested `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('featureunion', FeatureUnion(n_jobs=None,\n",
       "               transformer_list=[('pipeline',\n",
       "                                  Pipeline(memory=None,\n",
       "                                           steps=[('functiontransformer',\n",
       "                                                   FunctionTransformer(accept_sparse=False,\n",
       "                                                                       check_inverse=True,\n",
       "                                                                       func=<function get_text at 0x1a2707e320>,\n",
       "                                                                       inv_kw_args=None,\n",
       "                                                                       inverse_func=None,\n",
       "                                                                       kw_args=None,\n",
       "                                                                       pass_y='deprecated',\n",
       "                                                                       validate=False)),\n",
       "                                                  ('countvectorizer',\n",
       "                                                   CountVectorizer(analyzer='word',\n",
       "                                                                   binary=Fals...\n",
       "                                                                   stop_words=None,\n",
       "                                                                   strip_accents=None,\n",
       "                                                                   token_pattern=\"'([a-z \"\n",
       "                                                                                 \"]+)'\",\n",
       "                                                                   tokenizer=None,\n",
       "                                                                   vocabulary=None))],\n",
       "                                           verbose=False)),\n",
       "                                 ('functiontransformer',\n",
       "                                  FunctionTransformer(accept_sparse=False,\n",
       "                                                      check_inverse=True,\n",
       "                                                      func=<function get_manual at 0x1a2705f8c0>,\n",
       "                                                      inv_kw_args=None,\n",
       "                                                      inverse_func=None,\n",
       "                                                      kw_args=None,\n",
       "                                                      pass_y='deprecated',\n",
       "                                                      validate=False))],\n",
       "               transformer_weights=None, verbose=False)),\n",
       " ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the pipeline steps\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'featureunion__pipeline__countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b',\n",
       "  \"'([a-z ]+)'\"],\n",
       " 'multinomialnb__alpha': [0.5, 1]}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a grid of parameters to search (and specify the pipeline step along with the parameter)\n",
    "param_grid = {}\n",
    "param_grid['featureunion__pipeline__countvectorizer__token_pattern'] = [r\"\\b\\w\\w+\\b\", r\"'([a-z ]+)'\"]\n",
    "param_grid['multinomialnb__alpha'] = [0.5, 1]\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.3 s, sys: 877 ms, total: 55.1 s\n",
      "Wall time: 15.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('featureunion',\n",
       "                                        FeatureUnion(n_jobs=None,\n",
       "                                                     transformer_list=[('pipeline',\n",
       "                                                                        Pipeline(memory=None,\n",
       "                                                                                 steps=[('functiontransformer',\n",
       "                                                                                         FunctionTransformer(accept_sparse=False,\n",
       "                                                                                                             check_inverse=True,\n",
       "                                                                                                             func=<function get_text at 0x1a2707e320>,\n",
       "                                                                                                             inv_kw_args=None,\n",
       "                                                                                                             inverse_func=None,\n",
       "                                                                                                             kw_args=...\n",
       "                                                     verbose=False)),\n",
       "                                       ('multinomialnb',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'featureunion__pipeline__countvectorizer__token_pattern': ['\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                                                    \"'([a-z \"\n",
       "                                                                                    \"]+)'\"],\n",
       "                         'multinomialnb__alpha': [0.5, 1]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time grid.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7426710916679238\n",
      "{'featureunion__pipeline__countvectorizer__token_pattern': \"'([a-z ]+)'\", 'multinomialnb__alpha': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: Ensembling models\n",
    "\n",
    "Rather than combining features into a single feature matrix and training a single model, we can instead create separate models and \"ensemble\" them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is ensembling?\n",
    "\n",
    "Ensemble learning (or \"ensembling\") is the process of combining several predictive models in order to produce a combined model that is **better than any individual model**.\n",
    "\n",
    "- **Regression:** average the predictions made by the individual models\n",
    "- **Classification:** let the models \"vote\" and use the most common prediction, or average the predicted probabilities\n",
    "\n",
    "For ensembling to work well, the models must have the following characteristics:\n",
    "\n",
    "- **Accurate:** they outperform the null model\n",
    "- **Independent:** their predictions are generated using different \"processes\", such as:\n",
    "    - different types of models\n",
    "    - different features\n",
    "    - different tuning parameters\n",
    "\n",
    "**The big idea:** If you have a collection of individually imperfect (and independent) models, the \"one-off\" mistakes made by each model are probably not going to be made by the rest of the models, and thus the mistakes will be discarded when averaging the models.\n",
    "\n",
    "**Note:** There are also models that have built-in ensembling, such as Random Forests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1: KNN model using only manually created features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "feature_cols = ['num_ingredients', 'ingredient_length']\n",
    "X = train[feature_cols]\n",
    "y = train.cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use KNN with K=800\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=800, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train KNN on all of the training data\n",
    "knn.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X_new as the manually created features\n",
    "X_new = new[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944, 20)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities of class membership for the new data\n",
    "new_pred_prob_knn = knn.predict_proba(X_new)\n",
    "new_pred_prob_knn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02625, 0.0275 , 0.01375, 0.04375, 0.03375, 0.08   , 0.0175 ,\n",
       "       0.075  , 0.0275 , 0.135  , 0.01   , 0.075  , 0.01875, 0.165  ,\n",
       "       0.00875, 0.0125 , 0.1525 , 0.025  , 0.0275 , 0.025  ])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print predicted probabilities for the first row only\n",
    "new_pred_prob_knn[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x1a278d83c0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display classes with probabilities\n",
    "zip(knn.classes_, new_pred_prob_knn[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predicted probabilities will sum to 1 for each row\n",
    "new_pred_prob_knn[0, :].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: Naive Bayes model using only text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('countvectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=2,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern=\"'([a-z ]+)'\", tokenizer=None,\n",
       "                                 vocabulary=None)),\n",
       "                ('multinomialnb',\n",
       "                 MultinomialNB(alpha=0.7203244934421581, class_prior=None,\n",
       "                               fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the best model found by RandomizedSearchCV\n",
    "rand.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X_new as the ingredient text\n",
    "X_new = new.ingredients_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9944, 20)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate predicted probabilities of class membership for the new data\n",
    "new_pred_prob_rand = rand.predict_proba(X_new)\n",
    "new_pred_prob_rand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.59476986e-04, 4.04209227e-01, 7.38375500e-05, 1.29657196e-04,\n",
       "       3.00331358e-03, 2.09215451e-03, 4.82924358e-04, 5.35343905e-04,\n",
       "       1.22359513e-01, 7.08319855e-03, 2.06222706e-04, 7.18742744e-04,\n",
       "       5.49904762e-06, 1.64352345e-03, 1.01157435e-05, 1.71202022e-02,\n",
       "       4.39643190e-01, 3.21357119e-04, 1.84691815e-06, 6.53184216e-07])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print predicted probabilities for the first row only\n",
    "new_pred_prob_rand[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensembling models 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01330474, 0.21585461, 0.00691192, 0.02193983, 0.01837666,\n",
       "       0.04104608, 0.00899146, 0.03776767, 0.07492976, 0.0710416 ,\n",
       "       0.00510311, 0.03785937, 0.00937775, 0.08332176, 0.00438006,\n",
       "       0.0148101 , 0.2960716 , 0.01266068, 0.01375092, 0.01250033])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean of the predicted probabilities for the first row\n",
    "(new_pred_prob_knn[0, :] + new_pred_prob_rand[0, :]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brazilian</th>\n",
       "      <th>british</th>\n",
       "      <th>cajun_creole</th>\n",
       "      <th>chinese</th>\n",
       "      <th>filipino</th>\n",
       "      <th>french</th>\n",
       "      <th>greek</th>\n",
       "      <th>indian</th>\n",
       "      <th>irish</th>\n",
       "      <th>italian</th>\n",
       "      <th>jamaican</th>\n",
       "      <th>japanese</th>\n",
       "      <th>korean</th>\n",
       "      <th>mexican</th>\n",
       "      <th>moroccan</th>\n",
       "      <th>russian</th>\n",
       "      <th>southern_us</th>\n",
       "      <th>spanish</th>\n",
       "      <th>thai</th>\n",
       "      <th>vietnamese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013305</td>\n",
       "      <td>0.215855</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>0.02194</td>\n",
       "      <td>0.018377</td>\n",
       "      <td>0.041046</td>\n",
       "      <td>0.008991</td>\n",
       "      <td>0.037768</td>\n",
       "      <td>0.074930</td>\n",
       "      <td>0.071042</td>\n",
       "      <td>0.005103</td>\n",
       "      <td>0.037859</td>\n",
       "      <td>0.009378</td>\n",
       "      <td>0.083322</td>\n",
       "      <td>0.004380</td>\n",
       "      <td>0.014810</td>\n",
       "      <td>0.296072</td>\n",
       "      <td>0.012661</td>\n",
       "      <td>0.013751</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.011794</td>\n",
       "      <td>0.016875</td>\n",
       "      <td>0.04500</td>\n",
       "      <td>0.018143</td>\n",
       "      <td>0.024328</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.046250</td>\n",
       "      <td>0.010630</td>\n",
       "      <td>0.070625</td>\n",
       "      <td>0.005626</td>\n",
       "      <td>0.027503</td>\n",
       "      <td>0.021875</td>\n",
       "      <td>0.066875</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.008751</td>\n",
       "      <td>0.546973</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.025625</td>\n",
       "      <td>0.013125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013627</td>\n",
       "      <td>0.009447</td>\n",
       "      <td>0.007219</td>\n",
       "      <td>0.02000</td>\n",
       "      <td>0.015059</td>\n",
       "      <td>0.045080</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>0.029383</td>\n",
       "      <td>0.013628</td>\n",
       "      <td>0.449318</td>\n",
       "      <td>0.005651</td>\n",
       "      <td>0.038760</td>\n",
       "      <td>0.007505</td>\n",
       "      <td>0.080644</td>\n",
       "      <td>0.024697</td>\n",
       "      <td>0.008373</td>\n",
       "      <td>0.079388</td>\n",
       "      <td>0.112301</td>\n",
       "      <td>0.015626</td>\n",
       "      <td>0.012510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.004375</td>\n",
       "      <td>0.533750</td>\n",
       "      <td>0.03875</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.023125</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.075625</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.051875</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.008125</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.029375</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.038125</td>\n",
       "      <td>0.027500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001877</td>\n",
       "      <td>0.009598</td>\n",
       "      <td>0.020083</td>\n",
       "      <td>0.02125</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>0.045360</td>\n",
       "      <td>0.017502</td>\n",
       "      <td>0.013750</td>\n",
       "      <td>0.012539</td>\n",
       "      <td>0.640831</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.083130</td>\n",
       "      <td>0.004377</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.072734</td>\n",
       "      <td>0.018206</td>\n",
       "      <td>0.014375</td>\n",
       "      <td>0.003125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brazilian   british  cajun_creole  chinese  filipino    french     greek  \\\n",
       "0   0.013305  0.215855      0.006912  0.02194  0.018377  0.041046  0.008991   \n",
       "1   0.008752  0.011794      0.016875  0.04500  0.018143  0.024328  0.015625   \n",
       "2   0.013627  0.009447      0.007219  0.02000  0.015059  0.045080  0.011783   \n",
       "3   0.003125  0.004375      0.533750  0.03875  0.001875  0.023125  0.006250   \n",
       "4   0.001877  0.009598      0.020083  0.02125  0.003126  0.045360  0.017502   \n",
       "\n",
       "     indian     irish   italian  jamaican  japanese    korean   mexican  \\\n",
       "0  0.037768  0.074930  0.071042  0.005103  0.037859  0.009378  0.083322   \n",
       "1  0.046250  0.010630  0.070625  0.005626  0.027503  0.021875  0.066875   \n",
       "2  0.029383  0.013628  0.449318  0.005651  0.038760  0.007505  0.080644   \n",
       "3  0.075625  0.001250  0.051875  0.011875  0.008125  0.003125  0.107500   \n",
       "4  0.013750  0.012539  0.640831  0.003754  0.007500  0.003750  0.083130   \n",
       "\n",
       "   moroccan   russian  southern_us   spanish      thai  vietnamese  \n",
       "0  0.004380  0.014810     0.296072  0.012661  0.013751    0.012500  \n",
       "1  0.008125  0.008751     0.546973  0.007500  0.025625    0.013125  \n",
       "2  0.024697  0.008373     0.079388  0.112301  0.015626    0.012510  \n",
       "3  0.029375  0.001875     0.025000  0.007500  0.038125    0.027500  \n",
       "4  0.004377  0.003133     0.072734  0.018206  0.014375    0.003125  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean of the predicted probabilities for all rows\n",
    "new_pred_prob = pd.DataFrame((new_pred_prob_knn + new_pred_prob_rand) / 2, columns=knn.classes_)\n",
    "new_pred_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tensorflow/lib/python3.7/site-packages/numpy/core/fromnumeric.py:61: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     southern_us\n",
       "1     southern_us\n",
       "2         italian\n",
       "3    cajun_creole\n",
       "4         italian\n",
       "dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each row, find the column with the highest predicted probability\n",
    "new_pred_class = new_pred_prob.apply(np.argmax, axis=1)\n",
    "new_pred_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a submission file (score: 0.75241)\n",
    "pd.DataFrame({'id':new.id, 'cuisine':new_pred_class}).set_index('id').to_csv('submission4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** [VotingClassifier](http://scikit-learn.org/stable/modules/ensemble.html#votingclassifier) (new in 0.17) makes it easier to ensemble classifiers, though it is limited to the case in which all of the classifiers are fit to the same data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 8: Locating groups of similar cuisines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cuisine\n",
       "brazilian       ['ice cubes', 'club soda', 'white rum', 'lime'...\n",
       "british         ['greek yogurt', 'lemon curd', 'confectioners ...\n",
       "cajun_creole    ['herbs', 'lemon juice', 'fresh tomatoes', 'pa...\n",
       "chinese         ['low sodium soy sauce', 'fresh ginger', 'dry ...\n",
       "filipino        ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...\n",
       "french          ['sugar', 'salt', 'fennel bulb', 'water', 'lem...\n",
       "greek           ['romaine lettuce', 'black olives', 'grape tom...\n",
       "indian          ['water', 'vegetable oil', 'wheat', 'salt']['b...\n",
       "irish           ['cooking spray', 'salt', 'black pepper', 'yuk...\n",
       "italian         ['sugar', 'pistachio nuts', 'white almond bark...\n",
       "jamaican        ['plain flour', 'sugar', 'butter', 'eggs', 'fr...\n",
       "japanese        ['sirloin', 'mirin', 'yellow onion', 'low sodi...\n",
       "korean          ['jasmine rice', 'garlic', 'scallions', 'sugar...\n",
       "mexican         ['olive oil', 'purple onion', 'fresh pineapple...\n",
       "moroccan        ['ground cloves', 'whole nutmegs', 'ground gin...\n",
       "russian         ['water', 'grits', 'mozzarella cheese', 'salt'...\n",
       "southern_us     ['plain flour', 'ground pepper', 'salt', 'toma...\n",
       "spanish         ['olive oil', 'salt', 'medium shrimp', 'pepper...\n",
       "thai            ['sugar', 'hot chili', 'asian fish sauce', 'li...\n",
       "vietnamese      ['soy sauce', 'vegetable oil', 'red bell peppe...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each cuisine, combine all of the recipes into a single string\n",
    "cuisine_ingredients = train.groupby('cuisine').ingredients_str.sum()\n",
    "cuisine_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['ice cubes', 'club soda', 'white rum', 'lime', 'turbinado']['eggs', 'hearts of palm', 'cilantro', 'coconut cream', 'flax seed meal', 'kosher salt', 'jalapeno chilies', 'garlic', 'cream cheese, soften', 'coconut oil', 'lime juice', 'crushed red pepper flakes', 'ground coriander', 'pepper', 'chicken breasts', 'coconut flour', 'onions']['sweetened condensed milk', 'butter', 'cocoa powder']['lime', 'crushed ice', 'simple syrup', 'cachaca']['sugar', 'corn starch', 'egg whites', 'boiling water', 'col\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the brazilian ingredients\n",
    "cuisine_ingredients['brazilian'][0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41     ['ice cubes', 'club soda', 'white rum', 'lime'...\n",
       "380    ['eggs', 'hearts of palm', 'cilantro', 'coconu...\n",
       "423    ['sweetened condensed milk', 'butter', 'cocoa ...\n",
       "509    ['lime', 'crushed ice', 'simple syrup', 'cacha...\n",
       "724    ['sugar', 'corn starch', 'egg whites', 'boilin...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that they match the brazilian recipes\n",
    "train.loc[train.cuisine=='brazilian', 'ingredients_str'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 3010)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a document-term matrix from cuisine_ingredients\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n",
    "cuisine_dtm = vect.fit_transform(cuisine_ingredients)\n",
    "cuisine_dtm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[How to calculate document similarity](http://stackoverflow.com/questions/12118720/python-tf-idf-cosine-to-find-document-similarity/12128777#12128777) (Stack Overflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the cosine similarity between each cuisine and all other cuisines\n",
    "from sklearn import metrics\n",
    "cuisine_similarity = []\n",
    "for idx in range(cuisine_dtm.shape[0]):\n",
    "    similarity = metrics.pairwise.linear_kernel(cuisine_dtm[idx, :], cuisine_dtm).flatten()\n",
    "    cuisine_similarity.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>cuisine</th>\n",
       "      <th>brazilian</th>\n",
       "      <th>british</th>\n",
       "      <th>cajun_creole</th>\n",
       "      <th>chinese</th>\n",
       "      <th>filipino</th>\n",
       "      <th>french</th>\n",
       "      <th>greek</th>\n",
       "      <th>indian</th>\n",
       "      <th>irish</th>\n",
       "      <th>italian</th>\n",
       "      <th>jamaican</th>\n",
       "      <th>japanese</th>\n",
       "      <th>korean</th>\n",
       "      <th>mexican</th>\n",
       "      <th>moroccan</th>\n",
       "      <th>russian</th>\n",
       "      <th>southern_us</th>\n",
       "      <th>spanish</th>\n",
       "      <th>thai</th>\n",
       "      <th>vietnamese</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cuisine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>brazilian</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660232</td>\n",
       "      <td>0.742324</td>\n",
       "      <td>0.580756</td>\n",
       "      <td>0.769216</td>\n",
       "      <td>0.756392</td>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.687271</td>\n",
       "      <td>0.665713</td>\n",
       "      <td>0.740527</td>\n",
       "      <td>0.778320</td>\n",
       "      <td>0.555601</td>\n",
       "      <td>0.571440</td>\n",
       "      <td>0.743736</td>\n",
       "      <td>0.669009</td>\n",
       "      <td>0.706087</td>\n",
       "      <td>0.743156</td>\n",
       "      <td>0.807694</td>\n",
       "      <td>0.685539</td>\n",
       "      <td>0.653801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>british</th>\n",
       "      <td>0.660232</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.591230</td>\n",
       "      <td>0.467640</td>\n",
       "      <td>0.631356</td>\n",
       "      <td>0.859609</td>\n",
       "      <td>0.562750</td>\n",
       "      <td>0.560349</td>\n",
       "      <td>0.926682</td>\n",
       "      <td>0.632618</td>\n",
       "      <td>0.662057</td>\n",
       "      <td>0.508296</td>\n",
       "      <td>0.447177</td>\n",
       "      <td>0.560446</td>\n",
       "      <td>0.543260</td>\n",
       "      <td>0.909551</td>\n",
       "      <td>0.911271</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>0.445518</td>\n",
       "      <td>0.478901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cajun_creole</th>\n",
       "      <td>0.742324</td>\n",
       "      <td>0.591230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.605581</td>\n",
       "      <td>0.746151</td>\n",
       "      <td>0.708849</td>\n",
       "      <td>0.688391</td>\n",
       "      <td>0.618955</td>\n",
       "      <td>0.635197</td>\n",
       "      <td>0.738159</td>\n",
       "      <td>0.780897</td>\n",
       "      <td>0.532394</td>\n",
       "      <td>0.578645</td>\n",
       "      <td>0.724877</td>\n",
       "      <td>0.649831</td>\n",
       "      <td>0.657802</td>\n",
       "      <td>0.747480</td>\n",
       "      <td>0.803637</td>\n",
       "      <td>0.590103</td>\n",
       "      <td>0.605224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>0.580756</td>\n",
       "      <td>0.467640</td>\n",
       "      <td>0.605581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.839803</td>\n",
       "      <td>0.540446</td>\n",
       "      <td>0.496090</td>\n",
       "      <td>0.553532</td>\n",
       "      <td>0.460746</td>\n",
       "      <td>0.555504</td>\n",
       "      <td>0.635953</td>\n",
       "      <td>0.835587</td>\n",
       "      <td>0.866828</td>\n",
       "      <td>0.561837</td>\n",
       "      <td>0.505655</td>\n",
       "      <td>0.521844</td>\n",
       "      <td>0.558514</td>\n",
       "      <td>0.603526</td>\n",
       "      <td>0.755813</td>\n",
       "      <td>0.817005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filipino</th>\n",
       "      <td>0.769216</td>\n",
       "      <td>0.631356</td>\n",
       "      <td>0.746151</td>\n",
       "      <td>0.839803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.682939</td>\n",
       "      <td>0.607436</td>\n",
       "      <td>0.655934</td>\n",
       "      <td>0.641010</td>\n",
       "      <td>0.670628</td>\n",
       "      <td>0.792723</td>\n",
       "      <td>0.748558</td>\n",
       "      <td>0.782623</td>\n",
       "      <td>0.678302</td>\n",
       "      <td>0.614984</td>\n",
       "      <td>0.697000</td>\n",
       "      <td>0.720368</td>\n",
       "      <td>0.727409</td>\n",
       "      <td>0.741512</td>\n",
       "      <td>0.806833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>french</th>\n",
       "      <td>0.756392</td>\n",
       "      <td>0.859609</td>\n",
       "      <td>0.708849</td>\n",
       "      <td>0.540446</td>\n",
       "      <td>0.682939</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759936</td>\n",
       "      <td>0.624868</td>\n",
       "      <td>0.837384</td>\n",
       "      <td>0.835272</td>\n",
       "      <td>0.723225</td>\n",
       "      <td>0.540279</td>\n",
       "      <td>0.502205</td>\n",
       "      <td>0.666830</td>\n",
       "      <td>0.685384</td>\n",
       "      <td>0.881173</td>\n",
       "      <td>0.862062</td>\n",
       "      <td>0.817541</td>\n",
       "      <td>0.548375</td>\n",
       "      <td>0.570925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greek</th>\n",
       "      <td>0.695692</td>\n",
       "      <td>0.562750</td>\n",
       "      <td>0.688391</td>\n",
       "      <td>0.496090</td>\n",
       "      <td>0.607436</td>\n",
       "      <td>0.759936</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.640297</td>\n",
       "      <td>0.583675</td>\n",
       "      <td>0.859270</td>\n",
       "      <td>0.681281</td>\n",
       "      <td>0.469465</td>\n",
       "      <td>0.479835</td>\n",
       "      <td>0.696644</td>\n",
       "      <td>0.769412</td>\n",
       "      <td>0.649530</td>\n",
       "      <td>0.641229</td>\n",
       "      <td>0.837448</td>\n",
       "      <td>0.519004</td>\n",
       "      <td>0.538683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>indian</th>\n",
       "      <td>0.687271</td>\n",
       "      <td>0.560349</td>\n",
       "      <td>0.618955</td>\n",
       "      <td>0.553532</td>\n",
       "      <td>0.655934</td>\n",
       "      <td>0.624868</td>\n",
       "      <td>0.640297</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577338</td>\n",
       "      <td>0.616211</td>\n",
       "      <td>0.734926</td>\n",
       "      <td>0.567993</td>\n",
       "      <td>0.538853</td>\n",
       "      <td>0.708621</td>\n",
       "      <td>0.795271</td>\n",
       "      <td>0.607432</td>\n",
       "      <td>0.617278</td>\n",
       "      <td>0.678865</td>\n",
       "      <td>0.627460</td>\n",
       "      <td>0.605162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irish</th>\n",
       "      <td>0.665713</td>\n",
       "      <td>0.926682</td>\n",
       "      <td>0.635197</td>\n",
       "      <td>0.460746</td>\n",
       "      <td>0.641010</td>\n",
       "      <td>0.837384</td>\n",
       "      <td>0.583675</td>\n",
       "      <td>0.577338</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.649878</td>\n",
       "      <td>0.680914</td>\n",
       "      <td>0.494762</td>\n",
       "      <td>0.458798</td>\n",
       "      <td>0.591718</td>\n",
       "      <td>0.563303</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.902850</td>\n",
       "      <td>0.630921</td>\n",
       "      <td>0.449931</td>\n",
       "      <td>0.481712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>italian</th>\n",
       "      <td>0.740527</td>\n",
       "      <td>0.632618</td>\n",
       "      <td>0.738159</td>\n",
       "      <td>0.555504</td>\n",
       "      <td>0.670628</td>\n",
       "      <td>0.835272</td>\n",
       "      <td>0.859270</td>\n",
       "      <td>0.616211</td>\n",
       "      <td>0.649878</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695768</td>\n",
       "      <td>0.510280</td>\n",
       "      <td>0.522568</td>\n",
       "      <td>0.733959</td>\n",
       "      <td>0.709827</td>\n",
       "      <td>0.697593</td>\n",
       "      <td>0.718945</td>\n",
       "      <td>0.858166</td>\n",
       "      <td>0.555088</td>\n",
       "      <td>0.571096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jamaican</th>\n",
       "      <td>0.778320</td>\n",
       "      <td>0.662057</td>\n",
       "      <td>0.780897</td>\n",
       "      <td>0.635953</td>\n",
       "      <td>0.792723</td>\n",
       "      <td>0.723225</td>\n",
       "      <td>0.681281</td>\n",
       "      <td>0.734926</td>\n",
       "      <td>0.680914</td>\n",
       "      <td>0.695768</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.584689</td>\n",
       "      <td>0.609203</td>\n",
       "      <td>0.731859</td>\n",
       "      <td>0.757462</td>\n",
       "      <td>0.684492</td>\n",
       "      <td>0.752862</td>\n",
       "      <td>0.751672</td>\n",
       "      <td>0.650898</td>\n",
       "      <td>0.664175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>japanese</th>\n",
       "      <td>0.555601</td>\n",
       "      <td>0.508296</td>\n",
       "      <td>0.532394</td>\n",
       "      <td>0.835587</td>\n",
       "      <td>0.748558</td>\n",
       "      <td>0.540279</td>\n",
       "      <td>0.469465</td>\n",
       "      <td>0.567993</td>\n",
       "      <td>0.494762</td>\n",
       "      <td>0.510280</td>\n",
       "      <td>0.584689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.819828</td>\n",
       "      <td>0.506539</td>\n",
       "      <td>0.477401</td>\n",
       "      <td>0.557275</td>\n",
       "      <td>0.554022</td>\n",
       "      <td>0.547336</td>\n",
       "      <td>0.682604</td>\n",
       "      <td>0.738413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean</th>\n",
       "      <td>0.571440</td>\n",
       "      <td>0.447177</td>\n",
       "      <td>0.578645</td>\n",
       "      <td>0.866828</td>\n",
       "      <td>0.782623</td>\n",
       "      <td>0.502205</td>\n",
       "      <td>0.479835</td>\n",
       "      <td>0.538853</td>\n",
       "      <td>0.458798</td>\n",
       "      <td>0.522568</td>\n",
       "      <td>0.609203</td>\n",
       "      <td>0.819828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.516461</td>\n",
       "      <td>0.477964</td>\n",
       "      <td>0.517680</td>\n",
       "      <td>0.516811</td>\n",
       "      <td>0.582969</td>\n",
       "      <td>0.671054</td>\n",
       "      <td>0.747119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mexican</th>\n",
       "      <td>0.743736</td>\n",
       "      <td>0.560446</td>\n",
       "      <td>0.724877</td>\n",
       "      <td>0.561837</td>\n",
       "      <td>0.678302</td>\n",
       "      <td>0.666830</td>\n",
       "      <td>0.696644</td>\n",
       "      <td>0.708621</td>\n",
       "      <td>0.591718</td>\n",
       "      <td>0.733959</td>\n",
       "      <td>0.731859</td>\n",
       "      <td>0.506539</td>\n",
       "      <td>0.516461</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.697442</td>\n",
       "      <td>0.630541</td>\n",
       "      <td>0.691398</td>\n",
       "      <td>0.739874</td>\n",
       "      <td>0.617627</td>\n",
       "      <td>0.623531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moroccan</th>\n",
       "      <td>0.669009</td>\n",
       "      <td>0.543260</td>\n",
       "      <td>0.649831</td>\n",
       "      <td>0.505655</td>\n",
       "      <td>0.614984</td>\n",
       "      <td>0.685384</td>\n",
       "      <td>0.769412</td>\n",
       "      <td>0.795271</td>\n",
       "      <td>0.563303</td>\n",
       "      <td>0.709827</td>\n",
       "      <td>0.757462</td>\n",
       "      <td>0.477401</td>\n",
       "      <td>0.477964</td>\n",
       "      <td>0.697442</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.608343</td>\n",
       "      <td>0.605958</td>\n",
       "      <td>0.784612</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>0.553375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>russian</th>\n",
       "      <td>0.706087</td>\n",
       "      <td>0.909551</td>\n",
       "      <td>0.657802</td>\n",
       "      <td>0.521844</td>\n",
       "      <td>0.697000</td>\n",
       "      <td>0.881173</td>\n",
       "      <td>0.649530</td>\n",
       "      <td>0.607432</td>\n",
       "      <td>0.892428</td>\n",
       "      <td>0.697593</td>\n",
       "      <td>0.684492</td>\n",
       "      <td>0.557275</td>\n",
       "      <td>0.517680</td>\n",
       "      <td>0.630541</td>\n",
       "      <td>0.608343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.877901</td>\n",
       "      <td>0.702752</td>\n",
       "      <td>0.494331</td>\n",
       "      <td>0.539100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>southern_us</th>\n",
       "      <td>0.743156</td>\n",
       "      <td>0.911271</td>\n",
       "      <td>0.747480</td>\n",
       "      <td>0.558514</td>\n",
       "      <td>0.720368</td>\n",
       "      <td>0.862062</td>\n",
       "      <td>0.641229</td>\n",
       "      <td>0.617278</td>\n",
       "      <td>0.902850</td>\n",
       "      <td>0.718945</td>\n",
       "      <td>0.752862</td>\n",
       "      <td>0.554022</td>\n",
       "      <td>0.516811</td>\n",
       "      <td>0.691398</td>\n",
       "      <td>0.605958</td>\n",
       "      <td>0.877901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.707774</td>\n",
       "      <td>0.536965</td>\n",
       "      <td>0.562359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spanish</th>\n",
       "      <td>0.807694</td>\n",
       "      <td>0.604000</td>\n",
       "      <td>0.803637</td>\n",
       "      <td>0.603526</td>\n",
       "      <td>0.727409</td>\n",
       "      <td>0.817541</td>\n",
       "      <td>0.837448</td>\n",
       "      <td>0.678865</td>\n",
       "      <td>0.630921</td>\n",
       "      <td>0.858166</td>\n",
       "      <td>0.751672</td>\n",
       "      <td>0.547336</td>\n",
       "      <td>0.582969</td>\n",
       "      <td>0.739874</td>\n",
       "      <td>0.784612</td>\n",
       "      <td>0.702752</td>\n",
       "      <td>0.707774</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606200</td>\n",
       "      <td>0.614200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thai</th>\n",
       "      <td>0.685539</td>\n",
       "      <td>0.445518</td>\n",
       "      <td>0.590103</td>\n",
       "      <td>0.755813</td>\n",
       "      <td>0.741512</td>\n",
       "      <td>0.548375</td>\n",
       "      <td>0.519004</td>\n",
       "      <td>0.627460</td>\n",
       "      <td>0.449931</td>\n",
       "      <td>0.555088</td>\n",
       "      <td>0.650898</td>\n",
       "      <td>0.682604</td>\n",
       "      <td>0.671054</td>\n",
       "      <td>0.617627</td>\n",
       "      <td>0.533128</td>\n",
       "      <td>0.494331</td>\n",
       "      <td>0.536965</td>\n",
       "      <td>0.606200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vietnamese</th>\n",
       "      <td>0.653801</td>\n",
       "      <td>0.478901</td>\n",
       "      <td>0.605224</td>\n",
       "      <td>0.817005</td>\n",
       "      <td>0.806833</td>\n",
       "      <td>0.570925</td>\n",
       "      <td>0.538683</td>\n",
       "      <td>0.605162</td>\n",
       "      <td>0.481712</td>\n",
       "      <td>0.571096</td>\n",
       "      <td>0.664175</td>\n",
       "      <td>0.738413</td>\n",
       "      <td>0.747119</td>\n",
       "      <td>0.623531</td>\n",
       "      <td>0.553375</td>\n",
       "      <td>0.539100</td>\n",
       "      <td>0.562359</td>\n",
       "      <td>0.614200</td>\n",
       "      <td>0.914986</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "cuisine       brazilian   british  cajun_creole   chinese  filipino    french  \\\n",
       "cuisine                                                                         \n",
       "brazilian      1.000000  0.660232      0.742324  0.580756  0.769216  0.756392   \n",
       "british        0.660232  1.000000      0.591230  0.467640  0.631356  0.859609   \n",
       "cajun_creole   0.742324  0.591230      1.000000  0.605581  0.746151  0.708849   \n",
       "chinese        0.580756  0.467640      0.605581  1.000000  0.839803  0.540446   \n",
       "filipino       0.769216  0.631356      0.746151  0.839803  1.000000  0.682939   \n",
       "french         0.756392  0.859609      0.708849  0.540446  0.682939  1.000000   \n",
       "greek          0.695692  0.562750      0.688391  0.496090  0.607436  0.759936   \n",
       "indian         0.687271  0.560349      0.618955  0.553532  0.655934  0.624868   \n",
       "irish          0.665713  0.926682      0.635197  0.460746  0.641010  0.837384   \n",
       "italian        0.740527  0.632618      0.738159  0.555504  0.670628  0.835272   \n",
       "jamaican       0.778320  0.662057      0.780897  0.635953  0.792723  0.723225   \n",
       "japanese       0.555601  0.508296      0.532394  0.835587  0.748558  0.540279   \n",
       "korean         0.571440  0.447177      0.578645  0.866828  0.782623  0.502205   \n",
       "mexican        0.743736  0.560446      0.724877  0.561837  0.678302  0.666830   \n",
       "moroccan       0.669009  0.543260      0.649831  0.505655  0.614984  0.685384   \n",
       "russian        0.706087  0.909551      0.657802  0.521844  0.697000  0.881173   \n",
       "southern_us    0.743156  0.911271      0.747480  0.558514  0.720368  0.862062   \n",
       "spanish        0.807694  0.604000      0.803637  0.603526  0.727409  0.817541   \n",
       "thai           0.685539  0.445518      0.590103  0.755813  0.741512  0.548375   \n",
       "vietnamese     0.653801  0.478901      0.605224  0.817005  0.806833  0.570925   \n",
       "\n",
       "cuisine          greek    indian     irish   italian  jamaican  japanese  \\\n",
       "cuisine                                                                    \n",
       "brazilian     0.695692  0.687271  0.665713  0.740527  0.778320  0.555601   \n",
       "british       0.562750  0.560349  0.926682  0.632618  0.662057  0.508296   \n",
       "cajun_creole  0.688391  0.618955  0.635197  0.738159  0.780897  0.532394   \n",
       "chinese       0.496090  0.553532  0.460746  0.555504  0.635953  0.835587   \n",
       "filipino      0.607436  0.655934  0.641010  0.670628  0.792723  0.748558   \n",
       "french        0.759936  0.624868  0.837384  0.835272  0.723225  0.540279   \n",
       "greek         1.000000  0.640297  0.583675  0.859270  0.681281  0.469465   \n",
       "indian        0.640297  1.000000  0.577338  0.616211  0.734926  0.567993   \n",
       "irish         0.583675  0.577338  1.000000  0.649878  0.680914  0.494762   \n",
       "italian       0.859270  0.616211  0.649878  1.000000  0.695768  0.510280   \n",
       "jamaican      0.681281  0.734926  0.680914  0.695768  1.000000  0.584689   \n",
       "japanese      0.469465  0.567993  0.494762  0.510280  0.584689  1.000000   \n",
       "korean        0.479835  0.538853  0.458798  0.522568  0.609203  0.819828   \n",
       "mexican       0.696644  0.708621  0.591718  0.733959  0.731859  0.506539   \n",
       "moroccan      0.769412  0.795271  0.563303  0.709827  0.757462  0.477401   \n",
       "russian       0.649530  0.607432  0.892428  0.697593  0.684492  0.557275   \n",
       "southern_us   0.641229  0.617278  0.902850  0.718945  0.752862  0.554022   \n",
       "spanish       0.837448  0.678865  0.630921  0.858166  0.751672  0.547336   \n",
       "thai          0.519004  0.627460  0.449931  0.555088  0.650898  0.682604   \n",
       "vietnamese    0.538683  0.605162  0.481712  0.571096  0.664175  0.738413   \n",
       "\n",
       "cuisine         korean   mexican  moroccan   russian  southern_us   spanish  \\\n",
       "cuisine                                                                       \n",
       "brazilian     0.571440  0.743736  0.669009  0.706087     0.743156  0.807694   \n",
       "british       0.447177  0.560446  0.543260  0.909551     0.911271  0.604000   \n",
       "cajun_creole  0.578645  0.724877  0.649831  0.657802     0.747480  0.803637   \n",
       "chinese       0.866828  0.561837  0.505655  0.521844     0.558514  0.603526   \n",
       "filipino      0.782623  0.678302  0.614984  0.697000     0.720368  0.727409   \n",
       "french        0.502205  0.666830  0.685384  0.881173     0.862062  0.817541   \n",
       "greek         0.479835  0.696644  0.769412  0.649530     0.641229  0.837448   \n",
       "indian        0.538853  0.708621  0.795271  0.607432     0.617278  0.678865   \n",
       "irish         0.458798  0.591718  0.563303  0.892428     0.902850  0.630921   \n",
       "italian       0.522568  0.733959  0.709827  0.697593     0.718945  0.858166   \n",
       "jamaican      0.609203  0.731859  0.757462  0.684492     0.752862  0.751672   \n",
       "japanese      0.819828  0.506539  0.477401  0.557275     0.554022  0.547336   \n",
       "korean        1.000000  0.516461  0.477964  0.517680     0.516811  0.582969   \n",
       "mexican       0.516461  1.000000  0.697442  0.630541     0.691398  0.739874   \n",
       "moroccan      0.477964  0.697442  1.000000  0.608343     0.605958  0.784612   \n",
       "russian       0.517680  0.630541  0.608343  1.000000     0.877901  0.702752   \n",
       "southern_us   0.516811  0.691398  0.605958  0.877901     1.000000  0.707774   \n",
       "spanish       0.582969  0.739874  0.784612  0.702752     0.707774  1.000000   \n",
       "thai          0.671054  0.617627  0.533128  0.494331     0.536965  0.606200   \n",
       "vietnamese    0.747119  0.623531  0.553375  0.539100     0.562359  0.614200   \n",
       "\n",
       "cuisine           thai  vietnamese  \n",
       "cuisine                             \n",
       "brazilian     0.685539    0.653801  \n",
       "british       0.445518    0.478901  \n",
       "cajun_creole  0.590103    0.605224  \n",
       "chinese       0.755813    0.817005  \n",
       "filipino      0.741512    0.806833  \n",
       "french        0.548375    0.570925  \n",
       "greek         0.519004    0.538683  \n",
       "indian        0.627460    0.605162  \n",
       "irish         0.449931    0.481712  \n",
       "italian       0.555088    0.571096  \n",
       "jamaican      0.650898    0.664175  \n",
       "japanese      0.682604    0.738413  \n",
       "korean        0.671054    0.747119  \n",
       "mexican       0.617627    0.623531  \n",
       "moroccan      0.533128    0.553375  \n",
       "russian       0.494331    0.539100  \n",
       "southern_us   0.536965    0.562359  \n",
       "spanish       0.606200    0.614200  \n",
       "thai          1.000000    0.914986  \n",
       "vietnamese    0.914986    1.000000  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the results to a DataFrame\n",
    "cuisine_list = cuisine_ingredients.index\n",
    "cuisine_similarity = pd.DataFrame(cuisine_similarity, index=cuisine_list, columns=cuisine_list)\n",
    "cuisine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a298e6d50>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the similarities as a heatmap\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.heatmap(cuisine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hand-selected cuisine groups\n",
    "group_1 = ['chinese', 'filipino', 'japanese', 'korean', 'thai', 'vietnamese']\n",
    "group_2 = ['british', 'french', 'irish', 'russian', 'southern_us']\n",
    "group_3 = ['greek', 'italian', 'moroccan', 'spanish']\n",
    "group_4 = ['brazilian', 'cajun_creole', 'indian', 'jamaican', 'mexican']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 9: Model stacking\n",
    "\n",
    "- The term \"model stacking\" is used any time there are **multiple \"levels\" of models**, in which the outputs from one level are used as inputs to another level.\n",
    "- In this case, we will create one model that predicts the **cuisine group** for a recipe. Within each of the four groups, we will create another model that predicts the actual **cuisine**.\n",
    "- Our theory is that each of these five models may need to be **tuned differently** for maximum accuracy, but will ultimately result in a process that is more accurate than a single-level model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chinese': 1,\n",
       " 'filipino': 1,\n",
       " 'japanese': 1,\n",
       " 'korean': 1,\n",
       " 'thai': 1,\n",
       " 'vietnamese': 1,\n",
       " 'british': 2,\n",
       " 'french': 2,\n",
       " 'irish': 2,\n",
       " 'russian': 2,\n",
       " 'southern_us': 2,\n",
       " 'greek': 3,\n",
       " 'italian': 3,\n",
       " 'moroccan': 3,\n",
       " 'spanish': 3,\n",
       " 'brazilian': 4,\n",
       " 'cajun_creole': 4,\n",
       " 'indian': 4,\n",
       " 'jamaican': 4,\n",
       " 'mexican': 4}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary that maps each cuisine to its group number\n",
    "cuisines = group_1 + group_2 + group_3 + group_4\n",
    "group_numbers = [1]*len(group_1) + [2]*len(group_2) + [3]*len(group_3) + [4]*len(group_4)\n",
    "cuisine_to_group = dict(zip(cuisines, group_numbers))\n",
    "cuisine_to_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "      <th>ingredients_str</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>9</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>['romaine lettuce', 'black olives', 'grape tom...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.090909</td>\n",
       "      <td>['plain flour', 'ground pepper', 'salt', 'toma...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>12</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>['water', 'vegetable oil', 'wheat', 'salt']</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>20</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>['black pepper', 'shallots', 'cornflour', 'cay...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients  \\\n",
       "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3  22213       indian                [water, vegetable oil, wheat, salt]   \n",
       "4  13162       indian  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "   num_ingredients  ingredient_length  \\\n",
       "0                9          12.000000   \n",
       "1               11          10.090909   \n",
       "2               12          10.333333   \n",
       "3                4           6.750000   \n",
       "4               20          10.100000   \n",
       "\n",
       "                                     ingredients_str  group  \n",
       "0  ['romaine lettuce', 'black olives', 'grape tom...      3  \n",
       "1  ['plain flour', 'ground pepper', 'salt', 'toma...      2  \n",
       "2  ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...      1  \n",
       "3        ['water', 'vegetable oil', 'wheat', 'salt']      4  \n",
       "4  ['black pepper', 'shallots', 'cornflour', 'cay...      4  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map the cuisines to their group numbers\n",
    "train['group'] = train.cuisine.map(cuisine_to_group)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that all recipes were assigned a cuisine group\n",
    "train.group.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8276513701245822"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the cross-validated accuracy of using text to predict cuisine group\n",
    "X = train.ingredients_str\n",
    "y = train.group\n",
    "pipe_main = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "cross_val_score(pipe_main, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an X and y for each cuisine group\n",
    "X1 = train.loc[train.group==1, 'ingredients_str']\n",
    "y1 = train.loc[train.group==1, 'cuisine']\n",
    "X2 = train.loc[train.group==2, 'ingredients_str']\n",
    "y2 = train.loc[train.group==2, 'cuisine']\n",
    "X3 = train.loc[train.group==3, 'ingredients_str']\n",
    "y3 = train.loc[train.group==3, 'cuisine']\n",
    "X4 = train.loc[train.group==4, 'ingredients_str']\n",
    "y4 = train.loc[train.group==4, 'cuisine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a pipeline for each cuisine group\n",
    "pipe_1 = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "pipe_2 = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "pipe_3 = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "pipe_4 = make_pipeline(CountVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7693031228079263\n",
      "0.7568885301219405\n",
      "0.8701840957938736\n",
      "0.9043403347972706\n"
     ]
    }
   ],
   "source": [
    "# within each cuisine group, calculate the cross-validated accuracy of using text to predict cuisine\n",
    "print(cross_val_score(pipe_1, X1, y1, cv=5, scoring='accuracy').mean())\n",
    "print(cross_val_score(pipe_2, X2, y2, cv=5, scoring='accuracy').mean())\n",
    "print(cross_val_score(pipe_3, X3, y3, cv=5, scoring='accuracy').mean())\n",
    "print(cross_val_score(pipe_4, X4, y4, cv=5, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Ideally, each of the five pipelines should be **individually tuned** from start to finish, including feature engineering, model selection, and parameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions for the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('countvectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('multinomialnb',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit each pipeline with the relevant X and y\n",
    "pipe_main.fit(X, y)\n",
    "pipe_1.fit(X1, y1)\n",
    "pipe_2.fit(X2, y2)\n",
    "pipe_3.fit(X3, y3)\n",
    "pipe_4.fit(X4, y4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 3, ..., 3, 4, 4])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for the new data, first make cuisine group predictions\n",
    "X_new = new.ingredients_str\n",
    "new_pred_group = pipe_main.predict(X_new)\n",
    "new_pred_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chinese' 'japanese' 'vietnamese' ... 'chinese' 'chinese' 'vietnamese']\n",
      "['british' 'southern_us' 'southern_us' ... 'southern_us' 'french' 'french']\n",
      "['spanish' 'italian' 'spanish' ... 'italian' 'italian' 'italian']\n",
      "['cajun_creole' 'mexican' 'indian' ... 'mexican' 'cajun_creole' 'mexican']\n"
     ]
    }
   ],
   "source": [
    "# then within each predicted cuisine group, make cuisine predictions\n",
    "new_pred_class_1 = pipe_1.predict(X_new[new_pred_group==1])\n",
    "new_pred_class_2 = pipe_2.predict(X_new[new_pred_group==2])\n",
    "new_pred_class_3 = pipe_3.predict(X_new[new_pred_group==3])\n",
    "new_pred_class_4 = pipe_4.predict(X_new[new_pred_group==4])\n",
    "print(new_pred_class_1)\n",
    "print(new_pred_class_2)\n",
    "print(new_pred_class_3)\n",
    "print(new_pred_class_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the cuisine predictions to the DataFrame of new data\n",
    "new.loc[new_pred_group==1, 'pred_class'] = new_pred_class_1\n",
    "new.loc[new_pred_group==2, 'pred_class'] = new_pred_class_2\n",
    "new.loc[new_pred_group==3, 'pred_class'] = new_pred_class_3\n",
    "new.loc[new_pred_group==4, 'pred_class'] = new_pred_class_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>num_ingredients</th>\n",
       "      <th>ingredient_length</th>\n",
       "      <th>ingredients_str</th>\n",
       "      <th>pred_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18009</td>\n",
       "      <td>[baking powder, eggs, all-purpose flour, raisi...</td>\n",
       "      <td>6</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>['baking powder', 'eggs', 'all-purpose flour',...</td>\n",
       "      <td>british</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28583</td>\n",
       "      <td>[sugar, egg yolks, corn starch, cream of tarta...</td>\n",
       "      <td>11</td>\n",
       "      <td>10.272727</td>\n",
       "      <td>['sugar', 'egg yolks', 'corn starch', 'cream o...</td>\n",
       "      <td>southern_us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41580</td>\n",
       "      <td>[sausage links, fennel bulb, fronds, olive oil...</td>\n",
       "      <td>6</td>\n",
       "      <td>9.666667</td>\n",
       "      <td>['sausage links', 'fennel bulb', 'fronds', 'ol...</td>\n",
       "      <td>spanish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29752</td>\n",
       "      <td>[meat cuts, file powder, smoked sausage, okra,...</td>\n",
       "      <td>21</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>['meat cuts', 'file powder', 'smoked sausage',...</td>\n",
       "      <td>cajun_creole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35687</td>\n",
       "      <td>[ground black pepper, salt, sausage casings, l...</td>\n",
       "      <td>8</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>['ground black pepper', 'salt', 'sausage casin...</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                        ingredients  num_ingredients  \\\n",
       "0  18009  [baking powder, eggs, all-purpose flour, raisi...                6   \n",
       "1  28583  [sugar, egg yolks, corn starch, cream of tarta...               11   \n",
       "2  41580  [sausage links, fennel bulb, fronds, olive oil...                6   \n",
       "3  29752  [meat cuts, file powder, smoked sausage, okra,...               21   \n",
       "4  35687  [ground black pepper, salt, sausage casings, l...                8   \n",
       "\n",
       "   ingredient_length                                    ingredients_str  \\\n",
       "0           9.333333  ['baking powder', 'eggs', 'all-purpose flour',...   \n",
       "1          10.272727  ['sugar', 'egg yolks', 'corn starch', 'cream o...   \n",
       "2           9.666667  ['sausage links', 'fennel bulb', 'fronds', 'ol...   \n",
       "3          12.000000  ['meat cuts', 'file powder', 'smoked sausage',...   \n",
       "4          13.000000  ['ground black pepper', 'salt', 'sausage casin...   \n",
       "\n",
       "     pred_class  \n",
       "0       british  \n",
       "1   southern_us  \n",
       "2       spanish  \n",
       "3  cajun_creole  \n",
       "4       italian  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a submission file (score: 0.70475)\n",
    "pd.DataFrame({'id':new.id, 'cuisine':new.pred_class}).set_index('id').to_csv('submission5.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
