{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10.Part-of-Speech Tagging.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5WEerzzSeID",
        "colab_type": "text"
      },
      "source": [
        "# Part-of-Speech Tagging\n",
        "\n",
        "- using LSTM\n",
        "- Very simple example to understand concept"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnDcCpN-Sw9d",
        "colab_type": "text"
      },
      "source": [
        "# 1)- Importing key modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ormhGRA1SkYP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#support both Python 2 and Python 3 with minimal overhead.\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "# I am an engineer. I care only about error not warning. So, let's be maverick and ignore warnings.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D67sBX97TBC9",
        "colab_type": "code",
        "outputId": "11ed585e-7b27-4a26-cc53-20719affa21d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! pip install jdc"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jdc in /usr/local/lib/python3.6/dist-packages (0.0.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffmlRA40S1bS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For data processing and maths\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import math\n",
        "import os\n",
        "import jdc\n",
        "#For Visuals\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "from matplotlib import rcParams\n",
        "rcParams['figure.figsize'] = 11, 8\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ2K4n6-S_tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for deep learning and neural network\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNbXWUUTTLOV",
        "colab_type": "code",
        "outputId": "c2e91ee6-f9c4-4515-a232-2777d0c78f21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! pip install version_information"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: version_information in /usr/local/lib/python3.6/dist-packages (1.0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRJECjnJTOyF",
        "colab_type": "code",
        "outputId": "70a36765-4cc7-4e6b-f921-41d629faca72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "# first install: pip install version_information\n",
        "%reload_ext version_information\n",
        "%version_information pandas,torch,numpy,seaborn, matplotlib"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/latex": "\\begin{tabular}{|l|l|}\\hline\n{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\nPython & 3.6.8 64bit [GCC 8.0.1 20180414 (experimental) [trunk revision 259383] \\\\ \\hline\nIPython & 5.5.0 \\\\ \\hline\nOS & Linux 4.14.137+ x86\\_64 with Ubuntu 18.04 bionic \\\\ \\hline\npandas & 0.24.2 \\\\ \\hline\ntorch & 1.3.0+cu100 \\\\ \\hline\nnumpy & 1.16.5 \\\\ \\hline\nseaborn & 0.9.0 \\\\ \\hline\nmatplotlib & 3.0.3 \\\\ \\hline\n\\hline \\multicolumn{2}{|l|}{Mon Oct 21 17:50:37 2019 UTC} \\\\ \\hline\n\\end{tabular}\n",
            "application/json": {
              "Software versions": [
                {
                  "version": "3.6.8 64bit [GCC 8.0.1 20180414 (experimental) [trunk revision 259383]",
                  "module": "Python"
                },
                {
                  "version": "5.5.0",
                  "module": "IPython"
                },
                {
                  "version": "Linux 4.14.137+ x86_64 with Ubuntu 18.04 bionic",
                  "module": "OS"
                },
                {
                  "version": "0.24.2",
                  "module": "pandas"
                },
                {
                  "version": "1.3.0+cu100",
                  "module": "torch"
                },
                {
                  "version": "1.16.5",
                  "module": "numpy"
                },
                {
                  "version": "0.9.0",
                  "module": "seaborn"
                },
                {
                  "version": "3.0.3",
                  "module": "matplotlib"
                }
              ]
            },
            "text/html": [
              "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.8 64bit [GCC 8.0.1 20180414 (experimental) [trunk revision 259383]</td></tr><tr><td>IPython</td><td>5.5.0</td></tr><tr><td>OS</td><td>Linux 4.14.137+ x86_64 with Ubuntu 18.04 bionic</td></tr><tr><td>pandas</td><td>0.24.2</td></tr><tr><td>torch</td><td>1.3.0+cu100</td></tr><tr><td>numpy</td><td>1.16.5</td></tr><tr><td>seaborn</td><td>0.9.0</td></tr><tr><td>matplotlib</td><td>3.0.3</td></tr><tr><td colspan='2'>Mon Oct 21 17:50:37 2019 UTC</td></tr></table>"
            ],
            "text/plain": [
              "Software versions\n",
              "Python 3.6.8 64bit [GCC 8.0.1 20180414 (experimental) [trunk revision 259383]\n",
              "IPython 5.5.0\n",
              "OS Linux 4.14.137+ x86_64 with Ubuntu 18.04 bionic\n",
              "pandas 0.24.2\n",
              "torch 1.3.0+cu100\n",
              "numpy 1.16.5\n",
              "seaborn 0.9.0\n",
              "matplotlib 3.0.3\n",
              "Mon Oct 21 17:50:37 2019 UTC"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zjfC12iTUFU",
        "colab_type": "text"
      },
      "source": [
        "# 2)- Example data & its preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtLp2YNiTQxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data = [\n",
        "    (\"The dog ate the apple.\".split(), [\"Determiner\", \"Noun\", \"Verb\", \"Determiner\", \"Noun\"]),\n",
        "    (\"Everybody read that book.\".split(), [\"Noun\", \"Verb\", \"Determiner\", \"Noun\"])\n",
        "]\n",
        "training_sentences = [training_data[x][0] for x in range(len(training_data))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI22zEq2TdJA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "69aac852-50fb-4754-a4d6-51790735cf45"
      },
      "source": [
        "training_sentences"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['The', 'dog', 'ate', 'the', 'apple.'],\n",
              " ['Everybody', 'read', 'that', 'book.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8exHAdGTe_p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ed836fed-1a10-466a-8f10-2510346e6dfa"
      },
      "source": [
        "type(training_sentences)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-XydELCWlEc",
        "colab_type": "text"
      },
      "source": [
        "### 2.a)-Clean the data\n",
        "\n",
        "Make all words lower case and remove punctuation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxGE0LCtWm0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_data_clean = []\n",
        "for sentence, tags in training_data:\n",
        "    clean_sentence = [x.lower().split('.')[0] for x in sentence]\n",
        "    training_data_clean += [(clean_sentence, tags)]\n",
        "training_sentences_clean = [training_data_clean[x][0] for x in range(len(training_data_clean))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkCEQ_NvXghc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c9a47dc-d737-4ac1-b24f-ea0fb087bf83"
      },
      "source": [
        "training_sentences_clean "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['the', 'dog', 'ate', 'the', 'apple'], ['everybody', 'read', 'that', 'book']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HmiNoyXXly5",
        "colab_type": "text"
      },
      "source": [
        "### 2.b)-Create vocabulary\n",
        "\n",
        "Using all words in each sentence of the training data, create a vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7hCLeQ1XiIl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb80d68e-2a61-46d0-ecaa-68c1ea0caaf4"
      },
      "source": [
        "words = []\n",
        "for sentence in training_sentences_clean:\n",
        "    words += sentence\n",
        "vocab = list(set(words))\n",
        "print(vocab)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['everybody', 'that', 'the', 'ate', 'apple', 'dog', 'read', 'book']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpZAM5VTXqxx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "249b54c2-7734-44a8-e254-98088650a95d"
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "447byaX1X4i5",
        "colab_type": "text"
      },
      "source": [
        "### 2.c)-Create mapping dictionaries\n",
        "\n",
        "Using dictionaries to convert words to integers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9GepKijXq4R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c96f0fa5-48a1-45eb-c91c-ba5b75753257"
      },
      "source": [
        "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
        "print('word_to_ix: {}'.format(word_to_ix))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word_to_ix: {'everybody': 0, 'that': 1, 'the': 2, 'ate': 3, 'apple': 4, 'dog': 5, 'read': 6, 'book': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHI07H70YD7L",
        "colab_type": "text"
      },
      "source": [
        "### 2.d)-Map the parts-of-speech tags to integers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GJe0KplXq95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tags to integers\n",
        "tag_to_ix = {\"Determiner\": 0, \"Noun\": 1, \"Verb\": 2}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyGvfXkqYKqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Integers to tags\n",
        "ix_to_tag = {0: \"Determiner\", 1: \"Noun\", 2: \"Verb\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7Hup2_DYnBE",
        "colab_type": "text"
      },
      "source": [
        "### 2.e)-Set Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faHt99pkYpfA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 6\n",
        "HIDDEN_DIM = 6\n",
        "LEARNING_RATE = 0.1\n",
        "NUM_EPOCHS = 300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAFZvKBaYWaB",
        "colab_type": "text"
      },
      "source": [
        "# 3)-Create the model\n",
        "\n",
        "- LSTMTagger class.\n",
        "\n",
        "Inherits nn.Module from PyTorch.\n",
        "\n",
        "- Inputs:\n",
        "\n",
        "Embedding dimension.<br>\n",
        "Number of hidden dimensions.<br>\n",
        "Vocabulary size.<br>\n",
        "Tag set size.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfYNmsmYYMvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # LSTM: Inputs are embeddings, outputs are hidden states\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "        # Linear layer maps hidden space to tag space\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "        self.hidden = self.init_hidden()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqeRdZ49ZEwQ",
        "colab_type": "text"
      },
      "source": [
        "**function to initialize the hidden states**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qzmMcAoZA9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%add_to LSTMTagger\n",
        "def init_hidden(self):\n",
        "    \"\"\"\n",
        "    Initialize the hidden state. The axes correspond to (num_layers, minibatch_size, hidden_dim).\n",
        "    \"\"\"\n",
        "    return (torch.zeros(1, 1, self.hidden_dim),\n",
        "            torch.zeros(1, 1, self.hidden_dim))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOLGDkXxZObI",
        "colab_type": "text"
      },
      "source": [
        "**a function to make a forward pass through the recurrent LSTM network**\n",
        "\n",
        "\n",
        "It will return the predict tag values given an input sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umb_zBa-ZENB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%add_to LSTMTagger\n",
        "def forward(self, sentence):\n",
        "    \"\"\"\n",
        "    Make a forward pass through the LSTM.\n",
        "    \n",
        "    :param sentence: The input sentence.\n",
        "    :type sentence: list\n",
        "    :return: A Tensor of tag scores.\n",
        "    :rtype: Tensor\n",
        "    \"\"\"\n",
        "    embeds = self.word_embeddings(sentence)\n",
        "    lstm_out, self.hidden = self.lstm(\n",
        "        embeds.view(len(sentence), 1, -1), self.hidden)\n",
        "    tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "    tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "    return tag_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWBjftwaZYEA",
        "colab_type": "text"
      },
      "source": [
        "**Helper Function**\n",
        "\n",
        "Map either words or tags to integers, using the previously defined dictionaries (tag_to_ix, ix_to_tag)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmWEArccZUWw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "    \"\"\"\n",
        "    Convert words or tags to intigers and return a Pytorch tensor.\n",
        "    :param seq: Sequence of words.\n",
        "    :type seq: list\n",
        "    :param to_ix: Dictionary mapping words or tags to intigers.\n",
        "    :return: A Pytorch tensor of indices.\n",
        "    :rtype: Tensor\n",
        "    \"\"\"\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut-wvQ5EZc2g",
        "colab_type": "text"
      },
      "source": [
        "# 4)-Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOXHLiQ7Zb9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#LSTM Pytorch model using the hyperparameters defined above\n",
        "\n",
        "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOiH_6AHZtAw",
        "colab_type": "text"
      },
      "source": [
        "**Define loss function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gR2xyo9JZlbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we will be using a negative log likelihood function, which is useful in classification problems.\n",
        "\n",
        "loss_function = nn.NLLLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUr_SnfNZ2xg",
        "colab_type": "text"
      },
      "source": [
        "**optimizer**\n",
        "\n",
        "using stochastic gradient descent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa-tUctPZ0KU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCadgoLraDWo",
        "colab_type": "text"
      },
      "source": [
        "### 4.a)- Model before training\n",
        "\n",
        "Let's run the model before any training has been done and store the scores to a list. We will then compare these scores with the scores after training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8o6-o7PZ70P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "store_initial_probabilities = []\n",
        "store_initial_predictions = []\n",
        "with torch.no_grad():\n",
        "    for sentence in training_sentences_clean:\n",
        "        inputs = prepare_sequence(sentence, word_to_ix)\n",
        "        tag_scores = model(inputs)\n",
        "        tag_probabilities = tag_scores.exp()\n",
        "        max_values, max_indices = torch.max(tag_probabilities, 1)\n",
        "        initial_prediction = [ix_to_tag[x] for x in max_indices.numpy()]\n",
        "        store_initial_predictions.append(initial_prediction)\n",
        "        store_initial_probabilities.append(tag_probabilities)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVoAxjmAaOY4",
        "colab_type": "text"
      },
      "source": [
        "### 4.b)-Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wjbx-5tcaMxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(NUM_EPOCHS):\n",
        "    for sentence, tags in training_data_clean:\n",
        "        # Set gradients equal to zero after each intance\n",
        "        model.zero_grad()\n",
        "        \n",
        "        # Initialize hidden state of LSTM after each intance\n",
        "        model.hidden = model.init_hidden()\n",
        "        \n",
        "        # Turn inputs into tensors of word indices\n",
        "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "        targets = prepare_sequence(tags, tag_to_ix)\n",
        "        \n",
        "        # Run forward pass\n",
        "        tag_scores = model(sentence_in)\n",
        "        \n",
        "        # Compute the loss, gradients, and update the parameters\n",
        "        loss = loss_function(tag_scores, targets)\n",
        "        \n",
        "        # Perform backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update model parameters\n",
        "        optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIIW0RuJaVXI",
        "colab_type": "text"
      },
      "source": [
        "# 5)- Plot results\n",
        "\n",
        "Both before training and after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud-HK9oMaS5s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "ff4c4eca-7a49-437f-a3d9-08793b114e61"
      },
      "source": [
        "# Print out the scores after training the model\n",
        "store_initial_probabilities.reverse()\n",
        "store_initial_predictions.reverse()\n",
        "with torch.no_grad():\n",
        "    for sentence in training_sentences_clean:\n",
        "        inputs = prepare_sequence(sentence, word_to_ix)\n",
        "        tag_scores = model(inputs)\n",
        "        tag_probabilities = tag_scores.exp()\n",
        "        max_values, max_indices = torch.max(tag_probabilities, 1)\n",
        "        predictions = [ix_to_tag[x] for x in max_indices.numpy()]\n",
        "        \n",
        "        print('Before training:')\n",
        "        print(' - initial probabilities: {}'.format(store_initial_probabilities.pop()))\n",
        "        print(' - sentence: {}'.format(' '.join(sentence)))\n",
        "        print(' - predicition: {}'.format(store_initial_predictions.pop()))\n",
        "        print('After training:')\n",
        "        print(' - final probabilities: {}'.format(tag_probabilities))\n",
        "        print(' - sentence: {}'.format(' '.join(sentence)))\n",
        "        print(' - prediction: {}'.format(predictions))\n",
        "        print('')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before training:\n",
            " - initial probabilities: tensor([[0.4357, 0.2607, 0.3036],\n",
            "        [0.4626, 0.2501, 0.2873],\n",
            "        [0.4421, 0.2604, 0.2976],\n",
            "        [0.4406, 0.2551, 0.3043],\n",
            "        [0.4642, 0.2479, 0.2879]])\n",
            " - sentence: the dog ate the apple\n",
            " - predicition: ['Determiner', 'Determiner', 'Determiner', 'Determiner', 'Determiner']\n",
            "After training:\n",
            " - final probabilities: tensor([[0.9231, 0.0709, 0.0060],\n",
            "        [0.0210, 0.9477, 0.0313],\n",
            "        [0.0254, 0.0205, 0.9541],\n",
            "        [0.9766, 0.0180, 0.0054],\n",
            "        [0.0166, 0.9769, 0.0065]])\n",
            " - sentence: the dog ate the apple\n",
            " - prediction: ['Determiner', 'Noun', 'Verb', 'Determiner', 'Noun']\n",
            "\n",
            "Before training:\n",
            " - initial probabilities: tensor([[0.3742, 0.2619, 0.3639],\n",
            "        [0.3972, 0.2580, 0.3447],\n",
            "        [0.3657, 0.2808, 0.3535],\n",
            "        [0.4013, 0.2654, 0.3333]])\n",
            " - sentence: everybody read that book\n",
            " - predicition: ['Determiner', 'Determiner', 'Determiner', 'Determiner']\n",
            "After training:\n",
            " - final probabilities: tensor([[0.0036, 0.9883, 0.0081],\n",
            "        [0.0121, 0.0327, 0.9552],\n",
            "        [0.9231, 0.0453, 0.0316],\n",
            "        [0.0173, 0.9698, 0.0129]])\n",
            " - sentence: everybody read that book\n",
            " - prediction: ['Noun', 'Verb', 'Determiner', 'Noun']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpC0jVgFaq8Y",
        "colab_type": "text"
      },
      "source": [
        "**Making more sense of score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFCPmdSDactP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "aab068c6-78b3-4beb-c093-bfc545e04763"
      },
      "source": [
        "print('Let us take the 1st sentence of our dataset: {}'.format(' '.join(training_sentences[0])))\n",
        "print('For the word \"{}\" the list of possible parts-of-speech are: {}'.format(training_sentences[0][0], [x for x in ix_to_tag.values()]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Let us take the 1st sentence of our dataset: The dog ate the apple.\n",
            "For the word \"The\" the list of possible parts-of-speech are: ['Determiner', 'Noun', 'Verb']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9pOoApfaz5M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "06ce1c92-b776-4604-c688-fd2985be8172"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTMTagger(\n",
              "  (word_embeddings): Embedding(8, 6)\n",
              "  (lstm): LSTM(6, 6)\n",
              "  (hidden2tag): Linear(in_features=6, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-ZWwgk_a30z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b7b20733-bf38-4d5e-e5db-b54ee4013f6b"
      },
      "source": [
        "inputs = prepare_sequence(training_sentences_clean[0], word_to_ix)\n",
        "tag_scores = model(inputs)\n",
        "tag_probabilities = tag_scores.exp()\n",
        "max_values, max_indices = torch.max(tag_probabilities, 1)\n",
        "predictions = [ix_to_tag[x] for x in max_indices.numpy()]\n",
        "print('sentence: {}'.format(' '.join(training_sentences[0])))\n",
        "print('parts-of-speach: {}'.format(predictions))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence: The dog ate the apple.\n",
            "parts-of-speach: ['Determiner', 'Noun', 'Verb', 'Determiner', 'Noun']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlpAXWXea-Df",
        "colab_type": "text"
      },
      "source": [
        "**What about second sentence**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH4yMn0Ka9Pb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "15c0bf0f-634f-43cc-bfd4-c112c6c1fd38"
      },
      "source": [
        "inputs = prepare_sequence(training_sentences_clean[1], word_to_ix)\n",
        "tag_scores = model(inputs)\n",
        "tag_probabilities = tag_scores.exp()\n",
        "max_values, max_indices = torch.max(tag_probabilities, 1)\n",
        "predictions = [ix_to_tag[x] for x in max_indices.numpy()]\n",
        "print('sentence: {}'.format(' '.join(training_sentences[1])))\n",
        "print('parts-of-speach: {}'.format(predictions))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence: Everybody read that book.\n",
            "parts-of-speach: ['Noun', 'Verb', 'Determiner', 'Noun']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}