{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to work with tensorflow with our given json file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)- Import key Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n",
      "WARNING:tensorflow:From C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tflearn\\helpers\\summarizer.py:9: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tflearn\\helpers\\trainer.py:25: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tflearn\\collections.py:13: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tflearn\\config.py:123: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tflearn\\config.py:129: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tflearn\\config.py:131: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)- Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>helloi tried apply voucher order received mail...</td>\n",
       "      <td>Shipping issues</td>\n",
       "      <td>nichtkombiwb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi tracking number please thank youkind regard...</td>\n",
       "      <td>Shipping issues</td>\n",
       "      <td>renscom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hi ive received order one posters bad stateit ...</td>\n",
       "      <td>product complaints - products (Reklamation Pro...</td>\n",
       "      <td>neupverp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asked test saal photobook delighted result arr...</td>\n",
       "      <td>ShareWithSaal</td>\n",
       "      <td>teilen2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ainda recebi encomenda e estive sempre em casa</td>\n",
       "      <td>Order management</td>\n",
       "      <td>renscom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dobr den mm od vs objednanou fotoknihu objednv...</td>\n",
       "      <td>Order management</td>\n",
       "      <td>wp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  helloi tried apply voucher order received mail...   \n",
       "1  hi tracking number please thank youkind regard...   \n",
       "2  hi ive received order one posters bad stateit ...   \n",
       "3  asked test saal photobook delighted result arr...   \n",
       "4     ainda recebi encomenda e estive sempre em casa   \n",
       "5  dobr den mm od vs objednanou fotoknihu objednv...   \n",
       "\n",
       "                                              intent      response  \n",
       "0                                    Shipping issues  nichtkombiwb  \n",
       "1                                    Shipping issues       renscom  \n",
       "2  product complaints - products (Reklamation Pro...      neupverp  \n",
       "3                                      ShareWithSaal       teilen2  \n",
       "4                                   Order management       renscom  \n",
       "5                                   Order management            wp  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json('data_json.json')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data_json.json') as file:\n",
    "    data2 = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember to check nested_json code on Github**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'hi ive received order one posters bad stateit folded la post sent email saying reinforce packagingthe order 512005251803340regards eugenia sebastiani',\n",
       " 'intent': 'product complaints - products (Reklamation Produkte)',\n",
       " 'response': 'neupverp'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One step deeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'helloi tried apply voucher order received mail didnt appear order total your40 voucher 12999 rfk93r3anfpvgcan please apply orderthank colinon sat jun 6 2020 249 pm wrote http wwwsaaldigitalcom dear mr shreffler thank order pleased chosen wwwsaaldigitalcomyour order number https wwwsaaldigitalcom ordercockpit emailc40colinshrefflercomordernumber802006062223358 order article quantity total price metal print 197x295 metal print aluminium subframe 1 85 39 metal print 197x295 metal print aluminium subframe 1 85 39 metal print 118x177 metal print aluminium subframe 1 44 09 metal print 118x177 metal print aluminium subframe 1 44 09 metal print 118x177 metal print aluminium subframe 1 44 09 metal print 157x197 metal print aluminium subframe 1 53 54 metal print 118x177 metal print aluminium subframe 1 44 09 metal print 118x177 metal print aluminium subframe 1 44 09 metal print 118x177 metal print aluminium subframe 1 44 09 shipping costs 15 00 voucher 0 00 total 503 86 selected method payment already paid via paypal estimated delivery date 6 16 2020 delivery address colin shreffler photography colin shreffler 6791 halifax avenue 80104 castle rock usa billing address colin shreffler photography colin shreffler 6791 halifax avenue 80104 castle rock usayour order status order management tool find order current shipping status always see exactly order currently track real time also find information order example reorder individual items necessaryservice satisfied software webshop always happy hear customer opinion every customer opinion helps us improve fulfill customers wishes look forward seeing future hope enjoy order note use email address inform email products services object use email address time wish receive advertising click link delete profile end email notification best regards saal digital team saal digital corporation8000 towers crescent drive fl 13 vienna va 22182 terms conditions1 contract contract saal digital corporation saaldigital customer manufacture photographic products concluded saaldigital receives order via design software webshop app accepts contract within 5 days sending order confirmation addition shipping confirmation sent place jurisdiction sellers registered office information privacy protection policy applies2 prices terms payment fee paid customer saaldigital development production images shall determined prices saaldigital applicable time contract concluded charges paid customer shall understood include statutory valueadded tax applicable time3 delivery place performance saaldigital delivers photo products delivery address stated order shipping costs charged delivery amount shipping costs communicated customer placing order taxes customs duties incurred shipment borne customer saaldigital entitled make partial deliveries place performance registered office saaldigital4 payment photo products remain property saaldigital full payment received payment shall made exclusively cashless method payment specified customer placing order invoices sent exclusively pdf documents email5 vouchers unless otherwise stated voucher conditions following always applies vouchers vouchers cannot combined promotions vouchers vouchers applicable shipping costs redeemed per household vouchers cannot used purchase gift vouchers6 gift vouchers voucher cannot split several orders minimum order value therefore voucher value shipping costs excluded redeem voucher saal design software webshop app technical reasons one voucher redeemed per order7 cancellation return policy cancellation policy exist distance contracts delivery goods made according customer specifications clearly tailored personal needs8 liability saaldigital liable damages event breach essential contractual obligations absence warranted characteristics customers claims product liability act furthermore saaldigital shall liable damages cases intent gross negligence part saaldigital vicarious agents saaldigital liable indirect consequential atypical damages kind also applies compensation lost profit lost possibility use intangible values9 complaints dispute resolution prefer clarify concerns directly therefore participate consumer arbitration procedures furthermore obliged participate dispute settlement procedure consumer arbitration body please contact us directly questions problems contact us filling forms https wwwsaaldigitalcom support status march 2019', 'intent': 'Shipping issues', 'response': 'nichtkombiwb'}\n",
      "{'text': 'hi tracking number please thank youkind regards kerryon fri 5 jun 2020 1127 wrote http wwwsaaldigitalcouk dear ms keys order dispachedyour order number https wwwsaaldigitalcouk ordercockpit emailkerrykeys40gmailcomordernumber512006011553404 order article quantity total price 30x21 photobook professional line spreads matte photo paper 52 pages 1 5729 cover acrylic + leather cover surface leather black barcode without barcode 1 4500 shipping costs 499 voucher 10000 total 728 selected method payment already paid via paypal estimated delivery date 11 06 2020 delivery address kerry keys westcliff house 13 westcliff gardens ct20 1szfolkestone united kingdom billing address kerry keys westcliff house 13 westcliff gardens ct20 1sz folkestone united kingdomyour order status order management tool find order current shipping status always see exactly order currently track real time also find information order example reorder individual items necessaryservice satisfied software webshop always happy hear customer opinion every customer opinion helps us improve fulfill customers wishes look forward seeing future hope enjoy order note use email address inform email products services object use email address time wish receive advertising click link delete profile end email notification best regards saal digital team saal digital fotoservice gmbhzeppelinstrae 36 91187 rttenbach managing directors reinhard saal robin saal tim saal florian stellwag vat registration number de 250012471 local court siegen trade register number 9924 bank details sparkasse siegen iban de66 4605 0001 0000 0681 71 bic weladed1sie', 'intent': 'Shipping issues', 'response': 'renscom'}\n",
      "{'text': 'hi ive received order one posters bad stateit folded la post sent email saying reinforce packagingthe order 512005251803340regards eugenia sebastiani', 'intent': 'product complaints - products (Reklamation Produkte)', 'response': 'neupverp'}\n",
      "{'text': 'asked test saal photobook delighted result arrived 10 days high quality white leather look cover acrylic glass protect front photo made lovely lockdown gift best friend', 'intent': 'ShareWithSaal', 'response': 'teilen2'}\n",
      "{'text': 'ainda recebi encomenda e estive sempre em casa', 'intent': 'Order management', 'response': 'renscom'}\n",
      "{'text': 'dobr den mm od vs objednanou fotoknihu objednvkyhttps wwwsaaldigitalcz ordercockpit emailvvyslouzilova40seznamczordernumber512005210955444 jej pedpokldan doruen mlo bt 26 fotokniha vak stle nedorazila ke stavu objednvky nelze dohledat dn bli daje prosm proto informaci kdy bude fotokniha doruena dkuji pozdravem vyslouilov veronika', 'intent': 'Order management', 'response': 'wp'}\n"
     ]
    }
   ],
   "source": [
    "for text in data2:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Above is whole data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 For fetching only text from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dobr den mm od vs objednanou fotoknihu objednvkyhttps wwwsaaldigitalcz ordercockpit emailvvyslouzilova40seznamczordernumber512005210955444 jej pedpokldan doruen mlo bt 26 fotokniha vak stle nedorazila ke stavu objednvky nelze dohledat dn bli daje prosm proto informaci kdy bude fotokniha doruena dkuji pozdravem vyslouilov veronika'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_access=text[\"text\"]\n",
    "text_access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get only last of text data. We will append and get all text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word=[]\n",
    "\n",
    "for text in data2:\n",
    "    text_access=text[\"text\"]\n",
    "    word.append(text_access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['helloi tried apply voucher order received mail didnt appear order total your40 voucher 12999 rfk93r3anfpvgcan please apply orderthank colinon sat jun 6 2020 249 pm wrote http wwwsaaldigitalcom dear mr shreffler thank order pleased chosen wwwsaaldigitalcomyour order number https wwwsaaldigitalcom ordercockpit emailc40colinshrefflercomordernumber802006062223358 order article quantity total price metal print 197x295 metal print aluminium subframe 1 85 39 metal print 197x295 metal print aluminium subframe 1 85 39 metal print 118x177 metal print aluminium subframe 1 44 09 metal print 118x177 metal print aluminium subframe 1 44 09 metal print 118x177 metal print aluminium subframe 1 44 09 metal print 157x197 metal print aluminium subframe 1 53 54 metal print 118x177 metal print aluminium subframe 1 44 09 metal print 118x177 metal print aluminium subframe 1 44 09 metal print 118x177 metal print aluminium subframe 1 44 09 shipping costs 15 00 voucher 0 00 total 503 86 selected method payment already paid via paypal estimated delivery date 6 16 2020 delivery address colin shreffler photography colin shreffler 6791 halifax avenue 80104 castle rock usa billing address colin shreffler photography colin shreffler 6791 halifax avenue 80104 castle rock usayour order status order management tool find order current shipping status always see exactly order currently track real time also find information order example reorder individual items necessaryservice satisfied software webshop always happy hear customer opinion every customer opinion helps us improve fulfill customers wishes look forward seeing future hope enjoy order note use email address inform email products services object use email address time wish receive advertising click link delete profile end email notification best regards saal digital team saal digital corporation8000 towers crescent drive fl 13 vienna va 22182 terms conditions1 contract contract saal digital corporation saaldigital customer manufacture photographic products concluded saaldigital receives order via design software webshop app accepts contract within 5 days sending order confirmation addition shipping confirmation sent place jurisdiction sellers registered office information privacy protection policy applies2 prices terms payment fee paid customer saaldigital development production images shall determined prices saaldigital applicable time contract concluded charges paid customer shall understood include statutory valueadded tax applicable time3 delivery place performance saaldigital delivers photo products delivery address stated order shipping costs charged delivery amount shipping costs communicated customer placing order taxes customs duties incurred shipment borne customer saaldigital entitled make partial deliveries place performance registered office saaldigital4 payment photo products remain property saaldigital full payment received payment shall made exclusively cashless method payment specified customer placing order invoices sent exclusively pdf documents email5 vouchers unless otherwise stated voucher conditions following always applies vouchers vouchers cannot combined promotions vouchers vouchers applicable shipping costs redeemed per household vouchers cannot used purchase gift vouchers6 gift vouchers voucher cannot split several orders minimum order value therefore voucher value shipping costs excluded redeem voucher saal design software webshop app technical reasons one voucher redeemed per order7 cancellation return policy cancellation policy exist distance contracts delivery goods made according customer specifications clearly tailored personal needs8 liability saaldigital liable damages event breach essential contractual obligations absence warranted characteristics customers claims product liability act furthermore saaldigital shall liable damages cases intent gross negligence part saaldigital vicarious agents saaldigital liable indirect consequential atypical damages kind also applies compensation lost profit lost possibility use intangible values9 complaints dispute resolution prefer clarify concerns directly therefore participate consumer arbitration procedures furthermore obliged participate dispute settlement procedure consumer arbitration body please contact us directly questions problems contact us filling forms https wwwsaaldigitalcom support status march 2019',\n",
       " 'hi tracking number please thank youkind regards kerryon fri 5 jun 2020 1127 wrote http wwwsaaldigitalcouk dear ms keys order dispachedyour order number https wwwsaaldigitalcouk ordercockpit emailkerrykeys40gmailcomordernumber512006011553404 order article quantity total price 30x21 photobook professional line spreads matte photo paper 52 pages 1 5729 cover acrylic + leather cover surface leather black barcode without barcode 1 4500 shipping costs 499 voucher 10000 total 728 selected method payment already paid via paypal estimated delivery date 11 06 2020 delivery address kerry keys westcliff house 13 westcliff gardens ct20 1szfolkestone united kingdom billing address kerry keys westcliff house 13 westcliff gardens ct20 1sz folkestone united kingdomyour order status order management tool find order current shipping status always see exactly order currently track real time also find information order example reorder individual items necessaryservice satisfied software webshop always happy hear customer opinion every customer opinion helps us improve fulfill customers wishes look forward seeing future hope enjoy order note use email address inform email products services object use email address time wish receive advertising click link delete profile end email notification best regards saal digital team saal digital fotoservice gmbhzeppelinstrae 36 91187 rttenbach managing directors reinhard saal robin saal tim saal florian stellwag vat registration number de 250012471 local court siegen trade register number 9924 bank details sparkasse siegen iban de66 4605 0001 0000 0681 71 bic weladed1sie',\n",
       " 'hi ive received order one posters bad stateit folded la post sent email saying reinforce packagingthe order 512005251803340regards eugenia sebastiani',\n",
       " 'asked test saal photobook delighted result arrived 10 days high quality white leather look cover acrylic glass protect front photo made lovely lockdown gift best friend',\n",
       " 'ainda recebi encomenda e estive sempre em casa',\n",
       " 'dobr den mm od vs objednanou fotoknihu objednvkyhttps wwwsaaldigitalcz ordercockpit emailvvyslouzilova40seznamczordernumber512005210955444 jej pedpokldan doruen mlo bt 26 fotokniha vak stle nedorazila ke stavu objednvky nelze dohledat dn bli daje prosm proto informaci kdy bude fotokniha doruena dkuji pozdravem vyslouilov veronika']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 For all labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_y=[]\n",
    "\n",
    "for text in data2:\n",
    "    intent_access=text[\"intent\"]\n",
    "    docs_y.append(intent_access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Shipping issues', 'Shipping issues', 'product complaints - products (Reklamation Produkte)', 'ShareWithSaal', 'Order management', 'Order management']\n"
     ]
    }
   ],
   "source": [
    "print(docs_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 For unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for text in data2:\n",
    "    if text['intent'] not in labels:\n",
    "        labels.append(text['intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Shipping issues', 'product complaints - products (Reklamation Produkte)', 'ShareWithSaal', 'Order management']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(docs_y)) #for all labels\n",
    "print(len(labels)) # for unique labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 For words and unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "docs_x = []\n",
    "\n",
    "\n",
    "for pattern in data2: # tokenize words inside pattern \n",
    "    pattern_access=pattern['text']\n",
    "    wrds = nltk.word_tokenize(pattern_access)\n",
    "    words.extend(wrds)\n",
    "    docs_x.append(wrds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(words))\n",
    "print(len(docs_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- doc_x has 6 sentences and that is why it is of 6 length\n",
    "- words has all tokens i.e 897"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [lemm.lemmatize(w.lower()) for w in words if w != \"?\"]\n",
    "words = sorted(list(set(words))) # removes any duplicates if ever occured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Order management', 'ShareWithSaal', 'Shipping issues', 'product complaints - products (Reklamation Produkte)']\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(labels)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 4 labels. So, we will have pattern of 4 encoded terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  4 Bag of Words\n",
    "Converting out strings of words into numerical input.\n",
    "\n",
    "represent each sentence with a list the length of the amount of words in our models vocabulary. Each position in the list will represent a word from our vocabulary. If the position in the list is a 1 then that will mean that the word exists in our sentence, if it is a 0 then the word is nor present\n",
    "\n",
    "bag of words because the order in which the words appear in the sentence is lost, we only know the presence of words in our models vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Order management',\n",
       " 'ShareWithSaal',\n",
       " 'Shipping issues',\n",
       " 'product complaints - products (Reklamation Produkte)']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = []\n",
    "output = []\n",
    "\n",
    "out_empty = [0 for _ in range(len(labels))]\n",
    "\n",
    "for x, doc in enumerate(docs_x):\n",
    "    bag = []\n",
    "\n",
    "    wrds = [lemm.lemmatize(w.lower()) for w in doc]\n",
    "\n",
    "    for w in words:\n",
    "        if w in wrds:\n",
    "            bag.append(1)\n",
    "        else:\n",
    "            bag.append(0)\n",
    "\n",
    "    output_row = out_empty[:]\n",
    "    output_row[labels.index(docs_y[x])] = 1\n",
    "\n",
    "    training.append(bag)\n",
    "    output.append(output_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our neural network will take arrays so, we need to convert\n",
    "training = numpy.array(training)\n",
    "output = numpy.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 ... 0 0 1]\n",
      " [1 0 0 ... 0 1 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [0 0 0 1]\n",
      " [0 1 0 0]\n",
      " [1 0 0 0]\n",
      " [1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#labels\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tflearn\\layers\\core.py:81: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tflearn\\initializations.py:174: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tflearn\\optimizers.py:238: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tflearn\\summaries.py:46: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\hassan.sherwani\\Miniconda3\\envs\\tf1.14\\lib\\site-packages\\tflearn\\helpers\\trainer.py:134: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "net = tflearn.input_data(shape=[None, len(training[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "model = tflearn.DNN(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Run id: 29KUZE\n",
      "Log directory: /tmp/tflearn_logs/\n",
      "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 6\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.080s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m1.24765\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 002 | loss: 1.24765 - acc: 0.3000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m1.36071\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 003 | loss: 1.36071 - acc: 0.3273 -- iter: 6/6\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m1.37881\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 004 | loss: 1.37881 - acc: 0.3318 -- iter: 6/6\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m1.38237\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 005 | loss: 1.38237 - acc: 0.3329 -- iter: 6/6\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m1.38267\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 006 | loss: 1.38267 - acc: 0.3332 -- iter: 6/6\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m1.38195\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 007 | loss: 1.38195 - acc: 0.3333 -- iter: 6/6\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m1.38077\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 008 | loss: 1.38077 - acc: 0.3333 -- iter: 6/6\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m1.37927\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 009 | loss: 1.37927 - acc: 0.3333 -- iter: 6/6\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m1.37748\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 010 | loss: 1.37748 - acc: 0.4167 -- iter: 6/6\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m1.37540\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 011 | loss: 1.37540 - acc: 0.4561 -- iter: 6/6\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m1.37302\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 012 | loss: 1.37302 - acc: 0.4759 -- iter: 6/6\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m1.37031\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 013 | loss: 1.37031 - acc: 0.4862 -- iter: 6/6\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m1.36723\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 014 | loss: 1.36723 - acc: 0.4919 -- iter: 6/6\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m1.36373\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 015 | loss: 1.36373 - acc: 0.4950 -- iter: 6/6\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m1.35978\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 016 | loss: 1.35978 - acc: 0.4969 -- iter: 6/6\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m1.35532\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 017 | loss: 1.35532 - acc: 0.4980 -- iter: 6/6\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m1.35030\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 018 | loss: 1.35030 - acc: 0.5564 -- iter: 6/6\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m1.35205\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 019 | loss: 1.35205 - acc: 0.4820 -- iter: 6/6\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m1.34349\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 020 | loss: 1.34349 - acc: 0.5414 -- iter: 6/6\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m1.33512\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 021 | loss: 1.33512 - acc: 0.5803 -- iter: 6/6\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m1.32656\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 022 | loss: 1.32656 - acc: 0.6062 -- iter: 6/6\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m1.31755\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 023 | loss: 1.31755 - acc: 0.6237 -- iter: 6/6\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m1.30794\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 024 | loss: 1.30794 - acc: 0.6358 -- iter: 6/6\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m1.29761\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 025 | loss: 1.29761 - acc: 0.6442 -- iter: 6/6\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m1.28648\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 026 | loss: 1.28648 - acc: 0.6502 -- iter: 6/6\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m1.27450\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 027 | loss: 1.27450 - acc: 0.6544 -- iter: 6/6\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m1.30151\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 028 | loss: 1.30151 - acc: 0.5741 -- iter: 6/6\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m1.27884\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 029 | loss: 1.27884 - acc: 0.5966 -- iter: 6/6\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m1.25836\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 030 | loss: 1.25836 - acc: 0.6132 -- iter: 6/6\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m1.23919\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 031 | loss: 1.23919 - acc: 0.6256 -- iter: 6/6\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m1.22078\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 032 | loss: 1.22078 - acc: 0.6348 -- iter: 6/6\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m1.20278\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 033 | loss: 1.20278 - acc: 0.6418 -- iter: 6/6\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m1.18499\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 034 | loss: 1.18499 - acc: 0.6471 -- iter: 6/6\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m1.16732\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 035 | loss: 1.16732 - acc: 0.6512 -- iter: 6/6\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m1.14976\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 036 | loss: 1.14976 - acc: 0.6544 -- iter: 6/6\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m1.13237\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 037 | loss: 1.13237 - acc: 0.6568 -- iter: 6/6\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m1.24426\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 038 | loss: 1.24426 - acc: 0.5283 -- iter: 6/6\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m1.20434\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 039 | loss: 1.20434 - acc: 0.5548 -- iter: 6/6\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m1.17097\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 040 | loss: 1.17097 - acc: 0.5758 -- iter: 6/6\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m1.14262\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 041 | loss: 1.14262 - acc: 0.5925 -- iter: 6/6\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m1.11819\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 042 | loss: 1.11819 - acc: 0.6058 -- iter: 6/6\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m1.09683\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 043 | loss: 1.09683 - acc: 0.6166 -- iter: 6/6\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m1.07793\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 044 | loss: 1.07793 - acc: 0.6252 -- iter: 6/6\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m1.06102\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 045 | loss: 1.06102 - acc: 0.6323 -- iter: 6/6\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m1.04577\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 046 | loss: 1.04577 - acc: 0.6380 -- iter: 6/6\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m1.03190\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 047 | loss: 1.03190 - acc: 0.6427 -- iter: 6/6\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m1.01921\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 048 | loss: 1.01921 - acc: 0.6465 -- iter: 6/6\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m1.00755\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 049 | loss: 1.00755 - acc: 0.6497 -- iter: 6/6\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m0.99679\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 050 | loss: 0.99679 - acc: 0.6524 -- iter: 6/6\n",
      "--\n",
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m0.98683\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 051 | loss: 0.98683 - acc: 0.6545 -- iter: 6/6\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m0.97758\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 052 | loss: 0.97758 - acc: 0.6564 -- iter: 6/6\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m0.96897\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 053 | loss: 0.96897 - acc: 0.6579 -- iter: 6/6\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m0.96093\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 054 | loss: 0.96093 - acc: 0.6592 -- iter: 6/6\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m0.95340\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 055 | loss: 0.95340 - acc: 0.6602 -- iter: 6/6\n",
      "--\n",
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m0.94633\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 056 | loss: 0.94633 - acc: 0.6611 -- iter: 6/6\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m0.93968\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 057 | loss: 0.93968 - acc: 0.6619 -- iter: 6/6\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m0.93340\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 058 | loss: 0.93340 - acc: 0.6625 -- iter: 6/6\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m0.92746\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 059 | loss: 0.92746 - acc: 0.6631 -- iter: 6/6\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m0.92180\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 060 | loss: 0.92180 - acc: 0.6636 -- iter: 6/6\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m0.91642\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 061 | loss: 0.91642 - acc: 0.6640 -- iter: 6/6\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m0.91127\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 062 | loss: 0.91127 - acc: 0.6643 -- iter: 6/6\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m0.90633\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 063 | loss: 0.90633 - acc: 0.6646 -- iter: 6/6\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m0.90157\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 064 | loss: 0.90157 - acc: 0.6649 -- iter: 6/6\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m0.89698\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 065 | loss: 0.89698 - acc: 0.6651 -- iter: 6/6\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m0.89253\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 066 | loss: 0.89253 - acc: 0.6653 -- iter: 6/6\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m0.88822\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 067 | loss: 0.88822 - acc: 0.6655 -- iter: 6/6\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m0.88401\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 068 | loss: 0.88401 - acc: 0.6656 -- iter: 6/6\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m0.87991\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 069 | loss: 0.87991 - acc: 0.6657 -- iter: 6/6\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m0.87589\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 070 | loss: 0.87589 - acc: 0.6658 -- iter: 6/6\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m0.87195\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 071 | loss: 0.87195 - acc: 0.6659 -- iter: 6/6\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m0.86808\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 072 | loss: 0.86808 - acc: 0.6660 -- iter: 6/6\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m0.86427\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 073 | loss: 0.86427 - acc: 0.6661 -- iter: 6/6\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m0.86051\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 074 | loss: 0.86051 - acc: 0.6661 -- iter: 6/6\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m0.85679\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 075 | loss: 0.85679 - acc: 0.6662 -- iter: 6/6\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m0.85311\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 076 | loss: 0.85311 - acc: 0.6663 -- iter: 6/6\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m0.84946\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 077 | loss: 0.84946 - acc: 0.6663 -- iter: 6/6\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m0.84585\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 078 | loss: 0.84585 - acc: 0.6663 -- iter: 6/6\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m0.84225\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 079 | loss: 0.84225 - acc: 0.6664 -- iter: 6/6\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m0.83868\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 080 | loss: 0.83868 - acc: 0.6664 -- iter: 6/6\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m0.83512\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 081 | loss: 0.83512 - acc: 0.6664 -- iter: 6/6\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m0.83157\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 082 | loss: 0.83157 - acc: 0.6665 -- iter: 6/6\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m0.82800\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 083 | loss: 0.82800 - acc: 0.6665 -- iter: 6/6\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m0.82439\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 084 | loss: 0.82439 - acc: 0.6665 -- iter: 6/6\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m0.82076\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 085 | loss: 0.82076 - acc: 0.6665 -- iter: 6/6\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m0.81711\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 086 | loss: 0.81711 - acc: 0.6665 -- iter: 6/6\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m0.81343\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 087 | loss: 0.81343 - acc: 0.6665 -- iter: 6/6\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m0.80972\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 088 | loss: 0.80972 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m0.80600\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 089 | loss: 0.80600 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m0.80226\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 090 | loss: 0.80226 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m0.79850\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 091 | loss: 0.79850 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m0.79472\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 092 | loss: 0.79472 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m0.79093\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 093 | loss: 0.79093 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m0.78712\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 094 | loss: 0.78712 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m0.78331\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 095 | loss: 0.78331 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m0.77948\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 096 | loss: 0.77948 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m0.77565\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 097 | loss: 0.77565 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m0.77182\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 098 | loss: 0.77182 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m0.76798\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 099 | loss: 0.76798 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m0.76414\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 100 | loss: 0.76414 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m0.76031\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 101 | loss: 0.76031 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m0.75649\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 102 | loss: 0.75649 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m0.75267\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 103 | loss: 0.75267 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m0.74886\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 104 | loss: 0.74886 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m0.74506\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 105 | loss: 0.74506 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m0.74128\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 106 | loss: 0.74128 - acc: 0.6666 -- iter: 6/6\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m0.73752\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 107 | loss: 0.73752 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m0.73377\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 108 | loss: 0.73377 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m0.73003\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 109 | loss: 0.73003 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m0.72632\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 110 | loss: 0.72632 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m0.72262\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 111 | loss: 0.72262 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m0.71894\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 112 | loss: 0.71894 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m0.71527\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 113 | loss: 0.71527 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m0.71162\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 114 | loss: 0.71162 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m0.70798\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 115 | loss: 0.70798 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m0.70435\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 116 | loss: 0.70435 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m0.70074\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 117 | loss: 0.70074 - acc: 0.6667 -- iter: 6/6\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m0.69713\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 118 | loss: 0.69713 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m0.69353\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 119 | loss: 0.69353 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m0.68994\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 120 | loss: 0.68994 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m0.68635\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 121 | loss: 0.68635 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m0.68276\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 122 | loss: 0.68276 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m0.67918\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 123 | loss: 0.67918 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m0.67560\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 124 | loss: 0.67560 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m0.67202\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 125 | loss: 0.67202 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m0.66844\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 126 | loss: 0.66844 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m0.66487\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 127 | loss: 0.66487 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m0.66129\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 128 | loss: 0.66129 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m0.65772\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 129 | loss: 0.65772 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m0.65414\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 130 | loss: 0.65414 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m0.65057\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 131 | loss: 0.65057 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m0.64700\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 132 | loss: 0.64700 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m0.64344\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 133 | loss: 0.64344 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m0.63988\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 134 | loss: 0.63988 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m0.63633\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 135 | loss: 0.63633 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m0.63278\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 136 | loss: 0.63278 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m0.62924\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 137 | loss: 0.62924 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m0.62571\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 138 | loss: 0.62571 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m0.62218\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 139 | loss: 0.62218 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m0.61867\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 140 | loss: 0.61867 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m0.61517\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 141 | loss: 0.61517 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m0.61168\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 142 | loss: 0.61168 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m0.60820\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 143 | loss: 0.60820 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m0.60474\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 144 | loss: 0.60474 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m0.60129\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 145 | loss: 0.60129 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m0.59786\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 146 | loss: 0.59786 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m0.59444\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 147 | loss: 0.59444 - acc: 0.6667 -- iter: 6/6\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m0.87928\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 148 | loss: 0.87928 - acc: 0.6333 -- iter: 6/6\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m0.84727\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 149 | loss: 0.84727 - acc: 0.6367 -- iter: 6/6\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m0.81832\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 150 | loss: 0.81832 - acc: 0.6397 -- iter: 6/6\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m0.79212\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 151 | loss: 0.79212 - acc: 0.6424 -- iter: 6/6\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m0.76838\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 152 | loss: 0.76838 - acc: 0.6448 -- iter: 6/6\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m0.74685\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 153 | loss: 0.74685 - acc: 0.6470 -- iter: 6/6\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m0.72729\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 154 | loss: 0.72729 - acc: 0.6490 -- iter: 6/6\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m0.70951\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 155 | loss: 0.70951 - acc: 0.6507 -- iter: 6/6\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m0.69330\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 156 | loss: 0.69330 - acc: 0.6523 -- iter: 6/6\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m0.67851\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 157 | loss: 0.67851 - acc: 0.6538 -- iter: 6/6\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m0.66498\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 158 | loss: 0.66498 - acc: 0.6550 -- iter: 6/6\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m0.65259\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 159 | loss: 0.65259 - acc: 0.6562 -- iter: 6/6\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m0.64120\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 160 | loss: 0.64120 - acc: 0.6573 -- iter: 6/6\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m0.63072\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 161 | loss: 0.63072 - acc: 0.6582 -- iter: 6/6\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m0.62105\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 162 | loss: 0.62105 - acc: 0.6590 -- iter: 6/6\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m0.61211\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 163 | loss: 0.61211 - acc: 0.6598 -- iter: 6/6\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m0.60380\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 164 | loss: 0.60380 - acc: 0.6605 -- iter: 6/6\n",
      "--\n",
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m0.59608\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 165 | loss: 0.59608 - acc: 0.6611 -- iter: 6/6\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m0.58887\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 166 | loss: 0.58887 - acc: 0.6617 -- iter: 6/6\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m0.58213\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 167 | loss: 0.58213 - acc: 0.6622 -- iter: 6/6\n",
      "--\n",
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m0.57580\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 168 | loss: 0.57580 - acc: 0.6626 -- iter: 6/6\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m0.56984\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 169 | loss: 0.56984 - acc: 0.6630 -- iter: 6/6\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m0.56422\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 170 | loss: 0.56422 - acc: 0.6801 -- iter: 6/6\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m0.55889\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 171 | loss: 0.55889 - acc: 0.6954 -- iter: 6/6\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m0.55383\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 172 | loss: 0.55383 - acc: 0.7092 -- iter: 6/6\n",
      "--\n",
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m0.54901\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 173 | loss: 0.54901 - acc: 0.7216 -- iter: 6/6\n",
      "--\n",
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m0.54440\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 174 | loss: 0.54440 - acc: 0.7328 -- iter: 6/6\n",
      "--\n",
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m0.53999\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 175 | loss: 0.53999 - acc: 0.7428 -- iter: 6/6\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m0.53576\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 176 | loss: 0.53576 - acc: 0.7519 -- iter: 6/6\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m0.53168\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 177 | loss: 0.53168 - acc: 0.7600 -- iter: 6/6\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m0.52775\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 178 | loss: 0.52775 - acc: 0.7507 -- iter: 6/6\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m0.52394\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 179 | loss: 0.52394 - acc: 0.7423 -- iter: 6/6\n",
      "--\n",
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m0.52026\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 180 | loss: 0.52026 - acc: 0.7347 -- iter: 6/6\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m0.51667\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 181 | loss: 0.51667 - acc: 0.7446 -- iter: 6/6\n",
      "--\n",
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m0.51319\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 182 | loss: 0.51319 - acc: 0.7535 -- iter: 6/6\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m0.50979\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 183 | loss: 0.50979 - acc: 0.7614 -- iter: 6/6\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m0.50647\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 184 | loss: 0.50647 - acc: 0.7686 -- iter: 6/6\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m0.50322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 185 | loss: 0.50322 - acc: 0.7751 -- iter: 6/6\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m0.50004\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 186 | loss: 0.50004 - acc: 0.7809 -- iter: 6/6\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m0.49692\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 187 | loss: 0.49692 - acc: 0.7862 -- iter: 6/6\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m0.49386\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 188 | loss: 0.49386 - acc: 0.7909 -- iter: 6/6\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m0.49085\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 189 | loss: 0.49085 - acc: 0.7951 -- iter: 6/6\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m0.48789\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 190 | loss: 0.48789 - acc: 0.7989 -- iter: 6/6\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m0.48497\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 191 | loss: 0.48497 - acc: 0.8024 -- iter: 6/6\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m0.48209\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 192 | loss: 0.48209 - acc: 0.8055 -- iter: 6/6\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m0.47926\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 193 | loss: 0.47926 - acc: 0.8083 -- iter: 6/6\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m0.47646\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 194 | loss: 0.47646 - acc: 0.8108 -- iter: 6/6\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m0.47370\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 195 | loss: 0.47370 - acc: 0.8130 -- iter: 6/6\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m0.47097\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 196 | loss: 0.47097 - acc: 0.8151 -- iter: 6/6\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m0.46827\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 197 | loss: 0.46827 - acc: 0.8169 -- iter: 6/6\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m0.46560\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 198 | loss: 0.46560 - acc: 0.8185 -- iter: 6/6\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m0.46297\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 199 | loss: 0.46297 - acc: 0.8200 -- iter: 6/6\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m0.46036\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 200 | loss: 0.46036 - acc: 0.8213 -- iter: 6/6\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m0.45778\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 201 | loss: 0.45778 - acc: 0.8225 -- iter: 6/6\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m0.45523\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 202 | loss: 0.45523 - acc: 0.8236 -- iter: 6/6\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m0.45271\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 203 | loss: 0.45271 - acc: 0.8246 -- iter: 6/6\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m0.45022\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 204 | loss: 0.45022 - acc: 0.8255 -- iter: 6/6\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m0.44776\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 205 | loss: 0.44776 - acc: 0.8263 -- iter: 6/6\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m0.44532\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 206 | loss: 0.44532 - acc: 0.8270 -- iter: 6/6\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m0.44291\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 207 | loss: 0.44291 - acc: 0.8276 -- iter: 6/6\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m0.44053\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 208 | loss: 0.44053 - acc: 0.8282 -- iter: 6/6\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m0.43818\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 209 | loss: 0.43818 - acc: 0.8287 -- iter: 6/6\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m0.43586\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 210 | loss: 0.43586 - acc: 0.8292 -- iter: 6/6\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m0.43356\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 211 | loss: 0.43356 - acc: 0.8296 -- iter: 6/6\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m0.43128\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 212 | loss: 0.43128 - acc: 0.8299 -- iter: 6/6\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m0.42903\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 213 | loss: 0.42903 - acc: 0.8303 -- iter: 6/6\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m0.42680\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 214 | loss: 0.42680 - acc: 0.8306 -- iter: 6/6\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m0.42458\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 215 | loss: 0.42458 - acc: 0.8309 -- iter: 6/6\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m0.42238\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 216 | loss: 0.42238 - acc: 0.8311 -- iter: 6/6\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m0.42019\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 217 | loss: 0.42019 - acc: 0.8313 -- iter: 6/6\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m0.41800\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 218 | loss: 0.41800 - acc: 0.8482 -- iter: 6/6\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m0.41582\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 219 | loss: 0.41582 - acc: 0.8634 -- iter: 6/6\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m0.41363\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 220 | loss: 0.41363 - acc: 0.8770 -- iter: 6/6\n",
      "--\n",
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m0.41144\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 221 | loss: 0.41144 - acc: 0.8893 -- iter: 6/6\n",
      "--\n",
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m0.40924\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 222 | loss: 0.40924 - acc: 0.9004 -- iter: 6/6\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m0.40703\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 223 | loss: 0.40703 - acc: 0.9104 -- iter: 6/6\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m0.40481\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 224 | loss: 0.40481 - acc: 0.9193 -- iter: 6/6\n",
      "--\n",
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m0.40256\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 225 | loss: 0.40256 - acc: 0.9274 -- iter: 6/6\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m0.40030\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 226 | loss: 0.40030 - acc: 0.9347 -- iter: 6/6\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m0.39801\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 227 | loss: 0.39801 - acc: 0.9412 -- iter: 6/6\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m0.39568\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 228 | loss: 0.39568 - acc: 0.9471 -- iter: 6/6\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m0.39333\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 229 | loss: 0.39333 - acc: 0.9524 -- iter: 6/6\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m0.39093\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 230 | loss: 0.39093 - acc: 0.9571 -- iter: 6/6\n",
      "--\n",
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m0.38849\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 231 | loss: 0.38849 - acc: 0.9614 -- iter: 6/6\n",
      "--\n",
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m0.38601\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 232 | loss: 0.38601 - acc: 0.9653 -- iter: 6/6\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m0.38347\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 233 | loss: 0.38347 - acc: 0.9687 -- iter: 6/6\n",
      "--\n",
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m0.38088\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 234 | loss: 0.38088 - acc: 0.9719 -- iter: 6/6\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m0.37822\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 235 | loss: 0.37822 - acc: 0.9747 -- iter: 6/6\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m0.37550\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 236 | loss: 0.37550 - acc: 0.9772 -- iter: 6/6\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m0.37270\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 237 | loss: 0.37270 - acc: 0.9795 -- iter: 6/6\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m0.36983\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 238 | loss: 0.36983 - acc: 0.9815 -- iter: 6/6\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.36687\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 239 | loss: 0.36687 - acc: 0.9834 -- iter: 6/6\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.36383\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 240 | loss: 0.36383 - acc: 0.9851 -- iter: 6/6\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m0.36069\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 241 | loss: 0.36069 - acc: 0.9865 -- iter: 6/6\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m0.35746\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 242 | loss: 0.35746 - acc: 0.9879 -- iter: 6/6\n",
      "--\n",
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m0.35413\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 243 | loss: 0.35413 - acc: 0.9891 -- iter: 6/6\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m0.35069\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 244 | loss: 0.35069 - acc: 0.9902 -- iter: 6/6\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m0.34714\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 245 | loss: 0.34714 - acc: 0.9912 -- iter: 6/6\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m0.34347\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 246 | loss: 0.34347 - acc: 0.9921 -- iter: 6/6\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m0.33969\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 247 | loss: 0.33969 - acc: 0.9929 -- iter: 6/6\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m0.33579\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 248 | loss: 0.33579 - acc: 0.9936 -- iter: 6/6\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m0.33176\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 249 | loss: 0.33176 - acc: 0.9942 -- iter: 6/6\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m0.32760\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 250 | loss: 0.32760 - acc: 0.9948 -- iter: 6/6\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m0.32331\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 251 | loss: 0.32331 - acc: 0.9953 -- iter: 6/6\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m0.31889\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 252 | loss: 0.31889 - acc: 0.9958 -- iter: 6/6\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m0.31433\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 253 | loss: 0.31433 - acc: 0.9962 -- iter: 6/6\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m0.30963\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 254 | loss: 0.30963 - acc: 0.9966 -- iter: 6/6\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m0.30480\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 255 | loss: 0.30480 - acc: 0.9969 -- iter: 6/6\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m0.29984\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 256 | loss: 0.29984 - acc: 0.9972 -- iter: 6/6\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m0.29474\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 257 | loss: 0.29474 - acc: 0.9975 -- iter: 6/6\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m0.28951\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 258 | loss: 0.28951 - acc: 0.9978 -- iter: 6/6\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m0.28415\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 259 | loss: 0.28415 - acc: 0.9980 -- iter: 6/6\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m0.27866\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 260 | loss: 0.27866 - acc: 0.9982 -- iter: 6/6\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m0.27306\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 261 | loss: 0.27306 - acc: 0.9984 -- iter: 6/6\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m0.26734\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 262 | loss: 0.26734 - acc: 0.9985 -- iter: 6/6\n",
      "--\n",
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m0.26151\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 263 | loss: 0.26151 - acc: 0.9987 -- iter: 6/6\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m0.25559\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 264 | loss: 0.25559 - acc: 0.9988 -- iter: 6/6\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m0.24957\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 265 | loss: 0.24957 - acc: 0.9989 -- iter: 6/6\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m0.24347\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 266 | loss: 0.24347 - acc: 0.9990 -- iter: 6/6\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m0.23730\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 267 | loss: 0.23730 - acc: 0.9991 -- iter: 6/6\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m0.23108\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 268 | loss: 0.23108 - acc: 0.9992 -- iter: 6/6\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m0.22480\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 269 | loss: 0.22480 - acc: 0.9993 -- iter: 6/6\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m0.21848\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 270 | loss: 0.21848 - acc: 0.9994 -- iter: 6/6\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m0.21215\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 271 | loss: 0.21215 - acc: 0.9994 -- iter: 6/6\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m0.20580\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 272 | loss: 0.20580 - acc: 0.9995 -- iter: 6/6\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m0.19946\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 273 | loss: 0.19946 - acc: 0.9995 -- iter: 6/6\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m0.19313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 274 | loss: 0.19313 - acc: 0.9996 -- iter: 6/6\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m0.18683\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 275 | loss: 0.18683 - acc: 0.9996 -- iter: 6/6\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m0.76120\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 276 | loss: 0.76120 - acc: 0.9330 -- iter: 6/6\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m0.69710\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 277 | loss: 0.69710 - acc: 0.9397 -- iter: 6/6\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m0.63905\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 278 | loss: 0.63905 - acc: 0.9457 -- iter: 6/6\n",
      "--\n",
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m0.58647\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 279 | loss: 0.58647 - acc: 0.9512 -- iter: 6/6\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m0.53885\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 280 | loss: 0.53885 - acc: 0.9560 -- iter: 6/6\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m0.49568\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 281 | loss: 0.49568 - acc: 0.9604 -- iter: 6/6\n",
      "--\n",
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m0.45651\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 282 | loss: 0.45651 - acc: 0.9644 -- iter: 6/6\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m0.42091\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 283 | loss: 0.42091 - acc: 0.9680 -- iter: 6/6\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m0.38849\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 284 | loss: 0.38849 - acc: 0.9712 -- iter: 6/6\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m0.35890\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 285 | loss: 0.35890 - acc: 0.9740 -- iter: 6/6\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m0.33185\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 286 | loss: 0.33185 - acc: 0.9766 -- iter: 6/6\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m0.30707\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 287 | loss: 0.30707 - acc: 0.9790 -- iter: 6/6\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m0.28435\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 288 | loss: 0.28435 - acc: 0.9811 -- iter: 6/6\n",
      "--\n",
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m0.26350\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 289 | loss: 0.26350 - acc: 0.9830 -- iter: 6/6\n",
      "--\n",
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m0.24435\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 290 | loss: 0.24435 - acc: 0.9847 -- iter: 6/6\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m0.22676\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 291 | loss: 0.22676 - acc: 0.9862 -- iter: 6/6\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m0.21060\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 292 | loss: 0.21060 - acc: 0.9876 -- iter: 6/6\n",
      "--\n",
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m0.19574\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 293 | loss: 0.19574 - acc: 0.9888 -- iter: 6/6\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m0.18209\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 294 | loss: 0.18209 - acc: 0.9899 -- iter: 6/6\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m0.16953\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 295 | loss: 0.16953 - acc: 0.9909 -- iter: 6/6\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m0.15797\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 296 | loss: 0.15797 - acc: 0.9919 -- iter: 6/6\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m0.14734\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 297 | loss: 0.14734 - acc: 0.9927 -- iter: 6/6\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m0.13756\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 298 | loss: 0.13756 - acc: 0.9934 -- iter: 6/6\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m0.12854\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 299 | loss: 0.12854 - acc: 0.9941 -- iter: 6/6\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m0.12023\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 300 | loss: 0.12023 - acc: 0.9947 -- iter: 6/6\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m0.11257\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 301 | loss: 0.11257 - acc: 0.9952 -- iter: 6/6\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m0.10550\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 302 | loss: 0.10550 - acc: 0.9957 -- iter: 6/6\n",
      "--\n",
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m0.09898\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 303 | loss: 0.09898 - acc: 0.9961 -- iter: 6/6\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m0.09295\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 304 | loss: 0.09295 - acc: 0.9965 -- iter: 6/6\n",
      "--\n",
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m0.08738\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 305 | loss: 0.08738 - acc: 0.9968 -- iter: 6/6\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m0.08223\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 306 | loss: 0.08223 - acc: 0.9972 -- iter: 6/6\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m0.07746\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 307 | loss: 0.07746 - acc: 0.9974 -- iter: 6/6\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m0.07305\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 308 | loss: 0.07305 - acc: 0.9977 -- iter: 6/6\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m0.06896\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 309 | loss: 0.06896 - acc: 0.9979 -- iter: 6/6\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m0.06516\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 310 | loss: 0.06516 - acc: 0.9981 -- iter: 6/6\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m0.06164\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 311 | loss: 0.06164 - acc: 0.9983 -- iter: 6/6\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m0.05838\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 312 | loss: 0.05838 - acc: 0.9985 -- iter: 6/6\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m0.05534\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 313 | loss: 0.05534 - acc: 0.9986 -- iter: 6/6\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m0.05252\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 314 | loss: 0.05252 - acc: 0.9988 -- iter: 6/6\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m0.04990\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 315 | loss: 0.04990 - acc: 0.9989 -- iter: 6/6\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m0.04745\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 316 | loss: 0.04745 - acc: 0.9990 -- iter: 6/6\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m0.04518\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 317 | loss: 0.04518 - acc: 0.9991 -- iter: 6/6\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m0.04306\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 318 | loss: 0.04306 - acc: 0.9992 -- iter: 6/6\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m0.04108\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 319 | loss: 0.04108 - acc: 0.9993 -- iter: 6/6\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m0.03923\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 320 | loss: 0.03923 - acc: 0.9994 -- iter: 6/6\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m0.03751\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 321 | loss: 0.03751 - acc: 0.9994 -- iter: 6/6\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m0.03589\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 322 | loss: 0.03589 - acc: 0.9995 -- iter: 6/6\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m0.03439\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 323 | loss: 0.03439 - acc: 0.9995 -- iter: 6/6\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m0.03298\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 324 | loss: 0.03298 - acc: 0.9996 -- iter: 6/6\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m0.03165\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 325 | loss: 0.03165 - acc: 0.9996 -- iter: 6/6\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m0.03042\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 326 | loss: 0.03042 - acc: 0.9997 -- iter: 6/6\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m0.02925\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 327 | loss: 0.02925 - acc: 0.9997 -- iter: 6/6\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m0.35522\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 328 | loss: 0.35522 - acc: 0.9497 -- iter: 6/6\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m0.32152\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 329 | loss: 0.32152 - acc: 0.9547 -- iter: 6/6\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m0.29119\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 330 | loss: 0.29119 - acc: 0.9593 -- iter: 6/6\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m0.26390\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 331 | loss: 0.26390 - acc: 0.9633 -- iter: 6/6\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m0.23935\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 332 | loss: 0.23935 - acc: 0.9670 -- iter: 6/6\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m0.21729\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 333 | loss: 0.21729 - acc: 0.9703 -- iter: 6/6\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m0.19748\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 334 | loss: 0.19748 - acc: 0.9733 -- iter: 6/6\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m0.17969\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 335 | loss: 0.17969 - acc: 0.9760 -- iter: 6/6\n",
      "--\n",
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m0.16373\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 336 | loss: 0.16373 - acc: 0.9784 -- iter: 6/6\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m0.14941\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 337 | loss: 0.14941 - acc: 0.9805 -- iter: 6/6\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m0.13654\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 338 | loss: 0.13654 - acc: 0.9825 -- iter: 6/6\n",
      "--\n",
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m0.12497\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 339 | loss: 0.12497 - acc: 0.9842 -- iter: 6/6\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m0.11453\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 340 | loss: 0.11453 - acc: 0.9858 -- iter: 6/6\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m0.10509\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 341 | loss: 0.10509 - acc: 0.9872 -- iter: 6/6\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m0.09654\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 342 | loss: 0.09654 - acc: 0.9885 -- iter: 6/6\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m0.08877\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 343 | loss: 0.08877 - acc: 0.9896 -- iter: 6/6\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m0.08171\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 344 | loss: 0.08171 - acc: 0.9907 -- iter: 6/6\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m0.07528\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 345 | loss: 0.07528 - acc: 0.9916 -- iter: 6/6\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m0.47163\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 346 | loss: 0.47163 - acc: 0.9258 -- iter: 6/6\n",
      "--\n",
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m0.42615\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 347 | loss: 0.42615 - acc: 0.9332 -- iter: 6/6\n",
      "--\n",
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m0.38523\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 348 | loss: 0.38523 - acc: 0.9399 -- iter: 6/6\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m0.34843\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 349 | loss: 0.34843 - acc: 0.9459 -- iter: 6/6\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m0.31533\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 350 | loss: 0.31533 - acc: 0.9513 -- iter: 6/6\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m0.28557\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 351 | loss: 0.28557 - acc: 0.9562 -- iter: 6/6\n",
      "--\n",
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m0.25883\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 352 | loss: 0.25883 - acc: 0.9606 -- iter: 6/6\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m0.23479\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 353 | loss: 0.23479 - acc: 0.9645 -- iter: 6/6\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m0.21319\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 354 | loss: 0.21319 - acc: 0.9681 -- iter: 6/6\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m0.19378\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 355 | loss: 0.19378 - acc: 0.9712 -- iter: 6/6\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m0.17633\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 356 | loss: 0.17633 - acc: 0.9741 -- iter: 6/6\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m0.16064\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 357 | loss: 0.16064 - acc: 0.9767 -- iter: 6/6\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m0.14651\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 358 | loss: 0.14651 - acc: 0.9790 -- iter: 6/6\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m0.13379\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 359 | loss: 0.13379 - acc: 0.9811 -- iter: 6/6\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m0.12231\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 360 | loss: 0.12231 - acc: 0.9830 -- iter: 6/6\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m0.11196\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 361 | loss: 0.11196 - acc: 0.9847 -- iter: 6/6\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m0.10260\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 362 | loss: 0.10260 - acc: 0.9862 -- iter: 6/6\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m0.09414\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 363 | loss: 0.09414 - acc: 0.9876 -- iter: 6/6\n",
      "--\n",
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m0.08649\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 364 | loss: 0.08649 - acc: 0.9889 -- iter: 6/6\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m0.07957\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 365 | loss: 0.07957 - acc: 0.9900 -- iter: 6/6\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m0.07329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 366 | loss: 0.07329 - acc: 0.9910 -- iter: 6/6\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m0.06760\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 367 | loss: 0.06760 - acc: 0.9919 -- iter: 6/6\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m0.06245\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 368 | loss: 0.06245 - acc: 0.9927 -- iter: 6/6\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m0.05777\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 369 | loss: 0.05777 - acc: 0.9934 -- iter: 6/6\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m0.05353\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 370 | loss: 0.05353 - acc: 0.9941 -- iter: 6/6\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m0.04969\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 371 | loss: 0.04969 - acc: 0.9947 -- iter: 6/6\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m0.04620\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 372 | loss: 0.04620 - acc: 0.9952 -- iter: 6/6\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m0.04303\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 373 | loss: 0.04303 - acc: 0.9957 -- iter: 6/6\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m0.04015\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 374 | loss: 0.04015 - acc: 0.9961 -- iter: 6/6\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m0.03753\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 375 | loss: 0.03753 - acc: 0.9965 -- iter: 6/6\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m0.03516\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 376 | loss: 0.03516 - acc: 0.9969 -- iter: 6/6\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m0.03300\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 377 | loss: 0.03300 - acc: 0.9972 -- iter: 6/6\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m0.03103\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 378 | loss: 0.03103 - acc: 0.9975 -- iter: 6/6\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m0.02925\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 379 | loss: 0.02925 - acc: 0.9977 -- iter: 6/6\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m0.02762\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 380 | loss: 0.02762 - acc: 0.9979 -- iter: 6/6\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m0.02613\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 381 | loss: 0.02613 - acc: 0.9981 -- iter: 6/6\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m0.02478\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 382 | loss: 0.02478 - acc: 0.9983 -- iter: 6/6\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m0.02355\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 383 | loss: 0.02355 - acc: 0.9985 -- iter: 6/6\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m0.02242\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 384 | loss: 0.02242 - acc: 0.9986 -- iter: 6/6\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m0.02139\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 385 | loss: 0.02139 - acc: 0.9988 -- iter: 6/6\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m0.02044\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 386 | loss: 0.02044 - acc: 0.9989 -- iter: 6/6\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m0.01958\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 387 | loss: 0.01958 - acc: 0.9990 -- iter: 6/6\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m0.01878\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 388 | loss: 0.01878 - acc: 0.9991 -- iter: 6/6\n",
      "--\n",
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m0.01805\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 389 | loss: 0.01805 - acc: 0.9992 -- iter: 6/6\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m0.01738\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 390 | loss: 0.01738 - acc: 0.9993 -- iter: 6/6\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m0.01676\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 391 | loss: 0.01676 - acc: 0.9994 -- iter: 6/6\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m0.01619\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 392 | loss: 0.01619 - acc: 0.9994 -- iter: 6/6\n",
      "--\n",
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m0.01567\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 393 | loss: 0.01567 - acc: 0.9995 -- iter: 6/6\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m0.01518\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 394 | loss: 0.01518 - acc: 0.9995 -- iter: 6/6\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m0.01473\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 395 | loss: 0.01473 - acc: 0.9996 -- iter: 6/6\n",
      "--\n",
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m0.01431\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 396 | loss: 0.01431 - acc: 0.9996 -- iter: 6/6\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m0.01392\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 397 | loss: 0.01392 - acc: 0.9997 -- iter: 6/6\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m0.01356\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 398 | loss: 0.01356 - acc: 0.9997 -- iter: 6/6\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m0.01322\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 399 | loss: 0.01322 - acc: 0.9997 -- iter: 6/6\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m0.01290\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 400 | loss: 0.01290 - acc: 0.9997 -- iter: 6/6\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m0.01260\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 401 | loss: 0.01260 - acc: 0.9998 -- iter: 6/6\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m0.01233\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 402 | loss: 0.01233 - acc: 0.9998 -- iter: 6/6\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m0.01206\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 403 | loss: 0.01206 - acc: 0.9998 -- iter: 6/6\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m0.01182\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 404 | loss: 0.01182 - acc: 0.9998 -- iter: 6/6\n",
      "--\n",
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m0.01158\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 405 | loss: 0.01158 - acc: 0.9999 -- iter: 6/6\n",
      "--\n",
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m0.01136\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 406 | loss: 0.01136 - acc: 0.9999 -- iter: 6/6\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m0.01116\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 407 | loss: 0.01116 - acc: 0.9999 -- iter: 6/6\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m0.01096\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 408 | loss: 0.01096 - acc: 0.9999 -- iter: 6/6\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m0.01077\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 409 | loss: 0.01077 - acc: 0.9999 -- iter: 6/6\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m0.01059\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 410 | loss: 0.01059 - acc: 0.9999 -- iter: 6/6\n",
      "--\n",
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m0.01042\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 411 | loss: 0.01042 - acc: 0.9999 -- iter: 6/6\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m0.01026\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 412 | loss: 0.01026 - acc: 0.9999 -- iter: 6/6\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m0.01010\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 413 | loss: 0.01010 - acc: 0.9999 -- iter: 6/6\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m0.00995\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 414 | loss: 0.00995 - acc: 0.9999 -- iter: 6/6\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m0.00981\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 415 | loss: 0.00981 - acc: 0.9999 -- iter: 6/6\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m0.00967\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 416 | loss: 0.00967 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m0.00954\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 417 | loss: 0.00954 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m0.00941\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 418 | loss: 0.00941 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m0.00928\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 419 | loss: 0.00928 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m0.00916\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 420 | loss: 0.00916 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m0.00905\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 421 | loss: 0.00905 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m0.00893\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 422 | loss: 0.00893 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m0.00883\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 423 | loss: 0.00883 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m0.00872\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 424 | loss: 0.00872 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m0.00862\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 425 | loss: 0.00862 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m0.00852\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 426 | loss: 0.00852 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m0.00842\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 427 | loss: 0.00842 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m0.00833\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 428 | loss: 0.00833 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m0.00823\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 429 | loss: 0.00823 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m0.00814\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 430 | loss: 0.00814 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m0.00805\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 431 | loss: 0.00805 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m0.00797\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 432 | loss: 0.00797 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m0.00788\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 433 | loss: 0.00788 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m0.00780\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 434 | loss: 0.00780 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m0.00772\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 435 | loss: 0.00772 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m0.00764\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 436 | loss: 0.00764 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m0.00757\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 437 | loss: 0.00757 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m0.00749\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 438 | loss: 0.00749 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m0.00742\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 439 | loss: 0.00742 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m0.00734\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 440 | loss: 0.00734 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m0.00727\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 441 | loss: 0.00727 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m0.00720\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 442 | loss: 0.00720 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m0.00713\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 443 | loss: 0.00713 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m0.00707\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 444 | loss: 0.00707 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m0.00700\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 445 | loss: 0.00700 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m0.00693\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 446 | loss: 0.00693 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m0.00687\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 447 | loss: 0.00687 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m0.00681\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 448 | loss: 0.00681 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m0.00675\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 449 | loss: 0.00675 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m0.00668\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 450 | loss: 0.00668 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m0.00663\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 451 | loss: 0.00663 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m0.00657\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 452 | loss: 0.00657 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m0.00651\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 453 | loss: 0.00651 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m0.00645\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 454 | loss: 0.00645 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m0.00639\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 455 | loss: 0.00639 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m0.00634\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 456 | loss: 0.00634 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m0.00628\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 457 | loss: 0.00628 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m0.00623\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 458 | loss: 0.00623 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m0.00618\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 459 | loss: 0.00618 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m0.00613\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 460 | loss: 0.00613 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m0.00607\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 461 | loss: 0.00607 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m0.00602\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 462 | loss: 0.00602 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m0.00597\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 463 | loss: 0.00597 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m0.00592\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 464 | loss: 0.00592 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m0.00588\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 465 | loss: 0.00588 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m0.00583\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 466 | loss: 0.00583 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m0.00578\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 467 | loss: 0.00578 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m0.00573\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 468 | loss: 0.00573 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m0.00569\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 469 | loss: 0.00569 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m0.00564\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 470 | loss: 0.00564 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m0.00560\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 471 | loss: 0.00560 - acc: 1.0000 -- iter: 6/6\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m0.00555\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 472 | loss: 0.00555 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m0.00551\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 473 | loss: 0.00551 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m0.00547\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 474 | loss: 0.00547 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m0.00543\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 475 | loss: 0.00543 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m0.00538\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 476 | loss: 0.00538 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m0.00534\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 477 | loss: 0.00534 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m0.00530\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 478 | loss: 0.00530 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m0.00526\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 479 | loss: 0.00526 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m0.00522\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 480 | loss: 0.00522 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m0.00518\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 481 | loss: 0.00518 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m0.00514\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 482 | loss: 0.00514 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m0.00511\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 483 | loss: 0.00511 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m0.00507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 484 | loss: 0.00507 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m0.00503\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 485 | loss: 0.00503 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m0.00499\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 486 | loss: 0.00499 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m0.00496\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 487 | loss: 0.00496 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m0.00492\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 488 | loss: 0.00492 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m0.00489\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 489 | loss: 0.00489 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m0.00485\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 490 | loss: 0.00485 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m0.00482\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 491 | loss: 0.00482 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m0.00478\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 492 | loss: 0.00478 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m0.00475\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 493 | loss: 0.00475 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m0.00471\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 494 | loss: 0.00471 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m0.00468\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 495 | loss: 0.00468 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m0.00465\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 496 | loss: 0.00465 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m0.00462\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 497 | loss: 0.00462 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m0.00458\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 498 | loss: 0.00458 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m0.00455\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 499 | loss: 0.00455 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m0.00452\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 500 | loss: 0.00452 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 501  | total loss: \u001b[1m\u001b[32m0.00449\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 501 | loss: 0.00449 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 502  | total loss: \u001b[1m\u001b[32m0.00446\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 502 | loss: 0.00446 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 503  | total loss: \u001b[1m\u001b[32m0.00443\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 503 | loss: 0.00443 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 504  | total loss: \u001b[1m\u001b[32m0.00440\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 504 | loss: 0.00440 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 505  | total loss: \u001b[1m\u001b[32m0.00437\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 505 | loss: 0.00437 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 506  | total loss: \u001b[1m\u001b[32m0.00434\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 506 | loss: 0.00434 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 507  | total loss: \u001b[1m\u001b[32m0.00431\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 507 | loss: 0.00431 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 508  | total loss: \u001b[1m\u001b[32m0.00428\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 508 | loss: 0.00428 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 509  | total loss: \u001b[1m\u001b[32m0.00425\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 509 | loss: 0.00425 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 510  | total loss: \u001b[1m\u001b[32m0.00423\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 510 | loss: 0.00423 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 511  | total loss: \u001b[1m\u001b[32m0.00420\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 511 | loss: 0.00420 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 512  | total loss: \u001b[1m\u001b[32m0.00417\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 512 | loss: 0.00417 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 513  | total loss: \u001b[1m\u001b[32m0.00414\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 513 | loss: 0.00414 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 514  | total loss: \u001b[1m\u001b[32m0.00412\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 514 | loss: 0.00412 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 515  | total loss: \u001b[1m\u001b[32m0.00409\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 515 | loss: 0.00409 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 516  | total loss: \u001b[1m\u001b[32m0.00407\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 516 | loss: 0.00407 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 517  | total loss: \u001b[1m\u001b[32m0.00404\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 517 | loss: 0.00404 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 518  | total loss: \u001b[1m\u001b[32m0.00401\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 518 | loss: 0.00401 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 519  | total loss: \u001b[1m\u001b[32m0.00399\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 519 | loss: 0.00399 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 520  | total loss: \u001b[1m\u001b[32m0.00396\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 520 | loss: 0.00396 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 521  | total loss: \u001b[1m\u001b[32m0.00394\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 521 | loss: 0.00394 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 522  | total loss: \u001b[1m\u001b[32m0.00391\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 522 | loss: 0.00391 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 523  | total loss: \u001b[1m\u001b[32m0.00389\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 523 | loss: 0.00389 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 524  | total loss: \u001b[1m\u001b[32m0.00386\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 524 | loss: 0.00386 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 525  | total loss: \u001b[1m\u001b[32m0.00384\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 525 | loss: 0.00384 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 526  | total loss: \u001b[1m\u001b[32m0.00382\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 526 | loss: 0.00382 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 527  | total loss: \u001b[1m\u001b[32m0.00379\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 527 | loss: 0.00379 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 528  | total loss: \u001b[1m\u001b[32m0.00377\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 528 | loss: 0.00377 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 529  | total loss: \u001b[1m\u001b[32m0.00375\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 529 | loss: 0.00375 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 530  | total loss: \u001b[1m\u001b[32m0.00372\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 530 | loss: 0.00372 - acc: 1.0000 -- iter: 6/6\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 531  | total loss: \u001b[1m\u001b[32m0.00370\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 531 | loss: 0.00370 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 532  | total loss: \u001b[1m\u001b[32m0.00368\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 532 | loss: 0.00368 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 533  | total loss: \u001b[1m\u001b[32m0.00366\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 533 | loss: 0.00366 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 534  | total loss: \u001b[1m\u001b[32m0.00364\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 534 | loss: 0.00364 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 535  | total loss: \u001b[1m\u001b[32m0.00361\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 535 | loss: 0.00361 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 536  | total loss: \u001b[1m\u001b[32m0.00359\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 536 | loss: 0.00359 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 537  | total loss: \u001b[1m\u001b[32m0.00357\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 537 | loss: 0.00357 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 538  | total loss: \u001b[1m\u001b[32m0.00355\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 538 | loss: 0.00355 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 539  | total loss: \u001b[1m\u001b[32m0.00353\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 539 | loss: 0.00353 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 540  | total loss: \u001b[1m\u001b[32m0.00351\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 540 | loss: 0.00351 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 541  | total loss: \u001b[1m\u001b[32m0.00349\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 541 | loss: 0.00349 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 542  | total loss: \u001b[1m\u001b[32m0.00347\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 542 | loss: 0.00347 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 543  | total loss: \u001b[1m\u001b[32m0.00345\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 543 | loss: 0.00345 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 544  | total loss: \u001b[1m\u001b[32m0.00343\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 544 | loss: 0.00343 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 545  | total loss: \u001b[1m\u001b[32m0.00341\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 545 | loss: 0.00341 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 546  | total loss: \u001b[1m\u001b[32m0.00339\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 546 | loss: 0.00339 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 547  | total loss: \u001b[1m\u001b[32m0.00337\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 547 | loss: 0.00337 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 548  | total loss: \u001b[1m\u001b[32m0.00335\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 548 | loss: 0.00335 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 549  | total loss: \u001b[1m\u001b[32m0.00333\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 549 | loss: 0.00333 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 550  | total loss: \u001b[1m\u001b[32m0.00331\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 550 | loss: 0.00331 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 551  | total loss: \u001b[1m\u001b[32m0.00329\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 551 | loss: 0.00329 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 552  | total loss: \u001b[1m\u001b[32m0.00327\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 552 | loss: 0.00327 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 553  | total loss: \u001b[1m\u001b[32m0.00326\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 553 | loss: 0.00326 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 554  | total loss: \u001b[1m\u001b[32m0.00324\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 554 | loss: 0.00324 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 555  | total loss: \u001b[1m\u001b[32m0.00322\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 555 | loss: 0.00322 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 556  | total loss: \u001b[1m\u001b[32m0.00320\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 556 | loss: 0.00320 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 557  | total loss: \u001b[1m\u001b[32m0.00318\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 557 | loss: 0.00318 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 558  | total loss: \u001b[1m\u001b[32m0.00317\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 558 | loss: 0.00317 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 559  | total loss: \u001b[1m\u001b[32m0.00315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 559 | loss: 0.00315 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 560  | total loss: \u001b[1m\u001b[32m0.00313\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 560 | loss: 0.00313 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 561  | total loss: \u001b[1m\u001b[32m0.00311\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 561 | loss: 0.00311 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 562  | total loss: \u001b[1m\u001b[32m0.00310\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 562 | loss: 0.00310 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 563  | total loss: \u001b[1m\u001b[32m0.00308\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 563 | loss: 0.00308 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 564  | total loss: \u001b[1m\u001b[32m0.00306\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 564 | loss: 0.00306 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 565  | total loss: \u001b[1m\u001b[32m0.00305\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 565 | loss: 0.00305 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 566  | total loss: \u001b[1m\u001b[32m0.00303\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 566 | loss: 0.00303 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 567  | total loss: \u001b[1m\u001b[32m0.00302\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 567 | loss: 0.00302 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 568  | total loss: \u001b[1m\u001b[32m0.00300\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 568 | loss: 0.00300 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 569  | total loss: \u001b[1m\u001b[32m0.00298\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 569 | loss: 0.00298 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 570  | total loss: \u001b[1m\u001b[32m0.00297\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 570 | loss: 0.00297 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 571  | total loss: \u001b[1m\u001b[32m0.00295\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 571 | loss: 0.00295 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 572  | total loss: \u001b[1m\u001b[32m0.00294\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 572 | loss: 0.00294 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 573  | total loss: \u001b[1m\u001b[32m0.00292\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 573 | loss: 0.00292 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 574  | total loss: \u001b[1m\u001b[32m0.00291\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 574 | loss: 0.00291 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 575  | total loss: \u001b[1m\u001b[32m0.00289\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 575 | loss: 0.00289 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 576  | total loss: \u001b[1m\u001b[32m0.00288\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 576 | loss: 0.00288 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 577  | total loss: \u001b[1m\u001b[32m0.00286\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 577 | loss: 0.00286 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 578  | total loss: \u001b[1m\u001b[32m0.00285\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 578 | loss: 0.00285 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 579  | total loss: \u001b[1m\u001b[32m0.00283\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 579 | loss: 0.00283 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 580  | total loss: \u001b[1m\u001b[32m0.00282\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 580 | loss: 0.00282 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 581  | total loss: \u001b[1m\u001b[32m0.00280\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 581 | loss: 0.00280 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 582  | total loss: \u001b[1m\u001b[32m0.00279\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 582 | loss: 0.00279 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 583  | total loss: \u001b[1m\u001b[32m0.00277\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 583 | loss: 0.00277 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 584  | total loss: \u001b[1m\u001b[32m0.00276\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 584 | loss: 0.00276 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 585  | total loss: \u001b[1m\u001b[32m0.00275\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 585 | loss: 0.00275 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 586  | total loss: \u001b[1m\u001b[32m0.00273\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 586 | loss: 0.00273 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 587  | total loss: \u001b[1m\u001b[32m0.00272\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 587 | loss: 0.00272 - acc: 1.0000 -- iter: 6/6\n",
      "--\n",
      "Training Step: 588  | total loss: \u001b[1m\u001b[32m0.83354\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 588 | loss: 0.83354 - acc: 0.9167 -- iter: 6/6\n",
      "--\n",
      "Training Step: 589  | total loss: \u001b[1m\u001b[32m0.75046\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 589 | loss: 0.75046 - acc: 0.9250 -- iter: 6/6\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 590  | total loss: \u001b[1m\u001b[32m0.67569\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 590 | loss: 0.67569 - acc: 0.9325 -- iter: 6/6\n",
      "--\n",
      "Training Step: 591  | total loss: \u001b[1m\u001b[32m0.60842\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 591 | loss: 0.60842 - acc: 0.9392 -- iter: 6/6\n",
      "--\n",
      "Training Step: 592  | total loss: \u001b[1m\u001b[32m0.54789\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 592 | loss: 0.54789 - acc: 0.9453 -- iter: 6/6\n",
      "--\n",
      "Training Step: 593  | total loss: \u001b[1m\u001b[32m0.49343\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 593 | loss: 0.49343 - acc: 0.9508 -- iter: 6/6\n",
      "--\n",
      "Training Step: 594  | total loss: \u001b[1m\u001b[32m0.44443\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 594 | loss: 0.44443 - acc: 0.9557 -- iter: 6/6\n",
      "--\n",
      "Training Step: 595  | total loss: \u001b[1m\u001b[32m0.40036\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 595 | loss: 0.40036 - acc: 0.9601 -- iter: 6/6\n",
      "--\n",
      "Training Step: 596  | total loss: \u001b[1m\u001b[32m0.36071\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 596 | loss: 0.36071 - acc: 0.9641 -- iter: 6/6\n",
      "--\n",
      "Training Step: 597  | total loss: \u001b[1m\u001b[32m0.32505\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 597 | loss: 0.32505 - acc: 0.9677 -- iter: 6/6\n",
      "--\n",
      "Training Step: 598  | total loss: \u001b[1m\u001b[32m0.29299\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 598 | loss: 0.29299 - acc: 0.9709 -- iter: 6/6\n",
      "--\n",
      "Training Step: 599  | total loss: \u001b[1m\u001b[32m0.26415\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 599 | loss: 0.26415 - acc: 0.9738 -- iter: 6/6\n",
      "--\n",
      "Training Step: 600  | total loss: \u001b[1m\u001b[32m0.23821\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 600 | loss: 0.23821 - acc: 0.9765 -- iter: 6/6\n",
      "--\n",
      "Training Step: 601  | total loss: \u001b[1m\u001b[32m0.21488\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 601 | loss: 0.21488 - acc: 0.9788 -- iter: 6/6\n",
      "--\n",
      "Training Step: 602  | total loss: \u001b[1m\u001b[32m0.19390\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 602 | loss: 0.19390 - acc: 0.9809 -- iter: 6/6\n",
      "--\n",
      "Training Step: 603  | total loss: \u001b[1m\u001b[32m0.17502\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 603 | loss: 0.17502 - acc: 0.9828 -- iter: 6/6\n",
      "--\n",
      "Training Step: 604  | total loss: \u001b[1m\u001b[32m0.15804\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 604 | loss: 0.15804 - acc: 0.9846 -- iter: 6/6\n",
      "--\n",
      "Training Step: 605  | total loss: \u001b[1m\u001b[32m0.14275\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 605 | loss: 0.14275 - acc: 0.9861 -- iter: 6/6\n",
      "--\n",
      "Training Step: 606  | total loss: \u001b[1m\u001b[32m0.12899\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 606 | loss: 0.12899 - acc: 0.9875 -- iter: 6/6\n",
      "--\n",
      "Training Step: 607  | total loss: \u001b[1m\u001b[32m0.11659\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 607 | loss: 0.11659 - acc: 0.9887 -- iter: 6/6\n",
      "--\n",
      "Training Step: 608  | total loss: \u001b[1m\u001b[32m0.10542\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 608 | loss: 0.10542 - acc: 0.9899 -- iter: 6/6\n",
      "--\n",
      "Training Step: 609  | total loss: \u001b[1m\u001b[32m0.09536\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 609 | loss: 0.09536 - acc: 0.9909 -- iter: 6/6\n",
      "--\n",
      "Training Step: 610  | total loss: \u001b[1m\u001b[32m0.08629\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 610 | loss: 0.08629 - acc: 0.9918 -- iter: 6/6\n",
      "--\n",
      "Training Step: 611  | total loss: \u001b[1m\u001b[32m0.07811\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 611 | loss: 0.07811 - acc: 0.9926 -- iter: 6/6\n",
      "--\n",
      "Training Step: 612  | total loss: \u001b[1m\u001b[32m0.07074\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 612 | loss: 0.07074 - acc: 0.9934 -- iter: 6/6\n",
      "--\n",
      "Training Step: 613  | total loss: \u001b[1m\u001b[32m0.06409\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 613 | loss: 0.06409 - acc: 0.9940 -- iter: 6/6\n",
      "--\n",
      "Training Step: 614  | total loss: \u001b[1m\u001b[32m0.05809\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 614 | loss: 0.05809 - acc: 0.9946 -- iter: 6/6\n",
      "--\n",
      "Training Step: 615  | total loss: \u001b[1m\u001b[32m0.05269\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 615 | loss: 0.05269 - acc: 0.9952 -- iter: 6/6\n",
      "--\n",
      "Training Step: 616  | total loss: \u001b[1m\u001b[32m0.04781\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 616 | loss: 0.04781 - acc: 0.9956 -- iter: 6/6\n",
      "--\n",
      "Training Step: 617  | total loss: \u001b[1m\u001b[32m0.04342\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 617 | loss: 0.04342 - acc: 0.9961 -- iter: 6/6\n",
      "--\n",
      "Training Step: 618  | total loss: \u001b[1m\u001b[32m0.03945\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 618 | loss: 0.03945 - acc: 0.9965 -- iter: 6/6\n",
      "--\n",
      "Training Step: 619  | total loss: \u001b[1m\u001b[32m0.03588\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 619 | loss: 0.03588 - acc: 0.9968 -- iter: 6/6\n",
      "--\n",
      "Training Step: 620  | total loss: \u001b[1m\u001b[32m0.03265\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 620 | loss: 0.03265 - acc: 0.9971 -- iter: 6/6\n",
      "--\n",
      "Training Step: 621  | total loss: \u001b[1m\u001b[32m0.02974\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 621 | loss: 0.02974 - acc: 0.9974 -- iter: 6/6\n",
      "--\n",
      "Training Step: 622  | total loss: \u001b[1m\u001b[32m0.02712\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 622 | loss: 0.02712 - acc: 0.9977 -- iter: 6/6\n",
      "--\n",
      "Training Step: 623  | total loss: \u001b[1m\u001b[32m0.02475\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 623 | loss: 0.02475 - acc: 0.9979 -- iter: 6/6\n",
      "--\n",
      "Training Step: 624  | total loss: \u001b[1m\u001b[32m0.02262\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 624 | loss: 0.02262 - acc: 0.9981 -- iter: 6/6\n",
      "--\n",
      "Training Step: 625  | total loss: \u001b[1m\u001b[32m0.02069\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 625 | loss: 0.02069 - acc: 0.9983 -- iter: 6/6\n",
      "--\n",
      "Training Step: 626  | total loss: \u001b[1m\u001b[32m0.01896\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 626 | loss: 0.01896 - acc: 0.9985 -- iter: 6/6\n",
      "--\n",
      "Training Step: 627  | total loss: \u001b[1m\u001b[32m0.01739\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 627 | loss: 0.01739 - acc: 0.9986 -- iter: 6/6\n",
      "--\n",
      "Training Step: 628  | total loss: \u001b[1m\u001b[32m0.01598\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 628 | loss: 0.01598 - acc: 0.9988 -- iter: 6/6\n",
      "--\n",
      "Training Step: 629  | total loss: \u001b[1m\u001b[32m0.01470\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 629 | loss: 0.01470 - acc: 0.9989 -- iter: 6/6\n",
      "--\n",
      "Training Step: 630  | total loss: \u001b[1m\u001b[32m0.01355\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 630 | loss: 0.01355 - acc: 0.9990 -- iter: 6/6\n",
      "--\n",
      "Training Step: 631  | total loss: \u001b[1m\u001b[32m0.01252\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 631 | loss: 0.01252 - acc: 0.9991 -- iter: 6/6\n",
      "--\n",
      "Training Step: 632  | total loss: \u001b[1m\u001b[32m0.01158\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 632 | loss: 0.01158 - acc: 0.9992 -- iter: 6/6\n",
      "--\n",
      "Training Step: 633  | total loss: \u001b[1m\u001b[32m0.01074\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 633 | loss: 0.01074 - acc: 0.9993 -- iter: 6/6\n",
      "--\n",
      "Training Step: 634  | total loss: \u001b[1m\u001b[32m0.00997\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 634 | loss: 0.00997 - acc: 0.9993 -- iter: 6/6\n",
      "--\n",
      "Training Step: 635  | total loss: \u001b[1m\u001b[32m0.00928\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 635 | loss: 0.00928 - acc: 0.9994 -- iter: 6/6\n",
      "--\n",
      "Training Step: 636  | total loss: \u001b[1m\u001b[32m0.00866\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 636 | loss: 0.00866 - acc: 0.9995 -- iter: 6/6\n",
      "--\n",
      "Training Step: 637  | total loss: \u001b[1m\u001b[32m0.00810\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 637 | loss: 0.00810 - acc: 0.9995 -- iter: 6/6\n",
      "--\n",
      "Training Step: 638  | total loss: \u001b[1m\u001b[32m0.40564\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 638 | loss: 0.40564 - acc: 0.9496 -- iter: 6/6\n",
      "--\n",
      "Training Step: 639  | total loss: \u001b[1m\u001b[32m0.36540\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 639 | loss: 0.36540 - acc: 0.9546 -- iter: 6/6\n",
      "--\n",
      "Training Step: 640  | total loss: \u001b[1m\u001b[32m0.32921\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 640 | loss: 0.32921 - acc: 0.9592 -- iter: 6/6\n",
      "--\n",
      "Training Step: 641  | total loss: \u001b[1m\u001b[32m0.29666\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 641 | loss: 0.29666 - acc: 0.9632 -- iter: 6/6\n",
      "--\n",
      "Training Step: 642  | total loss: \u001b[1m\u001b[32m1.14824\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 642 | loss: 1.14824 - acc: 0.8836 -- iter: 6/6\n",
      "--\n",
      "Training Step: 643  | total loss: \u001b[1m\u001b[32m1.03388\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 643 | loss: 1.03388 - acc: 0.8952 -- iter: 6/6\n",
      "--\n",
      "Training Step: 644  | total loss: \u001b[1m\u001b[32m0.93102\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 644 | loss: 0.93102 - acc: 0.9057 -- iter: 6/6\n",
      "--\n",
      "Training Step: 645  | total loss: \u001b[1m\u001b[32m0.83850\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 645 | loss: 0.83850 - acc: 0.9151 -- iter: 6/6\n",
      "--\n",
      "Training Step: 646  | total loss: \u001b[1m\u001b[32m0.75529\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 646 | loss: 0.75529 - acc: 0.9236 -- iter: 6/6\n",
      "--\n",
      "Training Step: 647  | total loss: \u001b[1m\u001b[32m0.68046\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 647 | loss: 0.68046 - acc: 0.9313 -- iter: 6/6\n",
      "--\n",
      "Training Step: 648  | total loss: \u001b[1m\u001b[32m0.61315\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 648 | loss: 0.61315 - acc: 0.9381 -- iter: 6/6\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 649  | total loss: \u001b[1m\u001b[32m0.55260\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 649 | loss: 0.55260 - acc: 0.9443 -- iter: 6/6\n",
      "--\n",
      "Training Step: 650  | total loss: \u001b[1m\u001b[32m0.49814\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 650 | loss: 0.49814 - acc: 0.9499 -- iter: 6/6\n",
      "--\n",
      "Training Step: 651  | total loss: \u001b[1m\u001b[32m0.44914\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 651 | loss: 0.44914 - acc: 0.9549 -- iter: 6/6\n",
      "--\n",
      "Training Step: 652  | total loss: \u001b[1m\u001b[32m0.40505\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 652 | loss: 0.40505 - acc: 0.9594 -- iter: 6/6\n",
      "--\n",
      "Training Step: 653  | total loss: \u001b[1m\u001b[32m0.36537\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 653 | loss: 0.36537 - acc: 0.9635 -- iter: 6/6\n",
      "--\n",
      "Training Step: 654  | total loss: \u001b[1m\u001b[32m0.32966\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 654 | loss: 0.32966 - acc: 0.9671 -- iter: 6/6\n",
      "--\n",
      "Training Step: 655  | total loss: \u001b[1m\u001b[32m0.29751\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 655 | loss: 0.29751 - acc: 0.9704 -- iter: 6/6\n",
      "--\n",
      "Training Step: 656  | total loss: \u001b[1m\u001b[32m0.26856\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 656 | loss: 0.26856 - acc: 0.9734 -- iter: 6/6\n",
      "--\n",
      "Training Step: 657  | total loss: \u001b[1m\u001b[32m0.24249\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 657 | loss: 0.24249 - acc: 0.9760 -- iter: 6/6\n",
      "--\n",
      "Training Step: 658  | total loss: \u001b[1m\u001b[32m1.03581\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 658 | loss: 1.03581 - acc: 0.8951 -- iter: 6/6\n",
      "--\n",
      "Training Step: 659  | total loss: \u001b[1m\u001b[32m0.93302\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 659 | loss: 0.93302 - acc: 0.9056 -- iter: 6/6\n",
      "--\n",
      "Training Step: 660  | total loss: \u001b[1m\u001b[32m0.84052\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 660 | loss: 0.84052 - acc: 0.9150 -- iter: 6/6\n",
      "--\n",
      "Training Step: 661  | total loss: \u001b[1m\u001b[32m0.75729\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 661 | loss: 0.75729 - acc: 0.9235 -- iter: 6/6\n",
      "--\n",
      "Training Step: 662  | total loss: \u001b[1m\u001b[32m0.68240\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 662 | loss: 0.68240 - acc: 0.9312 -- iter: 6/6\n",
      "--\n",
      "Training Step: 663  | total loss: \u001b[1m\u001b[32m0.61501\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 663 | loss: 0.61501 - acc: 0.9381 -- iter: 6/6\n",
      "--\n",
      "Training Step: 664  | total loss: \u001b[1m\u001b[32m0.55437\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 664 | loss: 0.55437 - acc: 0.9442 -- iter: 6/6\n",
      "--\n",
      "Training Step: 665  | total loss: \u001b[1m\u001b[32m0.49982\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 665 | loss: 0.49982 - acc: 0.9498 -- iter: 6/6\n",
      "--\n",
      "Training Step: 666  | total loss: \u001b[1m\u001b[32m0.45073\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 666 | loss: 0.45073 - acc: 0.9548 -- iter: 6/6\n",
      "--\n",
      "Training Step: 667  | total loss: \u001b[1m\u001b[32m0.40656\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 667 | loss: 0.40656 - acc: 0.9594 -- iter: 6/6\n",
      "--\n",
      "Training Step: 668  | total loss: \u001b[1m\u001b[32m0.36682\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 668 | loss: 0.36682 - acc: 0.9634 -- iter: 6/6\n",
      "--\n",
      "Training Step: 669  | total loss: \u001b[1m\u001b[32m0.33107\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 669 | loss: 0.33107 - acc: 0.9671 -- iter: 6/6\n",
      "--\n",
      "Training Step: 670  | total loss: \u001b[1m\u001b[32m0.29890\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 670 | loss: 0.29890 - acc: 0.9704 -- iter: 6/6\n",
      "--\n",
      "Training Step: 671  | total loss: \u001b[1m\u001b[32m0.26995\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 671 | loss: 0.26995 - acc: 0.9733 -- iter: 6/6\n",
      "--\n",
      "Training Step: 672  | total loss: \u001b[1m\u001b[32m0.24390\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 672 | loss: 0.24390 - acc: 0.9760 -- iter: 6/6\n",
      "--\n",
      "Training Step: 673  | total loss: \u001b[1m\u001b[32m0.22046\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 673 | loss: 0.22046 - acc: 0.9784 -- iter: 6/6\n",
      "--\n",
      "Training Step: 674  | total loss: \u001b[1m\u001b[32m0.19937\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 674 | loss: 0.19937 - acc: 0.9806 -- iter: 6/6\n",
      "--\n",
      "Training Step: 675  | total loss: \u001b[1m\u001b[32m0.18039\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 675 | loss: 0.18039 - acc: 0.9825 -- iter: 6/6\n",
      "--\n",
      "Training Step: 676  | total loss: \u001b[1m\u001b[32m0.16331\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 676 | loss: 0.16331 - acc: 0.9843 -- iter: 6/6\n",
      "--\n",
      "Training Step: 677  | total loss: \u001b[1m\u001b[32m0.14793\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 677 | loss: 0.14793 - acc: 0.9858 -- iter: 6/6\n",
      "--\n",
      "Training Step: 678  | total loss: \u001b[1m\u001b[32m0.13410\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 678 | loss: 0.13410 - acc: 0.9872 -- iter: 6/6\n",
      "--\n",
      "Training Step: 679  | total loss: \u001b[1m\u001b[32m0.12164\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 679 | loss: 0.12164 - acc: 0.9885 -- iter: 6/6\n",
      "--\n",
      "Training Step: 680  | total loss: \u001b[1m\u001b[32m0.11043\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 680 | loss: 0.11043 - acc: 0.9897 -- iter: 6/6\n",
      "--\n",
      "Training Step: 681  | total loss: \u001b[1m\u001b[32m0.10033\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 681 | loss: 0.10033 - acc: 0.9907 -- iter: 6/6\n",
      "--\n",
      "Training Step: 682  | total loss: \u001b[1m\u001b[32m0.09124\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 682 | loss: 0.09124 - acc: 0.9916 -- iter: 6/6\n",
      "--\n",
      "Training Step: 683  | total loss: \u001b[1m\u001b[32m0.08306\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 683 | loss: 0.08306 - acc: 0.9925 -- iter: 6/6\n",
      "--\n",
      "Training Step: 684  | total loss: \u001b[1m\u001b[32m0.07568\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 684 | loss: 0.07568 - acc: 0.9932 -- iter: 6/6\n",
      "--\n",
      "Training Step: 685  | total loss: \u001b[1m\u001b[32m0.06904\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 685 | loss: 0.06904 - acc: 0.9939 -- iter: 6/6\n",
      "--\n",
      "Training Step: 686  | total loss: \u001b[1m\u001b[32m0.06306\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 686 | loss: 0.06306 - acc: 0.9945 -- iter: 6/6\n",
      "--\n",
      "Training Step: 687  | total loss: \u001b[1m\u001b[32m0.05767\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 687 | loss: 0.05767 - acc: 0.9951 -- iter: 6/6\n",
      "--\n",
      "Training Step: 688  | total loss: \u001b[1m\u001b[32m0.05281\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 688 | loss: 0.05281 - acc: 0.9956 -- iter: 6/6\n",
      "--\n",
      "Training Step: 689  | total loss: \u001b[1m\u001b[32m0.04843\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 689 | loss: 0.04843 - acc: 0.9960 -- iter: 6/6\n",
      "--\n",
      "Training Step: 690  | total loss: \u001b[1m\u001b[32m0.04448\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 690 | loss: 0.04448 - acc: 0.9964 -- iter: 6/6\n",
      "--\n",
      "Training Step: 691  | total loss: \u001b[1m\u001b[32m0.04092\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 691 | loss: 0.04092 - acc: 0.9968 -- iter: 6/6\n",
      "--\n",
      "Training Step: 692  | total loss: \u001b[1m\u001b[32m0.03771\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 692 | loss: 0.03771 - acc: 0.9971 -- iter: 6/6\n",
      "--\n",
      "Training Step: 693  | total loss: \u001b[1m\u001b[32m0.03481\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 693 | loss: 0.03481 - acc: 0.9974 -- iter: 6/6\n",
      "--\n",
      "Training Step: 694  | total loss: \u001b[1m\u001b[32m0.19197\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 694 | loss: 0.19197 - acc: 0.9643 -- iter: 6/6\n",
      "--\n",
      "Training Step: 695  | total loss: \u001b[1m\u001b[32m0.17366\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 695 | loss: 0.17366 - acc: 0.9679 -- iter: 6/6\n",
      "--\n",
      "Training Step: 696  | total loss: \u001b[1m\u001b[32m0.15720\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 696 | loss: 0.15720 - acc: 0.9711 -- iter: 6/6\n",
      "--\n",
      "Training Step: 697  | total loss: \u001b[1m\u001b[32m0.14240\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 697 | loss: 0.14240 - acc: 0.9740 -- iter: 6/6\n",
      "--\n",
      "Training Step: 698  | total loss: \u001b[1m\u001b[32m0.12910\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 698 | loss: 0.12910 - acc: 0.9766 -- iter: 6/6\n",
      "--\n",
      "Training Step: 699  | total loss: \u001b[1m\u001b[32m0.11715\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 699 | loss: 0.11715 - acc: 0.9789 -- iter: 6/6\n",
      "--\n",
      "Training Step: 700  | total loss: \u001b[1m\u001b[32m0.10640\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 700 | loss: 0.10640 - acc: 0.9810 -- iter: 6/6\n",
      "--\n",
      "Training Step: 701  | total loss: \u001b[1m\u001b[32m0.09674\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 701 | loss: 0.09674 - acc: 0.9829 -- iter: 6/6\n",
      "--\n",
      "Training Step: 702  | total loss: \u001b[1m\u001b[32m0.08805\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 702 | loss: 0.08805 - acc: 0.9846 -- iter: 6/6\n",
      "--\n",
      "Training Step: 703  | total loss: \u001b[1m\u001b[32m0.08023\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 703 | loss: 0.08023 - acc: 0.9862 -- iter: 6/6\n",
      "--\n",
      "Training Step: 704  | total loss: \u001b[1m\u001b[32m0.07321\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 704 | loss: 0.07321 - acc: 0.9876 -- iter: 6/6\n",
      "--\n",
      "Training Step: 705  | total loss: \u001b[1m\u001b[32m0.06689\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 705 | loss: 0.06689 - acc: 0.9888 -- iter: 6/6\n",
      "--\n",
      "Training Step: 706  | total loss: \u001b[1m\u001b[32m0.06121\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 706 | loss: 0.06121 - acc: 0.9899 -- iter: 6/6\n",
      "--\n",
      "Training Step: 707  | total loss: \u001b[1m\u001b[32m0.05609\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 707 | loss: 0.05609 - acc: 0.9909 -- iter: 6/6\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 708  | total loss: \u001b[1m\u001b[32m0.05149\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 708 | loss: 0.05149 - acc: 0.9918 -- iter: 6/6\n",
      "--\n",
      "Training Step: 709  | total loss: \u001b[1m\u001b[32m0.04734\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 709 | loss: 0.04734 - acc: 0.9927 -- iter: 6/6\n",
      "--\n",
      "Training Step: 710  | total loss: \u001b[1m\u001b[32m0.04361\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 710 | loss: 0.04361 - acc: 0.9934 -- iter: 6/6\n",
      "--\n",
      "Training Step: 711  | total loss: \u001b[1m\u001b[32m0.04025\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 711 | loss: 0.04025 - acc: 0.9940 -- iter: 6/6\n",
      "--\n",
      "Training Step: 712  | total loss: \u001b[1m\u001b[32m0.03723\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 712 | loss: 0.03723 - acc: 0.9946 -- iter: 6/6\n",
      "--\n",
      "Training Step: 713  | total loss: \u001b[1m\u001b[32m0.03450\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 713 | loss: 0.03450 - acc: 0.9952 -- iter: 6/6\n",
      "--\n",
      "Training Step: 714  | total loss: \u001b[1m\u001b[32m0.03204\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 714 | loss: 0.03204 - acc: 0.9957 -- iter: 6/6\n",
      "--\n",
      "Training Step: 715  | total loss: \u001b[1m\u001b[32m0.02982\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 715 | loss: 0.02982 - acc: 0.9961 -- iter: 6/6\n",
      "--\n",
      "Training Step: 716  | total loss: \u001b[1m\u001b[32m0.02782\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 716 | loss: 0.02782 - acc: 0.9965 -- iter: 6/6\n",
      "--\n",
      "Training Step: 717  | total loss: \u001b[1m\u001b[32m0.02601\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 717 | loss: 0.02601 - acc: 0.9968 -- iter: 6/6\n",
      "--\n",
      "Training Step: 718  | total loss: \u001b[1m\u001b[32m0.02438\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 718 | loss: 0.02438 - acc: 0.9972 -- iter: 6/6\n",
      "--\n",
      "Training Step: 719  | total loss: \u001b[1m\u001b[32m0.02290\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 719 | loss: 0.02290 - acc: 0.9974 -- iter: 6/6\n",
      "--\n",
      "Training Step: 720  | total loss: \u001b[1m\u001b[32m0.02156\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 720 | loss: 0.02156 - acc: 0.9977 -- iter: 6/6\n",
      "--\n",
      "Training Step: 721  | total loss: \u001b[1m\u001b[32m0.02035\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 721 | loss: 0.02035 - acc: 0.9979 -- iter: 6/6\n",
      "--\n",
      "Training Step: 722  | total loss: \u001b[1m\u001b[32m0.01926\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 722 | loss: 0.01926 - acc: 0.9981 -- iter: 6/6\n",
      "--\n",
      "Training Step: 723  | total loss: \u001b[1m\u001b[32m0.01826\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 723 | loss: 0.01826 - acc: 0.9983 -- iter: 6/6\n",
      "--\n",
      "Training Step: 724  | total loss: \u001b[1m\u001b[32m0.01736\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 724 | loss: 0.01736 - acc: 0.9985 -- iter: 6/6\n",
      "--\n",
      "Training Step: 725  | total loss: \u001b[1m\u001b[32m0.01654\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 725 | loss: 0.01654 - acc: 0.9986 -- iter: 6/6\n",
      "--\n",
      "Training Step: 726  | total loss: \u001b[1m\u001b[32m0.01580\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 726 | loss: 0.01580 - acc: 0.9988 -- iter: 6/6\n",
      "--\n",
      "Training Step: 727  | total loss: \u001b[1m\u001b[32m0.01512\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 727 | loss: 0.01512 - acc: 0.9989 -- iter: 6/6\n",
      "--\n",
      "Training Step: 728  | total loss: \u001b[1m\u001b[32m0.01450\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 728 | loss: 0.01450 - acc: 0.9990 -- iter: 6/6\n",
      "--\n",
      "Training Step: 729  | total loss: \u001b[1m\u001b[32m0.01394\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 729 | loss: 0.01394 - acc: 0.9991 -- iter: 6/6\n",
      "--\n",
      "Training Step: 730  | total loss: \u001b[1m\u001b[32m0.01342\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 730 | loss: 0.01342 - acc: 0.9992 -- iter: 6/6\n",
      "--\n",
      "Training Step: 731  | total loss: \u001b[1m\u001b[32m0.01295\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 731 | loss: 0.01295 - acc: 0.9993 -- iter: 6/6\n",
      "--\n",
      "Training Step: 732  | total loss: \u001b[1m\u001b[32m0.01252\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 732 | loss: 0.01252 - acc: 0.9993 -- iter: 6/6\n",
      "--\n",
      "Training Step: 733  | total loss: \u001b[1m\u001b[32m0.01212\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 733 | loss: 0.01212 - acc: 0.9994 -- iter: 6/6\n",
      "--\n",
      "Training Step: 734  | total loss: \u001b[1m\u001b[32m0.01175\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 734 | loss: 0.01175 - acc: 0.9995 -- iter: 6/6\n",
      "--\n",
      "Training Step: 735  | total loss: \u001b[1m\u001b[32m0.01142\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 735 | loss: 0.01142 - acc: 0.9995 -- iter: 6/6\n",
      "--\n",
      "Training Step: 736  | total loss: \u001b[1m\u001b[32m0.01111\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 736 | loss: 0.01111 - acc: 0.9996 -- iter: 6/6\n",
      "--\n",
      "Training Step: 737  | total loss: \u001b[1m\u001b[32m0.01082\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 737 | loss: 0.01082 - acc: 0.9996 -- iter: 6/6\n",
      "--\n",
      "Training Step: 738  | total loss: \u001b[1m\u001b[32m0.01055\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 738 | loss: 0.01055 - acc: 0.9997 -- iter: 6/6\n",
      "--\n",
      "Training Step: 739  | total loss: \u001b[1m\u001b[32m0.01031\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 739 | loss: 0.01031 - acc: 0.9997 -- iter: 6/6\n",
      "--\n",
      "Training Step: 740  | total loss: \u001b[1m\u001b[32m0.01008\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 740 | loss: 0.01008 - acc: 0.9997 -- iter: 6/6\n",
      "--\n",
      "Training Step: 741  | total loss: \u001b[1m\u001b[32m0.00986\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 741 | loss: 0.00986 - acc: 0.9997 -- iter: 6/6\n",
      "--\n",
      "Training Step: 742  | total loss: \u001b[1m\u001b[32m0.00966\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 742 | loss: 0.00966 - acc: 0.9998 -- iter: 6/6\n",
      "--\n",
      "Training Step: 743  | total loss: \u001b[1m\u001b[32m0.00948\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 743 | loss: 0.00948 - acc: 0.9998 -- iter: 6/6\n",
      "--\n",
      "Training Step: 744  | total loss: \u001b[1m\u001b[32m0.23868\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 744 | loss: 0.23868 - acc: 0.9665 -- iter: 6/6\n",
      "--\n",
      "Training Step: 745  | total loss: \u001b[1m\u001b[32m0.21558\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 745 | loss: 0.21558 - acc: 0.9698 -- iter: 6/6\n",
      "--\n",
      "Training Step: 746  | total loss: \u001b[1m\u001b[32m0.19478\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 746 | loss: 0.19478 - acc: 0.9729 -- iter: 6/6\n",
      "--\n",
      "Training Step: 747  | total loss: \u001b[1m\u001b[32m0.17607\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 747 | loss: 0.17607 - acc: 0.9756 -- iter: 6/6\n",
      "--\n",
      "Training Step: 748  | total loss: \u001b[1m\u001b[32m0.15923\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 748 | loss: 0.15923 - acc: 0.9780 -- iter: 6/6\n",
      "--\n",
      "Training Step: 749  | total loss: \u001b[1m\u001b[32m0.14407\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 749 | loss: 0.14407 - acc: 0.9802 -- iter: 6/6\n",
      "--\n",
      "Training Step: 750  | total loss: \u001b[1m\u001b[32m0.13044\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 750 | loss: 0.13044 - acc: 0.9822 -- iter: 6/6\n",
      "--\n",
      "Training Step: 751  | total loss: \u001b[1m\u001b[32m0.11817\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 751 | loss: 0.11817 - acc: 0.9840 -- iter: 6/6\n",
      "--\n",
      "Training Step: 752  | total loss: \u001b[1m\u001b[32m0.10715\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 752 | loss: 0.10715 - acc: 0.9856 -- iter: 6/6\n",
      "--\n",
      "Training Step: 753  | total loss: \u001b[1m\u001b[32m0.09723\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 753 | loss: 0.09723 - acc: 0.9870 -- iter: 6/6\n",
      "--\n",
      "Training Step: 754  | total loss: \u001b[1m\u001b[32m0.08832\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 754 | loss: 0.08832 - acc: 0.9883 -- iter: 6/6\n",
      "--\n",
      "Training Step: 755  | total loss: \u001b[1m\u001b[32m0.08031\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 755 | loss: 0.08031 - acc: 0.9895 -- iter: 6/6\n",
      "--\n",
      "Training Step: 756  | total loss: \u001b[1m\u001b[32m0.07312\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 756 | loss: 0.07312 - acc: 0.9905 -- iter: 6/6\n",
      "--\n",
      "Training Step: 757  | total loss: \u001b[1m\u001b[32m0.06666\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 757 | loss: 0.06666 - acc: 0.9915 -- iter: 6/6\n",
      "--\n",
      "Training Step: 758  | total loss: \u001b[1m\u001b[32m0.06086\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 758 | loss: 0.06086 - acc: 0.9923 -- iter: 6/6\n",
      "--\n",
      "Training Step: 759  | total loss: \u001b[1m\u001b[32m0.05564\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 759 | loss: 0.05564 - acc: 0.9931 -- iter: 6/6\n",
      "--\n",
      "Training Step: 760  | total loss: \u001b[1m\u001b[32m0.05096\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 760 | loss: 0.05096 - acc: 0.9938 -- iter: 6/6\n",
      "--\n",
      "Training Step: 761  | total loss: \u001b[1m\u001b[32m0.04674\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 761 | loss: 0.04674 - acc: 0.9944 -- iter: 6/6\n",
      "--\n",
      "Training Step: 762  | total loss: \u001b[1m\u001b[32m0.04295\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 762 | loss: 0.04295 - acc: 0.9950 -- iter: 6/6\n",
      "--\n",
      "Training Step: 763  | total loss: \u001b[1m\u001b[32m0.03954\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 763 | loss: 0.03954 - acc: 0.9955 -- iter: 6/6\n",
      "--\n",
      "Training Step: 764  | total loss: \u001b[1m\u001b[32m0.03647\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 764 | loss: 0.03647 - acc: 0.9959 -- iter: 6/6\n",
      "--\n",
      "Training Step: 765  | total loss: \u001b[1m\u001b[32m0.03370\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 765 | loss: 0.03370 - acc: 0.9963 -- iter: 6/6\n",
      "--\n",
      "Training Step: 766  | total loss: \u001b[1m\u001b[32m0.03119\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 766 | loss: 0.03119 - acc: 0.9967 -- iter: 6/6\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 767  | total loss: \u001b[1m\u001b[32m0.02893\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 767 | loss: 0.02893 - acc: 0.9970 -- iter: 6/6\n",
      "--\n",
      "Training Step: 768  | total loss: \u001b[1m\u001b[32m0.02688\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 768 | loss: 0.02688 - acc: 0.9973 -- iter: 6/6\n",
      "--\n",
      "Training Step: 769  | total loss: \u001b[1m\u001b[32m0.02502\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 769 | loss: 0.02502 - acc: 0.9976 -- iter: 6/6\n",
      "--\n",
      "Training Step: 770  | total loss: \u001b[1m\u001b[32m0.02334\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 770 | loss: 0.02334 - acc: 0.9978 -- iter: 6/6\n",
      "--\n",
      "Training Step: 771  | total loss: \u001b[1m\u001b[32m0.02181\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 771 | loss: 0.02181 - acc: 0.9981 -- iter: 6/6\n",
      "--\n",
      "Training Step: 772  | total loss: \u001b[1m\u001b[32m0.02042\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 772 | loss: 0.02042 - acc: 0.9982 -- iter: 6/6\n",
      "--\n",
      "Training Step: 773  | total loss: \u001b[1m\u001b[32m0.01916\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 773 | loss: 0.01916 - acc: 0.9984 -- iter: 6/6\n",
      "--\n",
      "Training Step: 774  | total loss: \u001b[1m\u001b[32m0.01801\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 774 | loss: 0.01801 - acc: 0.9986 -- iter: 6/6\n",
      "--\n",
      "Training Step: 775  | total loss: \u001b[1m\u001b[32m0.01696\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 775 | loss: 0.01696 - acc: 0.9987 -- iter: 6/6\n",
      "--\n",
      "Training Step: 776  | total loss: \u001b[1m\u001b[32m0.01600\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 776 | loss: 0.01600 - acc: 0.9988 -- iter: 6/6\n",
      "--\n",
      "Training Step: 777  | total loss: \u001b[1m\u001b[32m0.01513\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 777 | loss: 0.01513 - acc: 0.9990 -- iter: 6/6\n",
      "--\n",
      "Training Step: 778  | total loss: \u001b[1m\u001b[32m0.01433\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 778 | loss: 0.01433 - acc: 0.9991 -- iter: 6/6\n",
      "--\n",
      "Training Step: 779  | total loss: \u001b[1m\u001b[32m0.01361\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 779 | loss: 0.01361 - acc: 0.9992 -- iter: 6/6\n",
      "--\n",
      "Training Step: 780  | total loss: \u001b[1m\u001b[32m0.01294\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 780 | loss: 0.01294 - acc: 0.9992 -- iter: 6/6\n",
      "--\n",
      "Training Step: 781  | total loss: \u001b[1m\u001b[32m0.01234\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 781 | loss: 0.01234 - acc: 0.9993 -- iter: 6/6\n",
      "--\n",
      "Training Step: 782  | total loss: \u001b[1m\u001b[32m0.01178\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 782 | loss: 0.01178 - acc: 0.9994 -- iter: 6/6\n",
      "--\n",
      "Training Step: 783  | total loss: \u001b[1m\u001b[32m0.01127\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 783 | loss: 0.01127 - acc: 0.9994 -- iter: 6/6\n",
      "--\n",
      "Training Step: 784  | total loss: \u001b[1m\u001b[32m0.01081\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 784 | loss: 0.01081 - acc: 0.9995 -- iter: 6/6\n",
      "--\n",
      "Training Step: 785  | total loss: \u001b[1m\u001b[32m0.01038\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 785 | loss: 0.01038 - acc: 0.9996 -- iter: 6/6\n",
      "--\n",
      "Training Step: 786  | total loss: \u001b[1m\u001b[32m0.00999\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 786 | loss: 0.00999 - acc: 0.9996 -- iter: 6/6\n",
      "--\n",
      "Training Step: 787  | total loss: \u001b[1m\u001b[32m0.00963\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 787 | loss: 0.00963 - acc: 0.9996 -- iter: 6/6\n",
      "--\n",
      "Training Step: 788  | total loss: \u001b[1m\u001b[32m0.00930\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 788 | loss: 0.00930 - acc: 0.9997 -- iter: 6/6\n",
      "--\n",
      "Training Step: 789  | total loss: \u001b[1m\u001b[32m0.00900\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 789 | loss: 0.00900 - acc: 0.9997 -- iter: 6/6\n",
      "--\n",
      "Training Step: 790  | total loss: \u001b[1m\u001b[32m0.35449\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 790 | loss: 0.35449 - acc: 0.9497 -- iter: 6/6\n",
      "--\n",
      "Training Step: 791  | total loss: \u001b[1m\u001b[32m0.31967\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 791 | loss: 0.31967 - acc: 0.9548 -- iter: 6/6\n",
      "--\n",
      "Training Step: 792  | total loss: \u001b[1m\u001b[32m0.28834\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 792 | loss: 0.28834 - acc: 0.9593 -- iter: 6/6\n",
      "--\n",
      "Training Step: 793  | total loss: \u001b[1m\u001b[32m0.26016\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 793 | loss: 0.26016 - acc: 0.9634 -- iter: 6/6\n",
      "--\n",
      "Training Step: 794  | total loss: \u001b[1m\u001b[32m0.23481\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 794 | loss: 0.23481 - acc: 0.9670 -- iter: 6/6\n",
      "--\n",
      "Training Step: 795  | total loss: \u001b[1m\u001b[32m0.21201\u001b[0m\u001b[0m | time: 0.001s\n",
      "| Adam | epoch: 795 | loss: 0.21201 - acc: 0.9703 -- iter: 6/6\n",
      "--\n",
      "Training Step: 796  | total loss: \u001b[1m\u001b[32m0.19152\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 796 | loss: 0.19152 - acc: 0.9733 -- iter: 6/6\n",
      "--\n",
      "Training Step: 797  | total loss: \u001b[1m\u001b[32m0.17310\u001b[0m\u001b[0m | time: 0.003s\n",
      "| Adam | epoch: 797 | loss: 0.17310 - acc: 0.9760 -- iter: 6/6\n",
      "--\n",
      "Training Step: 798  | total loss: \u001b[1m\u001b[32m0.15655\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 798 | loss: 0.15655 - acc: 0.9784 -- iter: 6/6\n",
      "--\n",
      "Training Step: 799  | total loss: \u001b[1m\u001b[32m0.14168\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 799 | loss: 0.14168 - acc: 0.9805 -- iter: 6/6\n",
      "--\n",
      "Training Step: 800  | total loss: \u001b[1m\u001b[32m0.12832\u001b[0m\u001b[0m | time: 0.002s\n",
      "| Adam | epoch: 800 | loss: 0.12832 - acc: 0.9825 -- iter: 6/6\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(training, output, n_epoch=800, batch_size=8, show_metric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:C:\\Users\\hassan.sherwani\\Documents\\work\\companybot_tensorflow\\bot.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "model.save(\"bot.tflearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions\n",
    "\n",
    "with responses as per defined actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start talking with the bot (type close to stop)!\n",
      "User: hi ive received order one posters bad stateit folded la post sent email saying reinforce packagingthe order 512005251803340regards eugenia sebastiani\",\"intent\":\"product complaints - products (Reklamation Produkte)\",\"response\":\"neupverp\"},{\"text\":\"asked test saal photobook delighted result arrived 10 days high quality white leather look cover acrylic glass protect front photo made lovely lockdown gift best friend\n",
      "2\n",
      "User: close\n"
     ]
    }
   ],
   "source": [
    "def bag_of_words(s, words):\n",
    "    bag = [0 for _ in range(len(words))]\n",
    "\n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [lemm.lemmatize(word.lower()) for word in s_words]\n",
    "\n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "            \n",
    "    return numpy.array(bag)\n",
    "\n",
    "\n",
    "def chat():\n",
    "    print(\"Start talking with the bot (type close to stop)!\")\n",
    "    while True:\n",
    "        inp = input(\"User: \")\n",
    "        if inp.lower() == \"close\":\n",
    "            break\n",
    "\n",
    "        results = model.predict([bag_of_words(inp, words)]) # shows results with probability of each neurons with that word. \n",
    "        results_index = numpy.argmax(results) # to give maximum of index out of all neurons.\n",
    "        tag = labels[results_index]\n",
    "\n",
    "        for tg in data2:\n",
    "            if tg['intent'] == tag:\n",
    "                responses = tg['response']\n",
    "\n",
    "        print(random.choice(responses))\n",
    "\n",
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For checking Probability of each intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start talking with the bot (type close to stop)!\n",
      "User: hi ive received order one posters bad stateit folded la post sent email saying reinforce packagingthe order 512005251803340regards eugenia sebastiani\",\"intent\":\"product complaints - products (Reklamation Produkte)\",\"response\":\"neupverp\"},{\"text\":\"asked test saal photobook delighted result arrived 10 days high quality white leather look cover acrylic glass protect front photo made lovely lockdown gift best friend\n",
      "[[0.04194995 0.49493763 0.27980322 0.18330915]]\n",
      "teilen2\n",
      "User: ainda recebi encomenda e estive sempre em casa\",\"intent\":\"Order management\n",
      "[[0.9755712  0.0045671  0.00174536 0.01811626]]\n",
      "wp\n",
      "User: ainda recebi encomenda e estive sempre em casa\",\"intent\":\"Order management\n",
      "[[0.9755712  0.0045671  0.00174536 0.01811626]]\n",
      "wp\n",
      "User: dobr den mm od vs objednanou fotoknihu objednvkyhttps wwwsaaldigitalcz ordercockpit emailvvyslouzilova40seznamczordernumber512005210955444 jej pedpokldan doruen mlo bt 26 fotokniha vak stle nedorazila ke stavu objednvky nelze dohledat dn bli daje prosm proto informaci kdy bude fotokniha doruena dkuji pozdravem vyslouilov veronika\n",
      "[[9.993579e-01 2.882691e-05 8.680033e-06 6.045651e-04]]\n",
      "wp\n",
      "User: close\n"
     ]
    }
   ],
   "source": [
    "def bag_of_words(s, words):\n",
    "    bag = [0 for _ in range(len(words))]\n",
    "\n",
    "    s_words = nltk.word_tokenize(s)\n",
    "    s_words = [lemm.lemmatize(word.lower()) for word in s_words]\n",
    "\n",
    "    for se in s_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == se:\n",
    "                bag[i] = 1\n",
    "            \n",
    "    return numpy.array(bag)\n",
    "\n",
    "\n",
    "def chat():\n",
    "    print(\"Start talking with the bot (type close to stop)!\")\n",
    "    while True:\n",
    "        inp = input(\"User: \")\n",
    "        if inp.lower() == \"close\":\n",
    "            break\n",
    "\n",
    "        results = model.predict([bag_of_words(inp, words)]) # shows results with probability of each neurons with that word. \n",
    "        results_index = numpy.argmax(results) # to give maximum of index out of all neurons.\n",
    "        tag = labels[results_index]\n",
    "        print(results)\n",
    "\n",
    "        for tg in data2:\n",
    "            if tg['intent'] == tag:\n",
    "                responses = tg['response']\n",
    "\n",
    "        print(responses)\n",
    "\n",
    "chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For checking with original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Order management', 'ShareWithSaal', 'Shipping issues', 'product complaints - products (Reklamation Produkte)']\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                      Shipping issues\n",
      "1                                      Shipping issues\n",
      "2    product complaints - products (Reklamation Pro...\n",
      "3                                        ShareWithSaal\n",
      "4                                     Order management\n",
      "5                                     Order management\n",
      "Name: intent, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.intent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    nichtkombiwb\n",
      "1         renscom\n",
      "2        neupverp\n",
      "3         teilen2\n",
      "4         renscom\n",
      "5              wp\n",
      "Name: response, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>helloi tried apply voucher order received mail...</td>\n",
       "      <td>Shipping issues</td>\n",
       "      <td>nichtkombiwb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi tracking number please thank youkind regard...</td>\n",
       "      <td>Shipping issues</td>\n",
       "      <td>renscom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           intent  \\\n",
       "0  helloi tried apply voucher order received mail...  Shipping issues   \n",
       "1  hi tracking number please thank youkind regard...  Shipping issues   \n",
       "\n",
       "       response  \n",
       "0  nichtkombiwb  \n",
       "1       renscom  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tf1.14)",
   "language": "python",
   "name": "tf1.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
