{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "bow.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFBOqODHw6mV",
        "colab_type": "text"
      },
      "source": [
        "# 1)-Importing key Modules\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9CuXeO1xlV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#support both Python 2 and Python 3 with minimal overhead.\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "# I am an engineer. I care only about error not warning. So, let's be maverick and ignore warnings.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WRoiH9wxGPL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "f47b6955-3931-4906-f1a5-aa5327feb176"
      },
      "source": [
        "! pip install dynet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dynet in /usr/local/lib/python3.6/dist-packages (2.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from dynet) (0.29.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from dynet) (1.17.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiA4L15Iw7kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "import time\n",
        "import random\n",
        "import dynet as dy\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcCkkT0mx2Yc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "c5e6064b-6119-4327-e931-97f1e74b97de"
      },
      "source": [
        "! pip install version_information"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting version_information\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b0/6088e15b9ac43a08ccd300d68e0b900a20cf62077596c11ad11dd8cc9e4b/version_information-1.0.3.tar.gz\n",
            "Building wheels for collected packages: version-information\n",
            "  Building wheel for version-information (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for version-information: filename=version_information-1.0.3-cp36-none-any.whl size=3880 sha256=f176b54cd894b7bbad5a4d85bda1110b2897500a969ae6f27d77c88e8b333430\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/4c/b3/1976ac11dbd802723b564de1acaa453a72c36c95827e576321\n",
            "Successfully built version-information\n",
            "Installing collected packages: version-information\n",
            "Successfully installed version-information-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z56btwC7x268",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "outputId": "8640bebb-d708-46bc-c042-aeaec4f5ee52"
      },
      "source": [
        "# first install: pip install version_information\n",
        "%reload_ext version_information\n",
        "%version_information pandas,dynet,numpy"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/latex": "\\begin{tabular}{|l|l|}\\hline\n{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\nPython & 3.6.8 64bit [GCC 8.3.0] \\\\ \\hline\nIPython & 5.5.0 \\\\ \\hline\nOS & Linux 4.14.137+ x86\\_64 with Ubuntu 18.04 bionic \\\\ \\hline\npandas & 0.25.3 \\\\ \\hline\ndynet & 2.0.3 \\\\ \\hline\nnumpy & 1.17.3 \\\\ \\hline\n\\hline \\multicolumn{2}{|l|}{Thu Nov 07 21:32:17 2019 UTC} \\\\ \\hline\n\\end{tabular}\n",
            "application/json": {
              "Software versions": [
                {
                  "version": "3.6.8 64bit [GCC 8.3.0]",
                  "module": "Python"
                },
                {
                  "version": "5.5.0",
                  "module": "IPython"
                },
                {
                  "version": "Linux 4.14.137+ x86_64 with Ubuntu 18.04 bionic",
                  "module": "OS"
                },
                {
                  "version": "0.25.3",
                  "module": "pandas"
                },
                {
                  "version": "2.0.3",
                  "module": "dynet"
                },
                {
                  "version": "1.17.3",
                  "module": "numpy"
                }
              ]
            },
            "text/html": [
              "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.8 64bit [GCC 8.3.0]</td></tr><tr><td>IPython</td><td>5.5.0</td></tr><tr><td>OS</td><td>Linux 4.14.137+ x86_64 with Ubuntu 18.04 bionic</td></tr><tr><td>pandas</td><td>0.25.3</td></tr><tr><td>dynet</td><td>2.0.3</td></tr><tr><td>numpy</td><td>1.17.3</td></tr><tr><td colspan='2'>Thu Nov 07 21:32:17 2019 UTC</td></tr></table>"
            ],
            "text/plain": [
              "Software versions\n",
              "Python 3.6.8 64bit [GCC 8.3.0]\n",
              "IPython 5.5.0\n",
              "OS Linux 4.14.137+ x86_64 with Ubuntu 18.04 bionic\n",
              "pandas 0.25.3\n",
              "dynet 2.0.3\n",
              "numpy 1.17.3\n",
              "Thu Nov 07 21:32:17 2019 UTC"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTa40YTaxRXk",
        "colab_type": "text"
      },
      "source": [
        "# 2)- Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XguR09WKw5uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Functions to read in the corpus\n",
        "w2i = defaultdict(lambda: len(w2i))\n",
        "t2i = defaultdict(lambda: len(t2i))\n",
        "UNK = w2i[\"<unk>\"]\n",
        "def read_dataset(filename):\n",
        "  with open(filename, \"r\") as f:\n",
        "    for line in f:\n",
        "      tag, words = line.lower().strip().split(\" ||| \")\n",
        "      yield ([w2i[x] for x in words.split(\" \")], t2i[tag])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIeUL6YSw5us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in the data\n",
        "train = list(read_dataset(\"train.txt\"))\n",
        "w2i = defaultdict(lambda: UNK, w2i)\n",
        "dev = list(read_dataset(\"test.txt\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHhdGGgOyMqs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "abaff068-4f61-4a0e-cd88-8cd9faadee18"
      },
      "source": [
        "print(len(w2i))\n",
        "print(len(dev))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18649\n",
            "2210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6imEBuKaxZxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nwords = len(w2i)\n",
        "ntags = len(t2i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uK91esbw5uv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb4e4886-c57f-444e-ec64-11a8e2e3d28b"
      },
      "source": [
        "train[0][1]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGroI8b4w5uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start DyNet and define trainer\n",
        "model = dy.Model()\n",
        "trainer = dy.AdamTrainer(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU14n8zgw5u1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model\n",
        "W_sm = model.add_lookup_parameters((nwords, ntags)) # Word weights\n",
        "b_sm = model.add_parameters((ntags))                # Softmax bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B5K7C0gw5u5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function to calculate scores for one value\n",
        "def calc_scores(words):\n",
        "  dy.renew_cg()\n",
        "  score = dy.esum([dy.lookup(W_sm, x) for x in words])\n",
        "  b_sm_exp = dy.parameter(b_sm)\n",
        "  return score + b_sm_exp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdzRsP_XywvD",
        "colab_type": "text"
      },
      "source": [
        "# 3)- Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "kiDfLwG9w5u7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d9dde9d-c4c6-45b1-a60d-a160ea6383dd"
      },
      "source": [
        "for ITER in range(100):\n",
        "  # Perform training\n",
        "  random.shuffle(train)\n",
        "  train_loss = 0.0\n",
        "  start = time.time()\n",
        "  for words, tag in train:\n",
        "    my_loss = dy.pickneglogsoftmax(calc_scores(words), tag)\n",
        "    train_loss += my_loss.value()\n",
        "    my_loss.backward()\n",
        "    trainer.update()\n",
        "  print(\"iter %r: train loss/sent=%.4f, time=%.2fs\" % (ITER, train_loss/len(train), time.time()-start))\n",
        "  # Perform testing\n",
        "  test_correct = 0.0\n",
        "  for words, tag in dev:\n",
        "    scores = calc_scores(words).npvalue()\n",
        "    predict = np.argmax(scores)\n",
        "    if predict == tag:\n",
        "      test_correct += 1\n",
        "  print(\"iter %r: test acc=%.4f\" % (ITER, test_correct/len(dev)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dy.parameter(...) call is now DEPRECATED.\n",
            "        There is no longer need to explicitly add parameters to the computation graph.\n",
            "        Any used parameter will be added automatically.\n",
            "iter 0: train loss/sent=1.5173, time=0.23s\n",
            "iter 0: test acc=0.3597\n",
            "iter 1: train loss/sent=1.3385, time=0.22s\n",
            "iter 1: test acc=0.3765\n",
            "iter 2: train loss/sent=1.2355, time=0.22s\n",
            "iter 2: test acc=0.3873\n",
            "iter 3: train loss/sent=1.1567, time=0.23s\n",
            "iter 3: test acc=0.3905\n",
            "iter 4: train loss/sent=1.0920, time=0.23s\n",
            "iter 4: test acc=0.4036\n",
            "iter 5: train loss/sent=1.0381, time=0.22s\n",
            "iter 5: test acc=0.4045\n",
            "iter 6: train loss/sent=0.9913, time=0.22s\n",
            "iter 6: test acc=0.4104\n",
            "iter 7: train loss/sent=0.9498, time=0.21s\n",
            "iter 7: test acc=0.4063\n",
            "iter 8: train loss/sent=0.9129, time=0.23s\n",
            "iter 8: test acc=0.4113\n",
            "iter 9: train loss/sent=0.8799, time=0.21s\n",
            "iter 9: test acc=0.4090\n",
            "iter 10: train loss/sent=0.8496, time=0.22s\n",
            "iter 10: test acc=0.4136\n",
            "iter 11: train loss/sent=0.8224, time=0.21s\n",
            "iter 11: test acc=0.4181\n",
            "iter 12: train loss/sent=0.7977, time=0.21s\n",
            "iter 12: test acc=0.4140\n",
            "iter 13: train loss/sent=0.7743, time=0.22s\n",
            "iter 13: test acc=0.4149\n",
            "iter 14: train loss/sent=0.7538, time=0.22s\n",
            "iter 14: test acc=0.4172\n",
            "iter 15: train loss/sent=0.7343, time=0.24s\n",
            "iter 15: test acc=0.4154\n",
            "iter 16: train loss/sent=0.7159, time=0.22s\n",
            "iter 16: test acc=0.4181\n",
            "iter 17: train loss/sent=0.6988, time=0.22s\n",
            "iter 17: test acc=0.4258\n",
            "iter 18: train loss/sent=0.6830, time=0.22s\n",
            "iter 18: test acc=0.4222\n",
            "iter 19: train loss/sent=0.6679, time=0.22s\n",
            "iter 19: test acc=0.4244\n",
            "iter 20: train loss/sent=0.6539, time=0.22s\n",
            "iter 20: test acc=0.4172\n",
            "iter 21: train loss/sent=0.6407, time=0.22s\n",
            "iter 21: test acc=0.4213\n",
            "iter 22: train loss/sent=0.6281, time=0.22s\n",
            "iter 22: test acc=0.4136\n",
            "iter 23: train loss/sent=0.6160, time=0.22s\n",
            "iter 23: test acc=0.4190\n",
            "iter 24: train loss/sent=0.6049, time=0.22s\n",
            "iter 24: test acc=0.4127\n",
            "iter 25: train loss/sent=0.5941, time=0.22s\n",
            "iter 25: test acc=0.4068\n",
            "iter 26: train loss/sent=0.5841, time=0.22s\n",
            "iter 26: test acc=0.4176\n",
            "iter 27: train loss/sent=0.5737, time=0.22s\n",
            "iter 27: test acc=0.4104\n",
            "iter 28: train loss/sent=0.5646, time=0.22s\n",
            "iter 28: test acc=0.4167\n",
            "iter 29: train loss/sent=0.5559, time=0.22s\n",
            "iter 29: test acc=0.4100\n",
            "iter 30: train loss/sent=0.5468, time=0.22s\n",
            "iter 30: test acc=0.4136\n",
            "iter 31: train loss/sent=0.5389, time=0.21s\n",
            "iter 31: test acc=0.4041\n",
            "iter 32: train loss/sent=0.5312, time=0.22s\n",
            "iter 32: test acc=0.4167\n",
            "iter 33: train loss/sent=0.5234, time=0.22s\n",
            "iter 33: test acc=0.4072\n",
            "iter 34: train loss/sent=0.5163, time=0.22s\n",
            "iter 34: test acc=0.4140\n",
            "iter 35: train loss/sent=0.5090, time=0.22s\n",
            "iter 35: test acc=0.3995\n",
            "iter 36: train loss/sent=0.5024, time=0.22s\n",
            "iter 36: test acc=0.4068\n",
            "iter 37: train loss/sent=0.4958, time=0.22s\n",
            "iter 37: test acc=0.4113\n",
            "iter 38: train loss/sent=0.4894, time=0.22s\n",
            "iter 38: test acc=0.4149\n",
            "iter 39: train loss/sent=0.4833, time=0.22s\n",
            "iter 39: test acc=0.4149\n",
            "iter 40: train loss/sent=0.4777, time=0.22s\n",
            "iter 40: test acc=0.4118\n",
            "iter 41: train loss/sent=0.4719, time=0.25s\n",
            "iter 41: test acc=0.4158\n",
            "iter 42: train loss/sent=0.4664, time=0.22s\n",
            "iter 42: test acc=0.4068\n",
            "iter 43: train loss/sent=0.4610, time=0.23s\n",
            "iter 43: test acc=0.4095\n",
            "iter 44: train loss/sent=0.4558, time=0.23s\n",
            "iter 44: test acc=0.4109\n",
            "iter 45: train loss/sent=0.4507, time=0.22s\n",
            "iter 45: test acc=0.4118\n",
            "iter 46: train loss/sent=0.4459, time=0.22s\n",
            "iter 46: test acc=0.4086\n",
            "iter 47: train loss/sent=0.4410, time=0.22s\n",
            "iter 47: test acc=0.4127\n",
            "iter 48: train loss/sent=0.4362, time=0.23s\n",
            "iter 48: test acc=0.4172\n",
            "iter 49: train loss/sent=0.4319, time=0.22s\n",
            "iter 49: test acc=0.4136\n",
            "iter 50: train loss/sent=0.4275, time=0.22s\n",
            "iter 50: test acc=0.4077\n",
            "iter 51: train loss/sent=0.4231, time=0.22s\n",
            "iter 51: test acc=0.4095\n",
            "iter 52: train loss/sent=0.4190, time=0.23s\n",
            "iter 52: test acc=0.4059\n",
            "iter 53: train loss/sent=0.4149, time=0.22s\n",
            "iter 53: test acc=0.4086\n",
            "iter 54: train loss/sent=0.4107, time=0.22s\n",
            "iter 54: test acc=0.4041\n",
            "iter 55: train loss/sent=0.4069, time=0.25s\n",
            "iter 55: test acc=0.4054\n",
            "iter 56: train loss/sent=0.4034, time=0.24s\n",
            "iter 56: test acc=0.4014\n",
            "iter 57: train loss/sent=0.3998, time=0.23s\n",
            "iter 57: test acc=0.4077\n",
            "iter 58: train loss/sent=0.3960, time=0.22s\n",
            "iter 58: test acc=0.4054\n",
            "iter 59: train loss/sent=0.3923, time=0.22s\n",
            "iter 59: test acc=0.4045\n",
            "iter 60: train loss/sent=0.3889, time=0.22s\n",
            "iter 60: test acc=0.4109\n",
            "iter 61: train loss/sent=0.3856, time=0.22s\n",
            "iter 61: test acc=0.4086\n",
            "iter 62: train loss/sent=0.3823, time=0.22s\n",
            "iter 62: test acc=0.4063\n",
            "iter 63: train loss/sent=0.3790, time=0.22s\n",
            "iter 63: test acc=0.4081\n",
            "iter 64: train loss/sent=0.3757, time=0.25s\n",
            "iter 64: test acc=0.4077\n",
            "iter 65: train loss/sent=0.3727, time=0.25s\n",
            "iter 65: test acc=0.4149\n",
            "iter 66: train loss/sent=0.3698, time=0.22s\n",
            "iter 66: test acc=0.4041\n",
            "iter 67: train loss/sent=0.3668, time=0.24s\n",
            "iter 67: test acc=0.4063\n",
            "iter 68: train loss/sent=0.3637, time=0.22s\n",
            "iter 68: test acc=0.4077\n",
            "iter 69: train loss/sent=0.3609, time=0.22s\n",
            "iter 69: test acc=0.3941\n",
            "iter 70: train loss/sent=0.3579, time=0.22s\n",
            "iter 70: test acc=0.4140\n",
            "iter 71: train loss/sent=0.3553, time=0.22s\n",
            "iter 71: test acc=0.4050\n",
            "iter 72: train loss/sent=0.3525, time=0.22s\n",
            "iter 72: test acc=0.3900\n",
            "iter 73: train loss/sent=0.3498, time=0.22s\n",
            "iter 73: test acc=0.4081\n",
            "iter 74: train loss/sent=0.3471, time=0.22s\n",
            "iter 74: test acc=0.4023\n",
            "iter 75: train loss/sent=0.3444, time=0.22s\n",
            "iter 75: test acc=0.3995\n",
            "iter 76: train loss/sent=0.3422, time=0.22s\n",
            "iter 76: test acc=0.3995\n",
            "iter 77: train loss/sent=0.3397, time=0.22s\n",
            "iter 77: test acc=0.3932\n",
            "iter 78: train loss/sent=0.3374, time=0.22s\n",
            "iter 78: test acc=0.4014\n",
            "iter 79: train loss/sent=0.3348, time=0.22s\n",
            "iter 79: test acc=0.3986\n",
            "iter 80: train loss/sent=0.3325, time=0.23s\n",
            "iter 80: test acc=0.4023\n",
            "iter 81: train loss/sent=0.3302, time=0.22s\n",
            "iter 81: test acc=0.4054\n",
            "iter 82: train loss/sent=0.3278, time=0.22s\n",
            "iter 82: test acc=0.4041\n",
            "iter 83: train loss/sent=0.3256, time=0.22s\n",
            "iter 83: test acc=0.3973\n",
            "iter 84: train loss/sent=0.3234, time=0.23s\n",
            "iter 84: test acc=0.4090\n",
            "iter 85: train loss/sent=0.3211, time=0.22s\n",
            "iter 85: test acc=0.4036\n",
            "iter 86: train loss/sent=0.3192, time=0.23s\n",
            "iter 86: test acc=0.3959\n",
            "iter 87: train loss/sent=0.3168, time=0.22s\n",
            "iter 87: test acc=0.4045\n",
            "iter 88: train loss/sent=0.3146, time=0.22s\n",
            "iter 88: test acc=0.3941\n",
            "iter 89: train loss/sent=0.3129, time=0.22s\n",
            "iter 89: test acc=0.4032\n",
            "iter 90: train loss/sent=0.3108, time=0.23s\n",
            "iter 90: test acc=0.3959\n",
            "iter 91: train loss/sent=0.3088, time=0.22s\n",
            "iter 91: test acc=0.3968\n",
            "iter 92: train loss/sent=0.3068, time=0.24s\n",
            "iter 92: test acc=0.3923\n",
            "iter 93: train loss/sent=0.3048, time=0.21s\n",
            "iter 93: test acc=0.4014\n",
            "iter 94: train loss/sent=0.3031, time=0.22s\n",
            "iter 94: test acc=0.4041\n",
            "iter 95: train loss/sent=0.3010, time=0.22s\n",
            "iter 95: test acc=0.3923\n",
            "iter 96: train loss/sent=0.2991, time=0.22s\n",
            "iter 96: test acc=0.3995\n",
            "iter 97: train loss/sent=0.2975, time=0.22s\n",
            "iter 97: test acc=0.4036\n",
            "iter 98: train loss/sent=0.2956, time=0.22s\n",
            "iter 98: test acc=0.3977\n",
            "iter 99: train loss/sent=0.2934, time=0.22s\n",
            "iter 99: test acc=0.3878\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}