{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "Predicting__Next_Word(2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFBOqODHw6mV",
        "colab_type": "text"
      },
      "source": [
        "# Using Linear model\n",
        "\n",
        "- Applying embedding\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70Vdw8_niYm0",
        "colab_type": "text"
      },
      "source": [
        "# 1)-Importing key Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9CuXeO1xlV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#support both Python 2 and Python 3 with minimal overhead.\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "# I am an engineer. I care only about error not warning. So, let's be maverick and ignore warnings.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8TutW-ygWhX",
        "colab_type": "code",
        "outputId": "04a1b5b9-3ebd-404a-b885-b7e7250b000b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "! pip install dynet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dynet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/f0/01a561a301a8ea9aea1c28f82e108c38cd103964c7a46286ab01757a4092/dyNET-2.1-cp36-cp36m-manylinux1_x86_64.whl (28.1MB)\n",
            "\u001b[K     |████████████████████████████████| 28.1MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from dynet) (1.17.4)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from dynet) (0.29.14)\n",
            "Installing collected packages: dynet\n",
            "Successfully installed dynet-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiA4L15Iw7kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "import dynet as dy\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcCkkT0mx2Yc",
        "colab_type": "code",
        "outputId": "2ba00b87-19cc-42ee-dd8d-7108fb880d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "! pip install version_information"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting version_information\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b0/6088e15b9ac43a08ccd300d68e0b900a20cf62077596c11ad11dd8cc9e4b/version_information-1.0.3.tar.gz\n",
            "Building wheels for collected packages: version-information\n",
            "  Building wheel for version-information (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for version-information: filename=version_information-1.0.3-cp36-none-any.whl size=3880 sha256=7da10607b7db970da59015711308d7f3de7ba3657fd4ecf8a55d1b40c25af4be\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/4c/b3/1976ac11dbd802723b564de1acaa453a72c36c95827e576321\n",
            "Successfully built version-information\n",
            "Installing collected packages: version-information\n",
            "Successfully installed version-information-1.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z56btwC7x268",
        "colab_type": "code",
        "outputId": "1cfc22ac-4499-429d-bad8-feffa0ef5b32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "# first install: pip install version_information\n",
        "%reload_ext version_information\n",
        "%version_information pandas,torch,numpy"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/latex": "\\begin{tabular}{|l|l|}\\hline\n{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\nPython & 3.6.8 64bit [GCC 8.3.0] \\\\ \\hline\nIPython & 5.5.0 \\\\ \\hline\nOS & Linux 4.14.137+ x86\\_64 with Ubuntu 18.04 bionic \\\\ \\hline\npandas & 0.25.3 \\\\ \\hline\ntorch & 1.3.1+cu100 \\\\ \\hline\nnumpy & 1.17.4 \\\\ \\hline\n\\hline \\multicolumn{2}{|l|}{Sun Nov 17 19:52:48 2019 UTC} \\\\ \\hline\n\\end{tabular}\n",
            "application/json": {
              "Software versions": [
                {
                  "version": "3.6.8 64bit [GCC 8.3.0]",
                  "module": "Python"
                },
                {
                  "version": "5.5.0",
                  "module": "IPython"
                },
                {
                  "version": "Linux 4.14.137+ x86_64 with Ubuntu 18.04 bionic",
                  "module": "OS"
                },
                {
                  "version": "0.25.3",
                  "module": "pandas"
                },
                {
                  "version": "1.3.1+cu100",
                  "module": "torch"
                },
                {
                  "version": "1.17.4",
                  "module": "numpy"
                }
              ]
            },
            "text/html": [
              "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.8 64bit [GCC 8.3.0]</td></tr><tr><td>IPython</td><td>5.5.0</td></tr><tr><td>OS</td><td>Linux 4.14.137+ x86_64 with Ubuntu 18.04 bionic</td></tr><tr><td>pandas</td><td>0.25.3</td></tr><tr><td>torch</td><td>1.3.1+cu100</td></tr><tr><td>numpy</td><td>1.17.4</td></tr><tr><td colspan='2'>Sun Nov 17 19:52:48 2019 UTC</td></tr></table>"
            ],
            "text/plain": [
              "Software versions\n",
              "Python 3.6.8 64bit [GCC 8.3.0]\n",
              "IPython 5.5.0\n",
              "OS Linux 4.14.137+ x86_64 with Ubuntu 18.04 bionic\n",
              "pandas 0.25.3\n",
              "torch 1.3.1+cu100\n",
              "numpy 1.17.4\n",
              "Sun Nov 17 19:52:48 2019 UTC"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw-J6S79LU8O",
        "colab_type": "text"
      },
      "source": [
        "# 2)- Setting up neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFX88YgmLWsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 2 # The length of the n-gram\n",
        "EMB_SIZE = 128 # The size of the embedding\n",
        "HID_SIZE = 128 # The size of the hidden layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGXhZjWd7PKX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Functions to read in the corpus\n",
        "w2i = defaultdict(lambda: len(w2i))\n",
        "S = w2i[\"<s>\"]\n",
        "UNK = w2i[\"<unk>\"]\n",
        "def read_dataset(filename):\n",
        "  with open(filename, \"r\") as f:\n",
        "    for line in f:\n",
        "      yield [w2i[x] for x in line.strip().split(\" \")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTa40YTaxRXk",
        "colab_type": "text"
      },
      "source": [
        "# 3)- Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwirF9WxNbAY",
        "colab_type": "text"
      },
      "source": [
        "### loading data using traditional format\n",
        "using read()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XguR09WKw5uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = list(read_dataset(\"train.txt\"))\n",
        "w2i = defaultdict(lambda: UNK, w2i)\n",
        "dev = list(read_dataset(\"valid.txt\"))\n",
        "i2w = {v: k for k, v in w2i.items()}\n",
        "nwords = len(w2i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL8Mi4OWMWtT",
        "colab_type": "text"
      },
      "source": [
        "# 4)- Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPuE-EyrMZeT",
        "colab_type": "text"
      },
      "source": [
        "### 4.1)- Start DyNet and define trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT3XMPH3Mex7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = dy.ParameterCollection()\n",
        "trainer = dy.SimpleSGDTrainer(model, learning_rate=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_JwS6zcMmZT",
        "colab_type": "text"
      },
      "source": [
        "### 4.2)-Define the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKI5ySThMe0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W_emb = model.add_lookup_parameters((nwords, EMB_SIZE)) # Word weights at each position\n",
        "W_h = model.add_parameters((HID_SIZE, EMB_SIZE * N))    # Weights of the softmax\n",
        "b_h = model.add_parameters((HID_SIZE))                  # Weights of the softmax\n",
        "W_sm = model.add_parameters((nwords, HID_SIZE))         # Weights of the softmax\n",
        "b_sm = model.add_parameters((nwords))                   # Softmax bias"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxGBAs7aMuhz",
        "colab_type": "text"
      },
      "source": [
        "### 4.3)-A function to calculate scores for one value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC_uuRKvMe32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_score_of_history(words):\n",
        "  # Lookup the embeddings and concatenate them\n",
        "  emb = dy.concatenate([W_emb[x] for x in words])\n",
        "  # Create the hidden layer\n",
        "  h = dy.tanh(dy.affine_transform([b_h, W_h, emb]))\n",
        "  # Calculate the score and return\n",
        "  return dy.affine_transform([b_sm, W_sm, h])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Oo9CdoWM3DM",
        "colab_type": "text"
      },
      "source": [
        "### 4.4)-Calculate the loss value for the entire sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg0yiErZMe6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_sent_loss(sent):\n",
        "  # Create a computation graph\n",
        "  dy.renew_cg()\n",
        "  # The initial history is equal to end of sentence symbols\n",
        "  hist = [S] * N\n",
        "  # Step through the sentence, including the end of sentence token\n",
        "  all_losses = []\n",
        "  for next_word in sent + [S]:\n",
        "    s = calc_score_of_history(hist)\n",
        "    all_losses.append(dy.pickneglogsoftmax(s, next_word))\n",
        "    hist = hist[1:] + [next_word]\n",
        "  return dy.esum(all_losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8b1JUI0hvhk",
        "colab_type": "text"
      },
      "source": [
        "### 4.5)-Generate a sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-xgWIVrh0pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-8xXLvEMe87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sent():\n",
        "  dy.renew_cg()\n",
        "  hist = [S] * N\n",
        "  sent = []\n",
        "  while True:\n",
        "    p = dy.softmax(calc_score_of_history(hist)).npvalue()\n",
        "    next_word = np.random.choice(nwords, p=p/p.sum())\n",
        "    if next_word == S or len(sent) == MAX_LEN:\n",
        "      break\n",
        "    sent.append(next_word)\n",
        "    hist = hist[1:] + [next_word]\n",
        "  return sent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Huvgc_Gh959",
        "colab_type": "text"
      },
      "source": [
        "# 5)- Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6BKC7H9iAxM",
        "colab_type": "code",
        "outputId": "a2e05a2a-69ce-40b4-8ee1-ecee2d0e5de5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "for ITER in range(10):\n",
        "  # Perform training\n",
        "  random.shuffle(train)\n",
        "  train_words, train_loss = 0, 0.0\n",
        "  start = time.time()\n",
        "  for sent_id, sent in enumerate(train):\n",
        "    my_loss = calc_sent_loss(sent)\n",
        "    train_loss += my_loss.value()\n",
        "    train_words += len(sent)\n",
        "    my_loss.backward()\n",
        "    trainer.update()\n",
        "    if (sent_id+1) % 5000 == 0:\n",
        "      print(\"--finished %r sentences\" % (sent_id+1))\n",
        "  print(\"iter %r: train loss/word=%.4f, ppl=%.4f, time=%.2fs\" % (ITER, train_loss/train_words, math.exp(train_loss/train_words), time.time()-start))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--finished 5000 sentences\n",
            "--finished 10000 sentences\n",
            "--finished 15000 sentences\n",
            "--finished 20000 sentences\n",
            "--finished 25000 sentences\n",
            "--finished 30000 sentences\n",
            "--finished 35000 sentences\n",
            "--finished 40000 sentences\n",
            "iter 0: train loss/word=5.8904, ppl=361.5453, time=1539.64s\n",
            "--finished 5000 sentences\n",
            "--finished 10000 sentences\n",
            "--finished 15000 sentences\n",
            "--finished 20000 sentences\n",
            "--finished 25000 sentences\n",
            "--finished 30000 sentences\n",
            "--finished 35000 sentences\n",
            "--finished 40000 sentences\n",
            "iter 1: train loss/word=5.4269, ppl=227.4502, time=1534.92s\n",
            "--finished 5000 sentences\n",
            "--finished 10000 sentences\n",
            "--finished 15000 sentences\n",
            "--finished 20000 sentences\n",
            "--finished 25000 sentences\n",
            "--finished 30000 sentences\n",
            "--finished 35000 sentences\n",
            "--finished 40000 sentences\n",
            "iter 2: train loss/word=5.2224, ppl=185.3853, time=1534.46s\n",
            "--finished 5000 sentences\n",
            "--finished 10000 sentences\n",
            "--finished 15000 sentences\n",
            "--finished 20000 sentences\n",
            "--finished 25000 sentences\n",
            "--finished 30000 sentences\n",
            "--finished 35000 sentences\n",
            "--finished 40000 sentences\n",
            "iter 3: train loss/word=5.0775, ppl=160.3775, time=1538.21s\n",
            "--finished 5000 sentences\n",
            "--finished 10000 sentences\n",
            "--finished 15000 sentences\n",
            "--finished 20000 sentences\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-50d4f68bbec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmy_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtrain_words\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmy_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEFsbzY5X_0x",
        "colab_type": "text"
      },
      "source": [
        "We Interrupted due to long computing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2-RYk7_QXuB",
        "colab_type": "text"
      },
      "source": [
        "# 5)- Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOm0Wq1FM9wT",
        "colab_type": "code",
        "outputId": "8edc5bce-6748-431c-b7a9-44cd093e3f4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " #Evaluate on dev set\n",
        "dev_words, dev_loss = 0, 0.0\n",
        "start = time.time()\n",
        "for sent_id, sent in enumerate(dev):\n",
        "  my_loss = calc_sent_loss(sent)\n",
        "  dev_loss += my_loss.value()\n",
        "  dev_words += len(sent)\n",
        "print(\"iter %r: dev loss/word=%.4f, ppl=%.4f, time=%.2fs\" % (ITER, dev_loss/dev_words, math.exp(dev_loss/dev_words), time.time()-start))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 4: dev loss/word=5.4342, ppl=229.0993, time=41.79s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwmInnJOQpdg",
        "colab_type": "text"
      },
      "source": [
        "# 6)-Generate a few sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aIqjrDFQmXI",
        "colab_type": "code",
        "outputId": "2daff186-a708-4041-fa86-fe94474d94ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Generate a few sentences\n",
        "for _ in range(5):\n",
        "    sent = generate_sent()\n",
        "    print(\" \".join([i2w[x] for x in sent]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "in addition natural production a private company and more than anything wrong and suggest that the police whose public consequences of money investment report\n",
            "separately the state and <unk> elections of in <unk> car\n",
            "washington here\n",
            "at home development rates\n",
            "in a land television into advertisers\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}