{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "Predicting _Next_Word.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFBOqODHw6mV",
        "colab_type": "text"
      },
      "source": [
        "# 1)-Importing key Modules\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9CuXeO1xlV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#support both Python 2 and Python 3 with minimal overhead.\n",
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "# I am an engineer. I care only about error not warning. So, let's be maverick and ignore warnings.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiA4L15Iw7kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "import os, sys\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcCkkT0mx2Yc",
        "colab_type": "code",
        "outputId": "3d0ebe96-776f-4c55-e8a9-f4b44ff30360",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! pip install version_information"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: version_information in /usr/local/lib/python3.6/dist-packages (1.0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z56btwC7x268",
        "colab_type": "code",
        "outputId": "58808855-951a-4a51-c6fe-415b92be75ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        }
      },
      "source": [
        "# first install: pip install version_information\n",
        "%reload_ext version_information\n",
        "%version_information pandas,torch,numpy"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/latex": "\\begin{tabular}{|l|l|}\\hline\n{\\bf Software} & {\\bf Version} \\\\ \\hline\\hline\nPython & 3.6.8 64bit [GCC 8.3.0] \\\\ \\hline\nIPython & 5.5.0 \\\\ \\hline\nOS & Linux 4.14.137+ x86\\_64 with Ubuntu 18.04 bionic \\\\ \\hline\npandas & 0.25.3 \\\\ \\hline\ntorch & 1.3.1+cu100 \\\\ \\hline\nnumpy & 1.17.4 \\\\ \\hline\n\\hline \\multicolumn{2}{|l|}{Sat Nov 16 13:09:20 2019 UTC} \\\\ \\hline\n\\end{tabular}\n",
            "application/json": {
              "Software versions": [
                {
                  "version": "3.6.8 64bit [GCC 8.3.0]",
                  "module": "Python"
                },
                {
                  "version": "5.5.0",
                  "module": "IPython"
                },
                {
                  "version": "Linux 4.14.137+ x86_64 with Ubuntu 18.04 bionic",
                  "module": "OS"
                },
                {
                  "version": "0.25.3",
                  "module": "pandas"
                },
                {
                  "version": "1.3.1+cu100",
                  "module": "torch"
                },
                {
                  "version": "1.17.4",
                  "module": "numpy"
                }
              ]
            },
            "text/html": [
              "<table><tr><th>Software</th><th>Version</th></tr><tr><td>Python</td><td>3.6.8 64bit [GCC 8.3.0]</td></tr><tr><td>IPython</td><td>5.5.0</td></tr><tr><td>OS</td><td>Linux 4.14.137+ x86_64 with Ubuntu 18.04 bionic</td></tr><tr><td>pandas</td><td>0.25.3</td></tr><tr><td>torch</td><td>1.3.1+cu100</td></tr><tr><td>numpy</td><td>1.17.4</td></tr><tr><td colspan='2'>Sat Nov 16 13:09:20 2019 UTC</td></tr></table>"
            ],
            "text/plain": [
              "Software versions\n",
              "Python 3.6.8 64bit [GCC 8.3.0]\n",
              "IPython 5.5.0\n",
              "OS Linux 4.14.137+ x86_64 with Ubuntu 18.04 bionic\n",
              "pandas 0.25.3\n",
              "torch 1.3.1+cu100\n",
              "numpy 1.17.4\n",
              "Sat Nov 16 13:09:20 2019 UTC"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw-J6S79LU8O",
        "colab_type": "text"
      },
      "source": [
        "# 2)- Setting up neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFX88YgmLWsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Feed-forward Neural Network Language Model\n",
        "class FNN_LM(nn.Module):\n",
        "  def __init__(self, nwords, emb_size, hid_size, num_hist, dropout):\n",
        "    super(FNN_LM, self).__init__()\n",
        "    self.embedding = nn.Embedding(nwords, emb_size)\n",
        "    self.fnn = nn.Sequential(\n",
        "      nn.Linear(num_hist*emb_size, hid_size), nn.Tanh(),\n",
        "      nn.Dropout(dropout),\n",
        "      nn.Linear(hid_size, nwords)\n",
        "    )\n",
        "\n",
        "  def forward(self, words):\n",
        "    emb = self.embedding(words)      # 3D Tensor of size [batch_size x num_hist x emb_size]\n",
        "    feat = emb.view(emb.size(0), -1) # 2D Tensor of size [batch_size x (num_hist*emb_size)]\n",
        "    logit = self.fnn(feat)           # 2D Tensor of size [batch_size x nwords]\n",
        "\n",
        "    return logit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwEWsi2bLs5M",
        "colab_type": "text"
      },
      "source": [
        "### 2.1)- Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjwi2TINLnRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N = 2 # The length of the n-gram\n",
        "EMB_SIZE = 128 # The size of the embedding\n",
        "HID_SIZE = 128 # The size of the hidden layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kkdq02EdLw02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKg940UdL2pS",
        "colab_type": "text"
      },
      "source": [
        "### 2.2)-Functions to read in the corpus\n",
        "\n",
        "- NOTE: We are using data from the Penn Treebank, which is already converted\n",
        "into an easy-to-use format with \"<unk>\" symbols. If we were using other\n",
        "data we would have to do pre-processing and consider how to choose unknown words, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hva7bKQ6L6pa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "w2i = defaultdict(lambda: len(w2i))\n",
        "S = w2i[\"<s>\"]\n",
        "UNK = w2i[\"<unk>\"]\n",
        "def read_dataset(filename):\n",
        "  with open(filename, \"r\") as f:\n",
        "    for line in f:\n",
        "      yield [w2i[x] for x in line.strip().split(\" \")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ka0y9x_KL6sL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTa40YTaxRXk",
        "colab_type": "text"
      },
      "source": [
        "# 3)- Loading Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwirF9WxNbAY",
        "colab_type": "text"
      },
      "source": [
        "### loading data using traditional format\n",
        "using read()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XguR09WKw5uo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = list(read_dataset(\"train.txt\"))\n",
        "w2i = defaultdict(lambda: UNK, w2i)\n",
        "dev = list(read_dataset(\"valid.txt\"))\n",
        "i2w = {v: k for k, v in w2i.items()}\n",
        "nwords = len(w2i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL8Mi4OWMWtT",
        "colab_type": "text"
      },
      "source": [
        "# 4)- Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPuE-EyrMZeT",
        "colab_type": "text"
      },
      "source": [
        "### 4.1)- Initialize the model and the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZT3XMPH3Mex7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = FNN_LM(nwords=nwords, emb_size=EMB_SIZE, hid_size=HID_SIZE, num_hist=N, dropout=0.2)\n",
        "if USE_CUDA:\n",
        "  model = model.cuda()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# convert a (nested) list of int into a pytorch Variable\n",
        "def convert_to_variable(words):\n",
        "  var = Variable(torch.LongTensor(words))\n",
        "  if USE_CUDA:\n",
        "    var = var.cuda()\n",
        "\n",
        "  return var"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_JwS6zcMmZT",
        "colab_type": "text"
      },
      "source": [
        "### 4.2)-calculate scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKI5ySThMe0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A function to calculate scores for one value\n",
        "def calc_score_of_histories(words):\n",
        "  # This will change from a list of histories, to a pytorch Variable whose data type is LongTensor\n",
        "  words_var = convert_to_variable(words)\n",
        "  logits = model(words_var)\n",
        "  return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxGBAs7aMuhz",
        "colab_type": "text"
      },
      "source": [
        "### 4.3)-loss value for the entire sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SC_uuRKvMe32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_sent_loss(sent):\n",
        "  # The initial history is equal to end of sentence symbols\n",
        "  hist = [S] * N\n",
        "  # Step through the sentence, including the end of sentence token\n",
        "  all_histories = []\n",
        "  all_targets = []\n",
        "  for next_word in sent + [S]:\n",
        "    all_histories.append(list(hist))\n",
        "    all_targets.append(next_word)\n",
        "    hist = hist[1:] + [next_word]\n",
        "\n",
        "  logits = calc_score_of_histories(all_histories)\n",
        "  loss = nn.functional.cross_entropy(logits, convert_to_variable(all_targets), size_average=False)\n",
        "\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Oo9CdoWM3DM",
        "colab_type": "text"
      },
      "source": [
        "### 4.4)-Generate a sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg0yiErZMe6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-8xXLvEMe87",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "outputId": "e74c3a9f-d286-4a96-f520-fc1e98e15d6d"
      },
      "source": [
        "def generate_sent():\n",
        "  hist = [S] * N\n",
        "  sent = []\n",
        "  while True:\n",
        "    logits = calc_score_of_histories([hist])\n",
        "    prob = nn.functional.softmax(logits)\n",
        "    next_word = prob.multinomial().data[0,0]\n",
        "    if next_word == S or len(sent) == MAX_LEN:\n",
        "      break\n",
        "    sent.append(next_word)\n",
        "    hist = hist[1:] + [next_word]\n",
        "  return sent\n",
        "\n",
        "last_dev = 1e20\n",
        "best_dev = 1e20\n",
        "\n",
        "for ITER in range(5):\n",
        "  # Perform training\n",
        "  random.shuffle(train)\n",
        "  # set the model to training mode\n",
        "  model.train()\n",
        "  train_words, train_loss = 0, 0.0\n",
        "  start = time.time()\n",
        "  for sent_id, sent in enumerate(train):\n",
        "    my_loss = calc_sent_loss(sent)\n",
        "    train_loss += my_loss.data\n",
        "    train_words += len(sent)\n",
        "    optimizer.zero_grad()\n",
        "    my_loss.backward()\n",
        "    optimizer.step()\n",
        "    if (sent_id+1) % 5000 == 0:\n",
        "      print(\"--finished %r sentences (word/sec=%.2f)\" % (sent_id+1, train_words/(time.time()-start)))\n",
        "  print(\"iter %r: train loss/word=%.4f, ppl=%.4f (word/sec=%.2f)\" % (ITER, train_loss/train_words, math.exp(train_loss/train_words), train_words/(time.time()-start)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--finished 5000 sentences (word/sec=8074.55)\n",
            "--finished 10000 sentences (word/sec=8059.94)\n",
            "--finished 15000 sentences (word/sec=8212.21)\n",
            "--finished 20000 sentences (word/sec=8202.63)\n",
            "--finished 25000 sentences (word/sec=8231.49)\n",
            "--finished 30000 sentences (word/sec=8244.91)\n",
            "--finished 35000 sentences (word/sec=8234.18)\n",
            "--finished 40000 sentences (word/sec=8257.45)\n",
            "iter 0: train loss/word=6.2654, ppl=526.0477 (word/sec=8273.65)\n",
            "--finished 5000 sentences (word/sec=8264.47)\n",
            "--finished 10000 sentences (word/sec=8363.97)\n",
            "--finished 15000 sentences (word/sec=8349.43)\n",
            "--finished 20000 sentences (word/sec=8290.85)\n",
            "--finished 25000 sentences (word/sec=8315.94)\n",
            "--finished 30000 sentences (word/sec=8341.71)\n",
            "--finished 35000 sentences (word/sec=8390.00)\n",
            "--finished 40000 sentences (word/sec=8394.06)\n",
            "iter 1: train loss/word=5.7669, ppl=319.5546 (word/sec=8366.39)\n",
            "--finished 5000 sentences (word/sec=8633.65)\n",
            "--finished 10000 sentences (word/sec=8465.88)\n",
            "--finished 15000 sentences (word/sec=8431.93)\n",
            "--finished 20000 sentences (word/sec=8366.54)\n",
            "--finished 25000 sentences (word/sec=8325.59)\n",
            "--finished 30000 sentences (word/sec=8319.15)\n",
            "--finished 35000 sentences (word/sec=8359.97)\n",
            "--finished 40000 sentences (word/sec=8350.89)\n",
            "iter 2: train loss/word=5.6109, ppl=273.3883 (word/sec=8352.92)\n",
            "--finished 5000 sentences (word/sec=8127.28)\n",
            "--finished 10000 sentences (word/sec=8184.67)\n",
            "--finished 15000 sentences (word/sec=8316.92)\n",
            "--finished 20000 sentences (word/sec=8327.10)\n",
            "--finished 25000 sentences (word/sec=8307.51)\n",
            "--finished 30000 sentences (word/sec=8341.95)\n",
            "--finished 35000 sentences (word/sec=8310.40)\n",
            "--finished 40000 sentences (word/sec=8304.68)\n",
            "iter 3: train loss/word=5.5208, ppl=249.8263 (word/sec=8328.06)\n",
            "--finished 5000 sentences (word/sec=8262.91)\n",
            "--finished 10000 sentences (word/sec=8312.03)\n",
            "--finished 15000 sentences (word/sec=8283.86)\n",
            "--finished 20000 sentences (word/sec=8238.85)\n",
            "--finished 25000 sentences (word/sec=8312.59)\n",
            "--finished 30000 sentences (word/sec=8310.12)\n",
            "--finished 35000 sentences (word/sec=8277.23)\n",
            "--finished 40000 sentences (word/sec=8303.73)\n",
            "iter 4: train loss/word=5.4556, ppl=234.0679 (word/sec=8306.79)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2-RYk7_QXuB",
        "colab_type": "text"
      },
      "source": [
        "# 5)- Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOm0Wq1FM9wT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  model.eval()\n",
        "  dev_words, dev_loss = 0, 0.0\n",
        "  start = time.time()\n",
        "  for sent_id, sent in enumerate(dev):\n",
        "    my_loss = calc_sent_loss(sent)\n",
        "    dev_loss += my_loss.data\n",
        "    dev_words += len(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DidEkzaM9y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Keep track of the development accuracy and reduce the learning rate if it got worse\n",
        "  if last_dev < dev_loss:\n",
        "    optimizer.learning_rate /= 2\n",
        "  last_dev = dev_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5RJx0wjQf44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Keep track of the best development accuracy, and save the model only if it's the best one\n",
        "  if best_dev > dev_loss:\n",
        "    torch.save(model, \"model.pt\")\n",
        "    best_dev = dev_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZa_Bq2WQi2A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22444d67-8fd2-4d8e-9d21-553e0b31a21c"
      },
      "source": [
        "# Save the model\n",
        "  print(\"iter %r: dev loss/word=%.4f, ppl=%.4f (word/sec=%.2f)\" % (ITER, dev_loss/dev_words, math.exp(dev_loss/dev_words), dev_words/(time.time()-start)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 4: dev loss/word=5.7182, ppl=304.3606 (word/sec=16255.00)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwmInnJOQpdg",
        "colab_type": "text"
      },
      "source": [
        "# 6)-Generate a few sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aIqjrDFQmXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " for _ in range(5):\n",
        "    sent = generate_sent()\n",
        "    print(\" \".join([i2w[x] for x in sent]))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}